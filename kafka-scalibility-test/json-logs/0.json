[
    {
        "timestamp": "2015-03-23 05:25:58,991",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NodeManager",
        "message": " STARTUP_MSG: \n"
    },
    {
        "timestamp": "STARTUP_MSG: ",
        "type": "",
        "app": "classpath = /home/ubuntu/hadoop/etc/hadoop",
        "message": "/home/ubuntu/hadoop/etc/hadoop:/home/ubuntu/hadoop/etc/hadoop:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/common/lib/commons-net-3.1.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/common/lib/commons-httpclient-3.1.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/common/lib/httpclient-4.2.5.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/common/lib/jersey-json-1.9.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/common/lib/api-asn1-api-1.0.0-M20.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/common/lib/commons-digester-1.8.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/common/lib/guava-11.0.2.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/common/lib/jettison-1.1.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/common/lib/httpcore-4.2.5.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/common/lib/jsr305-1.3.9.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/common/lib/activation-1.1.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/common/lib/jersey-server-1.9.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/common/lib/jersey-core-1.9.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/common/lib/commons-cli-1.2.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/common/lib/jsp-api-2.1.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/common/lib/asm-3.2.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/common/lib/slf4j-api-1.7.5.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/common/lib/commons-collections-3.2.1.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/common/lib/jasper-runtime-5.5.23.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/common/lib/junit-4.11.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/common/lib/paranamer-2.3.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/common/lib/curator-recipes-2.6.0.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/common/lib/commons-codec-1.4.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/common/lib/commons-el-1.0.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/common/lib/curator-client-2.6.0.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/common/lib/jsch-0.1.42.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/common/lib/gson-2.2.4.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/common/lib/htrace-core-3.0.4.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/common/lib/xz-1.0.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/common/lib/apacheds-kerberos-codec-2.0.0-M15.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/common/lib/jasper-compiler-5.5.23.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/common/lib/curator-framework-2.6.0.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/common/lib/servlet-api-2.5.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/common/lib/avro-1.7.4.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/common/lib/commons-io-2.4.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/common/lib/api-util-1.0.0-M20.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/common/lib/xmlenc-0.52.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/common/lib/hadoop-annotations-2.6.0.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/common/lib/hadoop-auth-2.6.0.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/common/lib/jetty-6.1.26.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/common/lib/apacheds-i18n-2.0.0-M15.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/common/lib/commons-lang-2.6.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/common/lib/netty-3.6.2.Final.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/common/lib/log4j-1.2.17.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/common/hadoop-nfs-2.6.0.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/common/hadoop-common-2.6.0.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/common/hadoop-common-2.6.0-tests.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/hdfs:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/hdfs/lib/guava-11.0.2.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/hdfs/lib/jsr305-1.3.9.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/hdfs/lib/jersey-server-1.9.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/hdfs/lib/jersey-core-1.9.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/hdfs/lib/jsp-api-2.1.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/hdfs/lib/asm-3.2.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/hdfs/lib/jasper-runtime-5.5.23.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-codec-1.4.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-el-1.0.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/hdfs/lib/jetty-util-6.1.26.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/hdfs/lib/htrace-core-3.0.4.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/hdfs/lib/servlet-api-2.5.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-io-2.4.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/hdfs/lib/xmlenc-0.52.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/hdfs/lib/jetty-6.1.26.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/hdfs/lib/netty-3.6.2.Final.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/hdfs/hadoop-hdfs-nfs-2.6.0.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/hdfs/hadoop-hdfs-2.6.0-tests.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/hdfs/hadoop-hdfs-2.6.0.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/lib/jline-0.9.94.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/lib/jettison-1.1.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/lib/activation-1.1.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/lib/asm-3.2.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/lib/guice-3.0.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/lib/xz-1.0.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/lib/javax.inject-1.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-common-2.6.0.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-client-2.6.0.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.0.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-common-2.6.0.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.0.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.0.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.0.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.0.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.0.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.0.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-registry-2.6.0.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-api-2.6.0.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/mapreduce/lib/leveldbjni-all-1.8.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/mapreduce/lib/guice-servlet-3.0.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/mapreduce/lib/jersey-server-1.9.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/mapreduce/lib/jersey-core-1.9.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/mapreduce/lib/asm-3.2.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/mapreduce/lib/snappy-java-1.0.4.1.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/mapreduce/lib/jersey-guice-1.9.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/mapreduce/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/mapreduce/lib/junit-4.11.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/mapreduce/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/mapreduce/lib/paranamer-2.3.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/mapreduce/lib/commons-compress-1.4.1.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/mapreduce/lib/protobuf-java-2.5.0.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/mapreduce/lib/guice-3.0.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/mapreduce/lib/xz-1.0.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/mapreduce/lib/aopalliance-1.0.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/mapreduce/lib/avro-1.7.4.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/mapreduce/lib/commons-io-2.4.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/mapreduce/lib/hadoop-annotations-2.6.0.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/mapreduce/lib/javax.inject-1.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/mapreduce/lib/netty-3.6.2.Final.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/mapreduce/lib/log4j-1.2.17.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-2.6.0.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-core-2.6.0.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-common-2.6.0.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.0.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.6.0-tests.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-2.6.0.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-app-2.6.0.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.0.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-2.6.0.jar:/home/ubuntu/hadoop/contrib/capacity-scheduler/*.jar:/home/ubuntu/hadoop/contrib/capacity-scheduler/*.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-common-2.6.0.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-client-2.6.0.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-nodemanager-2.6.0.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-common-2.6.0.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-2.6.0.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-tests-2.6.0.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-web-proxy-2.6.0.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-2.6.0.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-2.6.0.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-2.6.0.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-registry-2.6.0.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-api-2.6.0.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-json-1.9.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/lib/jaxb-impl-2.2.3-1.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/lib/jline-0.9.94.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/lib/guava-11.0.2.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/lib/jettison-1.1.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/lib/stax-api-1.0-2.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/lib/leveldbjni-all-1.8.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/lib/jsr305-1.3.9.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/lib/activation-1.1.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/lib/guice-servlet-3.0.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-server-1.9.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-core-1.9.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/lib/commons-cli-1.2.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/lib/asm-3.2.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-jaxrs-1.9.13.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/lib/jaxb-api-2.2.2.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-guice-1.9.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/lib/commons-collections-3.2.1.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-mapper-asl-1.9.13.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/lib/jersey-client-1.9.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-core-asl-1.9.13.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/lib/commons-codec-1.4.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/lib/jetty-util-6.1.26.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/lib/commons-compress-1.4.1.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/lib/protobuf-java-2.5.0.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/lib/guice-3.0.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/lib/commons-logging-1.1.3.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/lib/xz-1.0.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/lib/servlet-api-2.5.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/lib/commons-io-2.4.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/lib/jackson-xc-1.9.13.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/lib/zookeeper-3.4.6.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/lib/javax.inject-1.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/lib/jetty-6.1.26.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/lib/commons-lang-2.6.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/lib/netty-3.6.2.Final.jar:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/lib/log4j-1.2.17.jar:/home/ubuntu/hadoop/etc/hadoop/nm-config/log4j.properties\n"
    },
    {
        "timestamp": "STARTUP_MSG: ",
        "type": "",
        "app": "build = Unknown -r Unknown; compiled by 'xuzhao' on 2015-02-27T18",
        "message": "41Z\n"
    },
    {
        "timestamp": "2015-03-23 05:25:59,110",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NodeManager",
        "message": " registered UNIX signal handlers for [TERM, HUP, INT]\n"
    },
    {
        "timestamp": "2015-03-23 05:26:06,774",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.event.AsyncDispatcher",
        "message": " Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.container.ContainerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ContainerEventDispatcher\n"
    },
    {
        "timestamp": "2015-03-23 05:26:06,775",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.event.AsyncDispatcher",
        "message": " Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.application.ApplicationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl$ApplicationEventDispatcher\n"
    },
    {
        "timestamp": "2015-03-23 05:26:06,776",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.event.AsyncDispatcher",
        "message": " Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizationEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService\n"
    },
    {
        "timestamp": "2015-03-23 05:26:06,777",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.event.AsyncDispatcher",
        "message": " Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServicesEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices\n"
    },
    {
        "timestamp": "2015-03-23 05:26:06,778",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.event.AsyncDispatcher",
        "message": " Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl\n"
    },
    {
        "timestamp": "2015-03-23 05:26:06,779",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.event.AsyncDispatcher",
        "message": " Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncherEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainersLauncher\n"
    },
    {
        "timestamp": "2015-03-23 05:26:06,885",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.event.AsyncDispatcher",
        "message": " Registering class org.apache.hadoop.yarn.server.nodemanager.ContainerManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl\n"
    },
    {
        "timestamp": "2015-03-23 05:26:06,886",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.event.AsyncDispatcher",
        "message": " Registering class org.apache.hadoop.yarn.server.nodemanager.NodeManagerEventType for class org.apache.hadoop.yarn.server.nodemanager.NodeManager\n"
    },
    {
        "timestamp": "2015-03-23 05:26:07,029",
        "type": "INFO",
        "app": "org.apache.hadoop.metrics2.impl.MetricsConfig",
        "message": " loaded properties from hadoop-metrics2.properties\n"
    },
    {
        "timestamp": "2015-03-23 05:26:07,261",
        "type": "INFO",
        "app": "org.apache.hadoop.metrics2.impl.MetricsSystemImpl",
        "message": " Scheduled snapshot period at 10 second(s).\n"
    },
    {
        "timestamp": "2015-03-23 05:26:07,261",
        "type": "INFO",
        "app": "org.apache.hadoop.metrics2.impl.MetricsSystemImpl",
        "message": " NodeManager metrics system started\n"
    },
    {
        "timestamp": "2015-03-23 05:26:07,541",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.event.AsyncDispatcher",
        "message": " Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.event.LogHandlerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler\n"
    },
    {
        "timestamp": "2015-03-23 05:26:07,541",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService",
        "message": " per directory file limit = 8192\n"
    },
    {
        "timestamp": "2015-03-23 05:26:07,675",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.event.AsyncDispatcher",
        "message": " Registering class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.event.LocalizerEventType for class org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService$LocalizerTracker\n"
    },
    {
        "timestamp": "2015-03-23 05:26:07,855",
        "type": "WARN",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " The Auxilurary Service named 'mapreduce_shuffle' in the configuration is for class class org.apache.hadoop.mapred.ShuffleHandler which has a name of 'httpshuffle'. Because these are not the same tools trying to send ServiceData and read Service Meta Data may have issues unless the refer to the name in the config.\n"
    },
    {
        "timestamp": "2015-03-23 05:26:07,855",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Adding auxiliary service httpshuffle, \"mapreduce_shuffle\"\n"
    },
    {
        "timestamp": "2015-03-23 05:26:08,019",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": "  Using ResourceCalculatorPlugin : org.apache.hadoop.yarn.util.LinuxResourceCalculatorPlugin@30cbd684\n"
    },
    {
        "timestamp": "2015-03-23 05:26:08,019",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": "  Using ResourceCalculatorProcessTree : null\n"
    },
    {
        "timestamp": "2015-03-23 05:26:08,019",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Physical memory check enabled: true\n"
    },
    {
        "timestamp": "2015-03-23 05:26:08,020",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Virtual memory check enabled: true\n"
    },
    {
        "timestamp": "2015-03-23 05:26:08,065",
        "type": "WARN",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " NodeManager configured with 8 G physical memory allocated to containers, which is more than 80% of the total physical memory available (1.6 G). Thrashing might happen.\n"
    },
    {
        "timestamp": "2015-03-23 05:26:08,076",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl",
        "message": " Initialized nodemanager for null: physical-memory=8192 virtual-memory=17204 virtual-cores=8\n"
    },
    {
        "timestamp": "2015-03-23 05:26:08,241",
        "type": "INFO",
        "app": "org.apache.hadoop.ipc.CallQueueManager",
        "message": " Using callQueue class java.util.concurrent.LinkedBlockingQueue\n"
    },
    {
        "timestamp": "2015-03-23 05:26:08,313",
        "type": "INFO",
        "app": "org.apache.hadoop.ipc.Server",
        "message": " Starting Socket Reader #1 for port 58841\n"
    },
    {
        "timestamp": "2015-03-23 05:26:08,418",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl",
        "message": " Adding protocol org.apache.hadoop.yarn.api.ContainerManagementProtocolPB to the server\n"
    },
    {
        "timestamp": "2015-03-23 05:26:08,418",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Blocking new container-requests as container manager rpc server is still starting.\n"
    },
    {
        "timestamp": "2015-03-23 05:26:08,419",
        "type": "INFO",
        "app": "org.apache.hadoop.ipc.Server",
        "message": " IPC Server Responder: starting\n"
    },
    {
        "timestamp": "2015-03-23 05:26:08,421",
        "type": "INFO",
        "app": "org.apache.hadoop.ipc.Server",
        "message": " IPC Server listener on 58841: starting\n"
    },
    {
        "timestamp": "2015-03-23 05:26:08,491",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager",
        "message": " Updating node address : i-a0ca09af:58841\n"
    },
    {
        "timestamp": "2015-03-23 05:26:08,516",
        "type": "INFO",
        "app": "org.apache.hadoop.ipc.CallQueueManager",
        "message": " Using callQueue class java.util.concurrent.LinkedBlockingQueue\n"
    },
    {
        "timestamp": "2015-03-23 05:26:08,517",
        "type": "INFO",
        "app": "org.apache.hadoop.ipc.Server",
        "message": " Starting Socket Reader #1 for port 8140\n"
    },
    {
        "timestamp": "2015-03-23 05:26:08,525",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.factories.impl.pb.RpcServerFactoryPBImpl",
        "message": " Adding protocol org.apache.hadoop.yarn.server.nodemanager.api.LocalizationProtocolPB to the server\n"
    },
    {
        "timestamp": "2015-03-23 05:26:08,525",
        "type": "INFO",
        "app": "org.apache.hadoop.ipc.Server",
        "message": " IPC Server Responder: starting\n"
    },
    {
        "timestamp": "2015-03-23 05:26:08,554",
        "type": "INFO",
        "app": "org.apache.hadoop.ipc.Server",
        "message": " IPC Server listener on 8140: starting\n"
    },
    {
        "timestamp": "2015-03-23 05:26:08,564",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService",
        "message": " Localizer started on port 8140\n"
    },
    {
        "timestamp": "2015-03-23 05:26:08,617",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.IndexCache",
        "message": " IndexCache created with max memory = 10485760\n"
    },
    {
        "timestamp": "2015-03-23 05:26:08,673",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " httpshuffle listening on port 13562\n"
    },
    {
        "timestamp": "2015-03-23 05:26:08,676",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " ContainerManager started at ip-172-31-17-65/172.31.17.65:58841\n"
    },
    {
        "timestamp": "2015-03-23 05:26:08,676",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " ContainerManager bound to 0.0.0.0/0.0.0.0:0\n"
    },
    {
        "timestamp": "2015-03-23 05:26:08,677",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.webapp.WebServer",
        "message": " Instantiating NMWebApp at 0.0.0.0:51060\n"
    },
    {
        "timestamp": "2015-03-23 05:26:08,988",
        "type": "INFO",
        "app": "org.mortbay.log",
        "message": " Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog\n"
    },
    {
        "timestamp": "2015-03-23 05:26:08,995",
        "type": "INFO",
        "app": "org.apache.hadoop.http.HttpRequestLog",
        "message": " Http request log for http.requests.nodemanager is not defined\n"
    },
    {
        "timestamp": "2015-03-23 05:26:09,041",
        "type": "INFO",
        "app": "org.apache.hadoop.http.HttpServer2",
        "message": " Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)\n"
    },
    {
        "timestamp": "2015-03-23 05:26:09,073",
        "type": "INFO",
        "app": "org.apache.hadoop.http.HttpServer2",
        "message": " Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context node\n"
    },
    {
        "timestamp": "2015-03-23 05:26:09,074",
        "type": "INFO",
        "app": "org.apache.hadoop.http.HttpServer2",
        "message": " Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs\n"
    },
    {
        "timestamp": "2015-03-23 05:26:09,074",
        "type": "INFO",
        "app": "org.apache.hadoop.http.HttpServer2",
        "message": " Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static\n"
    },
    {
        "timestamp": "2015-03-23 05:26:09,080",
        "type": "INFO",
        "app": "org.apache.hadoop.http.HttpServer2",
        "message": " adding path spec: /node/*\n"
    },
    {
        "timestamp": "2015-03-23 05:26:09,080",
        "type": "INFO",
        "app": "org.apache.hadoop.http.HttpServer2",
        "message": " adding path spec: /ws/*\n"
    },
    {
        "timestamp": "2015-03-23 05:26:09,130",
        "type": "INFO",
        "app": "org.apache.hadoop.http.HttpServer2",
        "message": " Jetty bound to port 51060\n"
    },
    {
        "timestamp": "2015-03-23 05:26:09,131",
        "type": "INFO",
        "app": "org.mortbay.log",
        "message": " jetty-6.1.26\n"
    },
    {
        "timestamp": "2015-03-23 05:26:09,322",
        "type": "INFO",
        "app": "org.mortbay.log",
        "message": " Extract jar:file:/home/ubuntu/3603-hive/hadoop-2.6.0-src/hadoop-dist/target/hadoop-2.6.0/share/hadoop/yarn/hadoop-yarn-common-2.6.0.jar!/webapps/node to /tmp/Jetty_0_0_0_0_51060_node____.bdhlm9/webapp\n"
    },
    {
        "timestamp": "2015-03-23 05:26:11,400",
        "type": "INFO",
        "app": "org.mortbay.log",
        "message": " Started HttpServer2$SelectChannelConnectorWithSafeStartup@0.0.0.0:51060\n"
    },
    {
        "timestamp": "2015-03-23 05:26:11,400",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.webapp.WebApps",
        "message": " Web app /node started at 51060\n"
    },
    {
        "timestamp": "2015-03-23 05:26:13,360",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.webapp.WebApps",
        "message": " Registered webapp guice modules\n"
    },
    {
        "timestamp": "2015-03-23 05:26:13,374",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.client.RMProxy",
        "message": " Connecting to ResourceManager at /172.31.17.135:8225\n"
    },
    {
        "timestamp": "2015-03-23 05:26:13,518",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl",
        "message": " Sending out 0 NM container statuses: []\n"
    },
    {
        "timestamp": "2015-03-23 05:26:13,553",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl",
        "message": " Registering with RM using containers :[]\n"
    },
    {
        "timestamp": "2015-03-23 05:26:14,625",
        "type": "INFO",
        "app": "org.apache.hadoop.ipc.Client",
        "message": " Retrying connect to server: i-89ca0986/172.31.17.135:8225. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)\n"
    },
    {
        "timestamp": "2015-03-23 05:26:15,626",
        "type": "INFO",
        "app": "org.apache.hadoop.ipc.Client",
        "message": " Retrying connect to server: i-89ca0986/172.31.17.135:8225. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)\n"
    },
    {
        "timestamp": "2015-03-23 05:26:16,627",
        "type": "INFO",
        "app": "org.apache.hadoop.ipc.Client",
        "message": " Retrying connect to server: i-89ca0986/172.31.17.135:8225. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)\n"
    },
    {
        "timestamp": "2015-03-23 05:26:17,628",
        "type": "INFO",
        "app": "org.apache.hadoop.ipc.Client",
        "message": " Retrying connect to server: i-89ca0986/172.31.17.135:8225. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)\n"
    },
    {
        "timestamp": "2015-03-23 05:26:18,635",
        "type": "INFO",
        "app": "org.apache.hadoop.ipc.Client",
        "message": " Retrying connect to server: i-89ca0986/172.31.17.135:8225. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)\n"
    },
    {
        "timestamp": "2015-03-23 05:26:19,643",
        "type": "INFO",
        "app": "org.apache.hadoop.ipc.Client",
        "message": " Retrying connect to server: i-89ca0986/172.31.17.135:8225. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)\n"
    },
    {
        "timestamp": "2015-03-23 05:26:20,652",
        "type": "INFO",
        "app": "org.apache.hadoop.ipc.Client",
        "message": " Retrying connect to server: i-89ca0986/172.31.17.135:8225. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)\n"
    },
    {
        "timestamp": "2015-03-23 05:26:21,689",
        "type": "INFO",
        "app": "org.apache.hadoop.ipc.Client",
        "message": " Retrying connect to server: i-89ca0986/172.31.17.135:8225. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)\n"
    },
    {
        "timestamp": "2015-03-23 05:26:22,690",
        "type": "INFO",
        "app": "org.apache.hadoop.ipc.Client",
        "message": " Retrying connect to server: i-89ca0986/172.31.17.135:8225. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)\n"
    },
    {
        "timestamp": "2015-03-23 05:26:23,691",
        "type": "INFO",
        "app": "org.apache.hadoop.ipc.Client",
        "message": " Retrying connect to server: i-89ca0986/172.31.17.135:8225. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)\n"
    },
    {
        "timestamp": "2015-03-23 05:26:53,807",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.security.NMContainerTokenSecretManager",
        "message": " Rolling master-key for container-tokens, got key with id -953817818\n"
    },
    {
        "timestamp": "2015-03-23 05:26:53,813",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.security.NMTokenSecretManagerInNM",
        "message": " Rolling master-key for container-tokens, got key with id 1844402530\n"
    },
    {
        "timestamp": "2015-03-23 05:26:53,814",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl",
        "message": " Registered with ResourceManager as i-a0ca09af:58841 with total resource of <memory:8192, vCores:8>\n"
    },
    {
        "timestamp": "2015-03-23 05:26:53,814",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl",
        "message": " Notifying ContainerManager to unblock new container-requests\n"
    },
    {
        "timestamp": "2015-03-23 05:39:41,891",
        "type": "INFO",
        "app": "SecurityLogger.org.apache.hadoop.ipc.Server",
        "message": " Auth successful for appattempt_1427088391284_0001_000001 (auth:SIMPLE)\n"
    },
    {
        "timestamp": "2015-03-23 05:39:42,627",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Start request for container_1427088391284_0001_01_000120 by user ubuntu\n"
    },
    {
        "timestamp": "2015-03-23 05:39:42,711",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Creating a new application reference for app application_1427088391284_0001\n"
    },
    {
        "timestamp": "2015-03-23 05:39:42,763",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tIP=172.31.17.2\tOPERATION=Start Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0001\tCONTAINERID=container_1427088391284_0001_01_000120\n"
    },
    {
        "timestamp": "2015-03-23 05:39:42,767",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0001 transitioned from NEW to INITING\n"
    },
    {
        "timestamp": "2015-03-23 05:39:42,767",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Adding container_1427088391284_0001_01_000120 to application application_1427088391284_0001\n"
    },
    {
        "timestamp": "2015-03-23 05:39:42,780",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0001 transitioned from INITING to RUNNING\n"
    },
    {
        "timestamp": "2015-03-23 05:39:42,833",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0001_01_000120 transitioned from NEW to LOCALIZING\n"
    },
    {
        "timestamp": "2015-03-23 05:39:42,833",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event CONTAINER_INIT for appId application_1427088391284_0001\n"
    },
    {
        "timestamp": "2015-03-23 05:39:42,836",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event APPLICATION_INIT for appId application_1427088391284_0001\n"
    },
    {
        "timestamp": "2015-03-23 05:39:42,836",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got APPLICATION_INIT for service mapreduce_shuffle\n"
    },
    {
        "timestamp": "2015-03-23 05:39:42,844",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Added token for job_1427088391284_0001\n"
    },
    {
        "timestamp": "2015-03-23 05:39:42,992",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/HiBench/Hive/temp/linkzipf transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 05:39:42,993",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0001/job.jar transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 05:39:42,993",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0001/job.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 05:39:42,993",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService",
        "message": " Downloading public rsrc:{ hdfs://172.31.17.135:8120/HiBench/Hive/temp/linkzipf, 1427089016189, FILE, null }\n"
    },
    {
        "timestamp": "2015-03-23 05:39:43,790",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService",
        "message": " Created localizer for container_1427088391284_0001_01_000120\n"
    },
    {
        "timestamp": "2015-03-23 05:39:43,947",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService",
        "message": " Writing credentials to the nmPrivate file /tmp/hadoop-ubuntu/nm-local-dir/nmPrivate/container_1427088391284_0001_01_000120.tokens. Credentials list: \n"
    },
    {
        "timestamp": "2015-03-23 05:39:44,280",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Initializing user ubuntu\n"
    },
    {
        "timestamp": "2015-03-23 05:39:45,314",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Copying from /tmp/hadoop-ubuntu/nm-local-dir/nmPrivate/container_1427088391284_0001_01_000120.tokens to /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0001/container_1427088391284_0001_01_000120.tokens\n"
    },
    {
        "timestamp": "2015-03-23 05:39:45,341",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Localizer CWD set to /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0001 = file:/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0001\n"
    },
    {
        "timestamp": "2015-03-23 05:39:48,335",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0001/job.jar(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0001/filecache/10/job.jar) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 05:39:48,395",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/HiBench/Hive/temp/linkzipf(->/tmp/hadoop-ubuntu/nm-local-dir/filecache/10/linkzipf) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 05:39:48,505",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0001/job.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0001/filecache/11/job.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 05:39:48,506",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0001_01_000120 transitioned from LOCALIZING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 05:39:48,644",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0001_01_000120 transitioned from LOCALIZED to RUNNING\n"
    },
    {
        "timestamp": "2015-03-23 05:39:48,678",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " launchContainer: [bash, /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0001/container_1427088391284_0001_01_000120/default_container_executor.sh]\n"
    },
    {
        "timestamp": "2015-03-23 05:39:50,970",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Starting resource-monitoring for container_1427088391284_0001_01_000120\n"
    },
    {
        "timestamp": "2015-03-23 05:39:51,136",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 1935 for container-id container_1427088391284_0001_01_000120: 45.5 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:39:54,303",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 1935 for container-id container_1427088391284_0001_01_000120: 58.3 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:39:57,332",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 1935 for container-id container_1427088391284_0001_01_000120: 73.6 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:40:00,402",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 1935 for container-id container_1427088391284_0001_01_000120: 84.9 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:40:03,465",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 1935 for container-id container_1427088391284_0001_01_000120: 90.4 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:40:06,529",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 1935 for container-id container_1427088391284_0001_01_000120: 110.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:40:09,596",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 1935 for container-id container_1427088391284_0001_01_000120: 132.1 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:40:12,708",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 1935 for container-id container_1427088391284_0001_01_000120: 134.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:40:15,816",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 1935 for container-id container_1427088391284_0001_01_000120: 137.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:40:18,913",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 1935 for container-id container_1427088391284_0001_01_000120: 159.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:40:22,031",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 1935 for container-id container_1427088391284_0001_01_000120: 162.1 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:40:25,117",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 1935 for container-id container_1427088391284_0001_01_000120: 166.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:40:28,175",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 1935 for container-id container_1427088391284_0001_01_000120: 166.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:40:31,216",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 1935 for container-id container_1427088391284_0001_01_000120: 166.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:40:31,440",
        "type": "INFO",
        "app": "SecurityLogger.org.apache.hadoop.ipc.Server",
        "message": " Auth successful for appattempt_1427088391284_0001_000001 (auth:SIMPLE)\n"
    },
    {
        "timestamp": "2015-03-23 05:40:31,449",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Stopping container with container Id: container_1427088391284_0001_01_000120\n"
    },
    {
        "timestamp": "2015-03-23 05:40:31,450",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0001_01_000120 transitioned from RUNNING to KILLING\n"
    },
    {
        "timestamp": "2015-03-23 05:40:31,450",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch",
        "message": " Cleaning up container container_1427088391284_0001_01_000120\n"
    },
    {
        "timestamp": "2015-03-23 05:40:31,451",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tIP=172.31.17.2\tOPERATION=Stop Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0001\tCONTAINERID=container_1427088391284_0001_01_000120\n"
    },
    {
        "timestamp": "2015-03-23 05:40:31,555",
        "type": "WARN",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Exit code from container container_1427088391284_0001_01_000120 is : 143\n"
    },
    {
        "timestamp": "2015-03-23 05:40:31,564",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0001_01_000120 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL\n"
    },
    {
        "timestamp": "2015-03-23 05:40:31,566",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Deleting absolute path : /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0001/container_1427088391284_0001_01_000120\n"
    },
    {
        "timestamp": "2015-03-23 05:40:31,569",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tOPERATION=Container Finished - Killed\tTARGET=ContainerImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0001\tCONTAINERID=container_1427088391284_0001_01_000120\n"
    },
    {
        "timestamp": "2015-03-23 05:40:31,574",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0001_01_000120 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE\n"
    },
    {
        "timestamp": "2015-03-23 05:40:31,574",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Removing container_1427088391284_0001_01_000120 from application application_1427088391284_0001\n"
    },
    {
        "timestamp": "2015-03-23 05:40:31,574",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event CONTAINER_STOP for appId application_1427088391284_0001\n"
    },
    {
        "timestamp": "2015-03-23 05:40:34,217",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Stopping resource-monitoring for container_1427088391284_0001_01_000120\n"
    },
    {
        "timestamp": "2015-03-23 05:40:34,581",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl",
        "message": " Removed completed containers from NM context: [container_1427088391284_0001_01_000120]\n"
    },
    {
        "timestamp": "2015-03-23 05:41:35,217",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0001 transitioned from RUNNING to APPLICATION_RESOURCES_CLEANINGUP\n"
    },
    {
        "timestamp": "2015-03-23 05:41:35,218",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Deleting absolute path : /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0001\n"
    },
    {
        "timestamp": "2015-03-23 05:41:35,222",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event APPLICATION_STOP for appId application_1427088391284_0001\n"
    },
    {
        "timestamp": "2015-03-23 05:41:35,229",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0001 transitioned from APPLICATION_RESOURCES_CLEANINGUP to FINISHED\n"
    },
    {
        "timestamp": "2015-03-23 05:41:35,229",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler",
        "message": " Scheduling Log Deletion for application: application_1427088391284_0001, with delay of 172800 seconds\n"
    },
    {
        "timestamp": "2015-03-23 05:42:11,534",
        "type": "INFO",
        "app": "SecurityLogger.org.apache.hadoop.ipc.Server",
        "message": " Auth successful for appattempt_1427088391284_0002_000001 (auth:SIMPLE)\n"
    },
    {
        "timestamp": "2015-03-23 05:42:11,632",
        "type": "INFO",
        "app": "SecurityLogger.org.apache.hadoop.ipc.Server",
        "message": " Auth successful for appattempt_1427088391284_0002_000001 (auth:SIMPLE)\n"
    },
    {
        "timestamp": "2015-03-23 05:42:11,770",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Start request for container_1427088391284_0002_01_000021 by user ubuntu\n"
    },
    {
        "timestamp": "2015-03-23 05:42:11,771",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Creating a new application reference for app application_1427088391284_0002\n"
    },
    {
        "timestamp": "2015-03-23 05:42:11,771",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0002 transitioned from NEW to INITING\n"
    },
    {
        "timestamp": "2015-03-23 05:42:11,772",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0002 transitioned from INITING to RUNNING\n"
    },
    {
        "timestamp": "2015-03-23 05:42:11,772",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Adding container_1427088391284_0002_01_000021 to application application_1427088391284_0002\n"
    },
    {
        "timestamp": "2015-03-23 05:42:11,773",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0002_01_000021 transitioned from NEW to LOCALIZING\n"
    },
    {
        "timestamp": "2015-03-23 05:42:11,773",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event CONTAINER_INIT for appId application_1427088391284_0002\n"
    },
    {
        "timestamp": "2015-03-23 05:42:11,773",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event APPLICATION_INIT for appId application_1427088391284_0002\n"
    },
    {
        "timestamp": "2015-03-23 05:42:11,773",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got APPLICATION_INIT for service mapreduce_shuffle\n"
    },
    {
        "timestamp": "2015-03-23 05:42:11,773",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Added token for job_1427088391284_0002\n"
    },
    {
        "timestamp": "2015-03-23 05:42:11,774",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/HiBench/Hive/temp/country_codes transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 05:42:11,774",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/HiBench/Hive/temp/user_agents transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 05:42:11,774",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/HiBench/Hive/temp/search_keys transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 05:42:11,774",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0002/job.jar transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 05:42:11,774",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0002/job.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 05:42:11,775",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService",
        "message": " Downloading public rsrc:{ hdfs://172.31.17.135:8120/HiBench/Hive/temp/country_codes, 1427089015096, FILE, null }\n"
    },
    {
        "timestamp": "2015-03-23 05:42:11,775",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tIP=172.31.17.31\tOPERATION=Start Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0002\tCONTAINERID=container_1427088391284_0002_01_000021\n"
    },
    {
        "timestamp": "2015-03-23 05:42:11,776",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService",
        "message": " Downloading public rsrc:{ hdfs://172.31.17.135:8120/HiBench/Hive/temp/user_agents, 1427089013998, FILE, null }\n"
    },
    {
        "timestamp": "2015-03-23 05:42:11,780",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService",
        "message": " Downloading public rsrc:{ hdfs://172.31.17.135:8120/HiBench/Hive/temp/search_keys, 1427089012867, FILE, null }\n"
    },
    {
        "timestamp": "2015-03-23 05:42:11,782",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService",
        "message": " Created localizer for container_1427088391284_0002_01_000021\n"
    },
    {
        "timestamp": "2015-03-23 05:42:11,791",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService",
        "message": " Writing credentials to the nmPrivate file /tmp/hadoop-ubuntu/nm-local-dir/nmPrivate/container_1427088391284_0002_01_000021.tokens. Credentials list: \n"
    },
    {
        "timestamp": "2015-03-23 05:42:11,836",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Start request for container_1427088391284_0002_01_000020 by user ubuntu\n"
    },
    {
        "timestamp": "2015-03-23 05:42:11,843",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Adding container_1427088391284_0002_01_000020 to application application_1427088391284_0002\n"
    },
    {
        "timestamp": "2015-03-23 05:42:11,843",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0002_01_000020 transitioned from NEW to LOCALIZING\n"
    },
    {
        "timestamp": "2015-03-23 05:42:11,843",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event CONTAINER_INIT for appId application_1427088391284_0002\n"
    },
    {
        "timestamp": "2015-03-23 05:42:11,844",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event APPLICATION_INIT for appId application_1427088391284_0002\n"
    },
    {
        "timestamp": "2015-03-23 05:42:11,844",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got APPLICATION_INIT for service mapreduce_shuffle\n"
    },
    {
        "timestamp": "2015-03-23 05:42:11,844",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Added token for job_1427088391284_0002\n"
    },
    {
        "timestamp": "2015-03-23 05:42:11,846",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tIP=172.31.17.31\tOPERATION=Start Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0002\tCONTAINERID=container_1427088391284_0002_01_000020\n"
    },
    {
        "timestamp": "2015-03-23 05:42:11,860",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Initializing user ubuntu\n"
    },
    {
        "timestamp": "2015-03-23 05:42:11,903",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Copying from /tmp/hadoop-ubuntu/nm-local-dir/nmPrivate/container_1427088391284_0002_01_000021.tokens to /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0002/container_1427088391284_0002_01_000021.tokens\n"
    },
    {
        "timestamp": "2015-03-23 05:42:11,904",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Localizer CWD set to /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0002 = file:/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0002\n"
    },
    {
        "timestamp": "2015-03-23 05:42:11,948",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService",
        "message": " Downloading public rsrc:{ hdfs://172.31.17.135:8120/HiBench/Hive/temp/country_codes, 1427089015096, FILE, null }\n"
    },
    {
        "timestamp": "2015-03-23 05:42:11,948",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService",
        "message": " Downloading public rsrc:{ hdfs://172.31.17.135:8120/HiBench/Hive/temp/user_agents, 1427089013998, FILE, null }\n"
    },
    {
        "timestamp": "2015-03-23 05:42:11,949",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService",
        "message": " Downloading public rsrc:{ hdfs://172.31.17.135:8120/HiBench/Hive/temp/search_keys, 1427089012867, FILE, null }\n"
    },
    {
        "timestamp": "2015-03-23 05:42:11,949",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService",
        "message": " Created localizer for container_1427088391284_0002_01_000020\n"
    },
    {
        "timestamp": "2015-03-23 05:42:11,951",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService",
        "message": " Writing credentials to the nmPrivate file /tmp/hadoop-ubuntu/nm-local-dir/nmPrivate/container_1427088391284_0002_01_000020.tokens. Credentials list: \n"
    },
    {
        "timestamp": "2015-03-23 05:42:12,110",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Initializing user ubuntu\n"
    },
    {
        "timestamp": "2015-03-23 05:42:12,114",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Copying from /tmp/hadoop-ubuntu/nm-local-dir/nmPrivate/container_1427088391284_0002_01_000020.tokens to /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0002/container_1427088391284_0002_01_000020.tokens\n"
    },
    {
        "timestamp": "2015-03-23 05:42:12,150",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Localizer CWD set to /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0002 = file:/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0002\n"
    },
    {
        "timestamp": "2015-03-23 05:42:12,311",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/HiBench/Hive/temp/user_agents(->/tmp/hadoop-ubuntu/nm-local-dir/filecache/12/user_agents) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 05:42:12,319",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/HiBench/Hive/temp/search_keys(->/tmp/hadoop-ubuntu/nm-local-dir/filecache/13/search_keys) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 05:42:12,424",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/HiBench/Hive/temp/country_codes(->/tmp/hadoop-ubuntu/nm-local-dir/filecache/11/country_codes) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 05:42:12,550",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0002/job.jar(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0002/filecache/10/job.jar) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 05:42:12,677",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0002/job.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0002/filecache/11/job.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 05:42:12,678",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0002_01_000021 transitioned from LOCALIZING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 05:42:12,678",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0002_01_000020 transitioned from LOCALIZING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 05:42:12,867",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0002_01_000021 transitioned from LOCALIZED to RUNNING\n"
    },
    {
        "timestamp": "2015-03-23 05:42:12,896",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0002_01_000020 transitioned from LOCALIZED to RUNNING\n"
    },
    {
        "timestamp": "2015-03-23 05:42:12,904",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " launchContainer: [bash, /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0002/container_1427088391284_0002_01_000021/default_container_executor.sh]\n"
    },
    {
        "timestamp": "2015-03-23 05:42:12,909",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " launchContainer: [bash, /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0002/container_1427088391284_0002_01_000020/default_container_executor.sh]\n"
    },
    {
        "timestamp": "2015-03-23 05:42:13,243",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Starting resource-monitoring for container_1427088391284_0002_01_000021\n"
    },
    {
        "timestamp": "2015-03-23 05:42:13,244",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Starting resource-monitoring for container_1427088391284_0002_01_000020\n"
    },
    {
        "timestamp": "2015-03-23 05:42:13,361",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2080 for container-id container_1427088391284_0002_01_000021: 5.5 MB of 4 GB physical memory used; 105.6 MB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:42:13,925",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2083 for container-id container_1427088391284_0002_01_000020: 18.3 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:42:16,971",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2080 for container-id container_1427088391284_0002_01_000021: 41.4 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:42:17,169",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2083 for container-id container_1427088391284_0002_01_000020: 44.7 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:42:20,271",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2080 for container-id container_1427088391284_0002_01_000021: 48.3 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:42:20,322",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2083 for container-id container_1427088391284_0002_01_000020: 47.9 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:42:23,354",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2080 for container-id container_1427088391284_0002_01_000021: 57.7 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:42:23,549",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2083 for container-id container_1427088391284_0002_01_000020: 57.8 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:42:26,669",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2080 for container-id container_1427088391284_0002_01_000021: 62.7 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:42:26,721",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2083 for container-id container_1427088391284_0002_01_000020: 68.2 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:42:29,887",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2080 for container-id container_1427088391284_0002_01_000021: 75.9 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:42:29,936",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2083 for container-id container_1427088391284_0002_01_000020: 68.5 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:42:33,005",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2080 for container-id container_1427088391284_0002_01_000021: 83.6 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:42:33,058",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2083 for container-id container_1427088391284_0002_01_000020: 78.8 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:42:36,203",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2080 for container-id container_1427088391284_0002_01_000021: 86.7 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:42:36,334",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2083 for container-id container_1427088391284_0002_01_000020: 86.4 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:42:39,469",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2080 for container-id container_1427088391284_0002_01_000021: 86.5 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:42:39,601",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2083 for container-id container_1427088391284_0002_01_000020: 85.3 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:42:42,769",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2080 for container-id container_1427088391284_0002_01_000021: 89.7 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:42:43,061",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2083 for container-id container_1427088391284_0002_01_000020: 89.8 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:42:46,204",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2080 for container-id container_1427088391284_0002_01_000021: 95.4 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:42:46,532",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2083 for container-id container_1427088391284_0002_01_000020: 93.4 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:42:49,590",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2080 for container-id container_1427088391284_0002_01_000021: 195.7 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:42:49,640",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2083 for container-id container_1427088391284_0002_01_000020: 195.5 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:42:52,713",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2080 for container-id container_1427088391284_0002_01_000021: 196.5 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:42:52,732",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2083 for container-id container_1427088391284_0002_01_000020: 196.6 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:42:55,832",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2080 for container-id container_1427088391284_0002_01_000021: 197.4 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:42:55,992",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2083 for container-id container_1427088391284_0002_01_000020: 198.6 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:42:59,098",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2080 for container-id container_1427088391284_0002_01_000021: 201.9 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:42:59,151",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2083 for container-id container_1427088391284_0002_01_000020: 201.7 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:43:02,343",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2080 for container-id container_1427088391284_0002_01_000021: 201.9 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:43:02,391",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2083 for container-id container_1427088391284_0002_01_000020: 201.8 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:43:03,622",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch",
        "message": " Container container_1427088391284_0002_01_000020 succeeded \n"
    },
    {
        "timestamp": "2015-03-23 05:43:03,623",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0002_01_000020 transitioned from RUNNING to EXITED_WITH_SUCCESS\n"
    },
    {
        "timestamp": "2015-03-23 05:43:03,623",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch",
        "message": " Cleaning up container container_1427088391284_0002_01_000020\n"
    },
    {
        "timestamp": "2015-03-23 05:43:03,874",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch",
        "message": " Container container_1427088391284_0002_01_000021 succeeded \n"
    },
    {
        "timestamp": "2015-03-23 05:43:03,875",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Deleting absolute path : /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0002/container_1427088391284_0002_01_000020\n"
    },
    {
        "timestamp": "2015-03-23 05:43:03,878",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0002_01_000021 transitioned from RUNNING to EXITED_WITH_SUCCESS\n"
    },
    {
        "timestamp": "2015-03-23 05:43:03,878",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tOPERATION=Container Finished - Succeeded\tTARGET=ContainerImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0002\tCONTAINERID=container_1427088391284_0002_01_000020\n"
    },
    {
        "timestamp": "2015-03-23 05:43:03,878",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0002_01_000020 transitioned from EXITED_WITH_SUCCESS to DONE\n"
    },
    {
        "timestamp": "2015-03-23 05:43:03,878",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch",
        "message": " Cleaning up container container_1427088391284_0002_01_000021\n"
    },
    {
        "timestamp": "2015-03-23 05:43:04,008",
        "type": "INFO",
        "app": "SecurityLogger.org.apache.hadoop.ipc.Server",
        "message": " Auth successful for appattempt_1427088391284_0002_000001 (auth:SIMPLE)\n"
    },
    {
        "timestamp": "2015-03-23 05:43:04,010",
        "type": "INFO",
        "app": "SecurityLogger.org.apache.hadoop.ipc.Server",
        "message": " Auth successful for appattempt_1427088391284_0002_000001 (auth:SIMPLE)\n"
    },
    {
        "timestamp": "2015-03-23 05:43:04,113",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Stopping container with container Id: container_1427088391284_0002_01_000020\n"
    },
    {
        "timestamp": "2015-03-23 05:43:04,114",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tIP=172.31.17.31\tOPERATION=Stop Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0002\tCONTAINERID=container_1427088391284_0002_01_000020\n"
    },
    {
        "timestamp": "2015-03-23 05:43:04,114",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Deleting absolute path : /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0002/container_1427088391284_0002_01_000021\n"
    },
    {
        "timestamp": "2015-03-23 05:43:04,117",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Removing container_1427088391284_0002_01_000020 from application application_1427088391284_0002\n"
    },
    {
        "timestamp": "2015-03-23 05:43:04,119",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event CONTAINER_STOP for appId application_1427088391284_0002\n"
    },
    {
        "timestamp": "2015-03-23 05:43:04,119",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tOPERATION=Container Finished - Succeeded\tTARGET=ContainerImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0002\tCONTAINERID=container_1427088391284_0002_01_000021\n"
    },
    {
        "timestamp": "2015-03-23 05:43:04,119",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0002_01_000021 transitioned from EXITED_WITH_SUCCESS to DONE\n"
    },
    {
        "timestamp": "2015-03-23 05:43:04,120",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Removing container_1427088391284_0002_01_000021 from application application_1427088391284_0002\n"
    },
    {
        "timestamp": "2015-03-23 05:43:04,120",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event CONTAINER_STOP for appId application_1427088391284_0002\n"
    },
    {
        "timestamp": "2015-03-23 05:43:04,238",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Stopping container with container Id: container_1427088391284_0002_01_000021\n"
    },
    {
        "timestamp": "2015-03-23 05:43:04,239",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tIP=172.31.17.31\tOPERATION=Stop Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0002\tCONTAINERID=container_1427088391284_0002_01_000021\n"
    },
    {
        "timestamp": "2015-03-23 05:43:05,411",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Stopping resource-monitoring for container_1427088391284_0002_01_000020\n"
    },
    {
        "timestamp": "2015-03-23 05:43:05,411",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Stopping resource-monitoring for container_1427088391284_0002_01_000021\n"
    },
    {
        "timestamp": "2015-03-23 05:43:05,569",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:05,572",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:05,706",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:05,716",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:05,798",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:05,801",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:05,805",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:05,810",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:05,844",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:05,848",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:05,852",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:05,857",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:05,865",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:05,982",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:05,999",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:06,044",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:06,074",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:06,157",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:06,188",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:06,206",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:06,215",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:06,255",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:06,281",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl",
        "message": " Removed completed containers from NM context: [container_1427088391284_0002_01_000020]\n"
    },
    {
        "timestamp": "2015-03-23 05:43:06,296",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:06,299",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:06,304",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:06,460",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:06,547",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:06,550",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:06,629",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:06,663",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:06,722",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:06,754",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:06,852",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:07,005",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:07,023",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:07,091",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:07,094",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:07,158",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:07,186",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:07,270",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:07,288",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl",
        "message": " Removed completed containers from NM context: [container_1427088391284_0002_01_000021]\n"
    },
    {
        "timestamp": "2015-03-23 05:43:07,329",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:07,335",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:07,343",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:07,369",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:07,387",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:07,437",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:07,473",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:07,509",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:07,552",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:07,559",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:07,562",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:07,569",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:07,610",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:07,622",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:07,754",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:07,853",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:07,869",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:07,899",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:07,926",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:08,029",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:08,073",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:08,100",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:08,120",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:08,186",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:08,215",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:08,240",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:08,241",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:08,275",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:08,458",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:08,494",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:08,514",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:08,527",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:08,552",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:08,719",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:08,782",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:08,856",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:08,994",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:09,046",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:09,092",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:09,107",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:09,217",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:10,413",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:10,427",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:10,464",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:10,753",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:12,223",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:12,369",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:12,384",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:14,025",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:15,058",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:15,120",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:15,535",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:15,897",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:16,351",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:16,417",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:17,636",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:18,970",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:43:20,044",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:44:59,048",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0002 transitioned from RUNNING to APPLICATION_RESOURCES_CLEANINGUP\n"
    },
    {
        "timestamp": "2015-03-23 05:44:59,049",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event APPLICATION_STOP for appId application_1427088391284_0002\n"
    },
    {
        "timestamp": "2015-03-23 05:44:59,050",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0002 transitioned from APPLICATION_RESOURCES_CLEANINGUP to FINISHED\n"
    },
    {
        "timestamp": "2015-03-23 05:44:59,050",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler",
        "message": " Scheduling Log Deletion for application: application_1427088391284_0002, with delay of 172800 seconds\n"
    },
    {
        "timestamp": "2015-03-23 05:44:59,050",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Deleting absolute path : /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0002\n"
    },
    {
        "timestamp": "2015-03-23 05:49:30,654",
        "type": "INFO",
        "app": "SecurityLogger.org.apache.hadoop.ipc.Server",
        "message": " Auth successful for appattempt_1427088391284_0003_000001 (auth:SIMPLE)\n"
    },
    {
        "timestamp": "2015-03-23 05:49:30,895",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Start request for container_1427088391284_0003_01_000125 by user ubuntu\n"
    },
    {
        "timestamp": "2015-03-23 05:49:30,896",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Creating a new application reference for app application_1427088391284_0003\n"
    },
    {
        "timestamp": "2015-03-23 05:49:30,896",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0003 transitioned from NEW to INITING\n"
    },
    {
        "timestamp": "2015-03-23 05:49:30,896",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0003 transitioned from INITING to RUNNING\n"
    },
    {
        "timestamp": "2015-03-23 05:49:30,897",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Adding container_1427088391284_0003_01_000125 to application application_1427088391284_0003\n"
    },
    {
        "timestamp": "2015-03-23 05:49:30,897",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0003_01_000125 transitioned from NEW to LOCALIZING\n"
    },
    {
        "timestamp": "2015-03-23 05:49:30,897",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event CONTAINER_INIT for appId application_1427088391284_0003\n"
    },
    {
        "timestamp": "2015-03-23 05:49:30,897",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event APPLICATION_INIT for appId application_1427088391284_0003\n"
    },
    {
        "timestamp": "2015-03-23 05:49:30,897",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got APPLICATION_INIT for service mapreduce_shuffle\n"
    },
    {
        "timestamp": "2015-03-23 05:49:30,898",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Added token for job_1427088391284_0003\n"
    },
    {
        "timestamp": "2015-03-23 05:49:30,898",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/f5ec271c-8d72-4a5f-ba52-affc8897cef1/hive_2015-03-23_05-47-45_838_171229174683052032-1/-mr-10003/be3cccf6-4cad-488d-9cf4-bac33fa90b07/map.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 05:49:30,898",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/f5ec271c-8d72-4a5f-ba52-affc8897cef1/hive_2015-03-23_05-47-45_838_171229174683052032-1/-mr-10003/be3cccf6-4cad-488d-9cf4-bac33fa90b07/reduce.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 05:49:30,898",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0003/job.jar transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 05:49:30,898",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0003/job.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 05:49:30,898",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService",
        "message": " Created localizer for container_1427088391284_0003_01_000125\n"
    },
    {
        "timestamp": "2015-03-23 05:49:30,899",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tIP=172.31.16.246\tOPERATION=Start Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0003\tCONTAINERID=container_1427088391284_0003_01_000125\n"
    },
    {
        "timestamp": "2015-03-23 05:49:30,904",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService",
        "message": " Writing credentials to the nmPrivate file /tmp/hadoop-ubuntu/nm-local-dir/nmPrivate/container_1427088391284_0003_01_000125.tokens. Credentials list: \n"
    },
    {
        "timestamp": "2015-03-23 05:49:30,929",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Initializing user ubuntu\n"
    },
    {
        "timestamp": "2015-03-23 05:49:30,933",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Copying from /tmp/hadoop-ubuntu/nm-local-dir/nmPrivate/container_1427088391284_0003_01_000125.tokens to /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0003/container_1427088391284_0003_01_000125.tokens\n"
    },
    {
        "timestamp": "2015-03-23 05:49:30,933",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Localizer CWD set to /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0003 = file:/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0003\n"
    },
    {
        "timestamp": "2015-03-23 05:49:31,910",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/f5ec271c-8d72-4a5f-ba52-affc8897cef1/hive_2015-03-23_05-47-45_838_171229174683052032-1/-mr-10003/be3cccf6-4cad-488d-9cf4-bac33fa90b07/map.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/filecache/10/map.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 05:49:32,110",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/f5ec271c-8d72-4a5f-ba52-affc8897cef1/hive_2015-03-23_05-47-45_838_171229174683052032-1/-mr-10003/be3cccf6-4cad-488d-9cf4-bac33fa90b07/reduce.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/filecache/11/reduce.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 05:49:33,108",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0003/job.jar(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0003/filecache/10/job.jar) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 05:49:33,173",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0003/job.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0003/filecache/11/job.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 05:49:33,173",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0003_01_000125 transitioned from LOCALIZING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 05:49:33,269",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0003_01_000125 transitioned from LOCALIZED to RUNNING\n"
    },
    {
        "timestamp": "2015-03-23 05:49:33,302",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " launchContainer: [bash, /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0003/container_1427088391284_0003_01_000125/default_container_executor.sh]\n"
    },
    {
        "timestamp": "2015-03-23 05:49:35,426",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Starting resource-monitoring for container_1427088391284_0003_01_000125\n"
    },
    {
        "timestamp": "2015-03-23 05:49:35,520",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2230 for container-id container_1427088391284_0003_01_000125: 46.6 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:49:38,637",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2230 for container-id container_1427088391284_0003_01_000125: 57.5 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:49:41,705",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2230 for container-id container_1427088391284_0003_01_000125: 74.5 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:49:44,773",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2230 for container-id container_1427088391284_0003_01_000125: 86.6 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:49:47,825",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2230 for container-id container_1427088391284_0003_01_000125: 97.0 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:49:50,948",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2230 for container-id container_1427088391284_0003_01_000125: 114.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:49:53,962",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2230 for container-id container_1427088391284_0003_01_000125: 114.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:49:56,976",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2230 for container-id container_1427088391284_0003_01_000125: 114.7 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:50:00,000",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2230 for container-id container_1427088391284_0003_01_000125: 116.2 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:50:03,018",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2230 for container-id container_1427088391284_0003_01_000125: 122.1 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:50:06,032",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2230 for container-id container_1427088391284_0003_01_000125: 122.1 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:50:09,046",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2230 for container-id container_1427088391284_0003_01_000125: 122.1 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:50:12,066",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2230 for container-id container_1427088391284_0003_01_000125: 128.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:50:15,080",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2230 for container-id container_1427088391284_0003_01_000125: 128.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:50:18,094",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2230 for container-id container_1427088391284_0003_01_000125: 128.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:50:21,122",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2230 for container-id container_1427088391284_0003_01_000125: 128.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:50:24,152",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2230 for container-id container_1427088391284_0003_01_000125: 131.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:50:27,166",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2230 for container-id container_1427088391284_0003_01_000125: 131.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:50:30,192",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2230 for container-id container_1427088391284_0003_01_000125: 131.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:50:33,206",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2230 for container-id container_1427088391284_0003_01_000125: 137.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:50:36,256",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2230 for container-id container_1427088391284_0003_01_000125: 137.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:50:39,278",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2230 for container-id container_1427088391284_0003_01_000125: 137.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:50:42,293",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2230 for container-id container_1427088391284_0003_01_000125: 137.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:50:45,306",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2230 for container-id container_1427088391284_0003_01_000125: 137.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:50:48,319",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2230 for container-id container_1427088391284_0003_01_000125: 137.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:50:51,372",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2230 for container-id container_1427088391284_0003_01_000125: 137.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:50:54,396",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2230 for container-id container_1427088391284_0003_01_000125: 138.7 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:50:57,427",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2230 for container-id container_1427088391284_0003_01_000125: 143.1 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:51:00,444",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2230 for container-id container_1427088391284_0003_01_000125: 145.1 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:51:03,457",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2230 for container-id container_1427088391284_0003_01_000125: 148.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:51:06,469",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2230 for container-id container_1427088391284_0003_01_000125: 148.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:51:09,486",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2230 for container-id container_1427088391284_0003_01_000125: 148.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:51:12,499",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2230 for container-id container_1427088391284_0003_01_000125: 148.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:51:15,511",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2230 for container-id container_1427088391284_0003_01_000125: 148.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:51:18,526",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2230 for container-id container_1427088391284_0003_01_000125: 148.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:51:21,539",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2230 for container-id container_1427088391284_0003_01_000125: 148.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:51:24,679",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2230 for container-id container_1427088391284_0003_01_000125: 148.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:51:27,784",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2230 for container-id container_1427088391284_0003_01_000125: 153.2 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:51:30,808",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2230 for container-id container_1427088391284_0003_01_000125: 161.2 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:51:33,876",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2230 for container-id container_1427088391284_0003_01_000125: 163.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:51:36,896",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2230 for container-id container_1427088391284_0003_01_000125: 172.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:51:39,987",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2230 for container-id container_1427088391284_0003_01_000125: 165.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:51:43,051",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2230 for container-id container_1427088391284_0003_01_000125: 165.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:51:46,114",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2230 for container-id container_1427088391284_0003_01_000125: 164.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:51:49,208",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2230 for container-id container_1427088391284_0003_01_000125: 164.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:51:52,249",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2230 for container-id container_1427088391284_0003_01_000125: 164.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:51:55,302",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2230 for container-id container_1427088391284_0003_01_000125: 164.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:51:58,425",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2230 for container-id container_1427088391284_0003_01_000125: 164.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:52:01,454",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2230 for container-id container_1427088391284_0003_01_000125: 164.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:52:04,523",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2230 for container-id container_1427088391284_0003_01_000125: 164.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:52:07,658",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2230 for container-id container_1427088391284_0003_01_000125: 164.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:52:10,687",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2230 for container-id container_1427088391284_0003_01_000125: 164.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:52:13,786",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2230 for container-id container_1427088391284_0003_01_000125: 164.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:52:16,832",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2230 for container-id container_1427088391284_0003_01_000125: 164.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:52:19,910",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2230 for container-id container_1427088391284_0003_01_000125: 164.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:52:22,963",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2230 for container-id container_1427088391284_0003_01_000125: 164.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:52:26,002",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2230 for container-id container_1427088391284_0003_01_000125: 164.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:52:26,426",
        "type": "INFO",
        "app": "SecurityLogger.org.apache.hadoop.ipc.Server",
        "message": " Auth successful for appattempt_1427088391284_0003_000001 (auth:SIMPLE)\n"
    },
    {
        "timestamp": "2015-03-23 05:52:26,429",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Stopping container with container Id: container_1427088391284_0003_01_000125\n"
    },
    {
        "timestamp": "2015-03-23 05:52:26,430",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tIP=172.31.16.246\tOPERATION=Stop Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0003\tCONTAINERID=container_1427088391284_0003_01_000125\n"
    },
    {
        "timestamp": "2015-03-23 05:52:26,430",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0003_01_000125 transitioned from RUNNING to KILLING\n"
    },
    {
        "timestamp": "2015-03-23 05:52:26,430",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch",
        "message": " Cleaning up container container_1427088391284_0003_01_000125\n"
    },
    {
        "timestamp": "2015-03-23 05:52:26,486",
        "type": "WARN",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Exit code from container container_1427088391284_0003_01_000125 is : 143\n"
    },
    {
        "timestamp": "2015-03-23 05:52:26,537",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0003_01_000125 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL\n"
    },
    {
        "timestamp": "2015-03-23 05:52:26,538",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Deleting absolute path : /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0003/container_1427088391284_0003_01_000125\n"
    },
    {
        "timestamp": "2015-03-23 05:52:26,541",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tOPERATION=Container Finished - Killed\tTARGET=ContainerImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0003\tCONTAINERID=container_1427088391284_0003_01_000125\n"
    },
    {
        "timestamp": "2015-03-23 05:52:26,541",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0003_01_000125 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE\n"
    },
    {
        "timestamp": "2015-03-23 05:52:26,541",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Removing container_1427088391284_0003_01_000125 from application application_1427088391284_0003\n"
    },
    {
        "timestamp": "2015-03-23 05:52:26,541",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event CONTAINER_STOP for appId application_1427088391284_0003\n"
    },
    {
        "timestamp": "2015-03-23 05:52:29,002",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Stopping resource-monitoring for container_1427088391284_0003_01_000125\n"
    },
    {
        "timestamp": "2015-03-23 05:52:29,485",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl",
        "message": " Removed completed containers from NM context: [container_1427088391284_0003_01_000125]\n"
    },
    {
        "timestamp": "2015-03-23 05:52:55,807",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0003 transitioned from RUNNING to APPLICATION_RESOURCES_CLEANINGUP\n"
    },
    {
        "timestamp": "2015-03-23 05:52:55,808",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event APPLICATION_STOP for appId application_1427088391284_0003\n"
    },
    {
        "timestamp": "2015-03-23 05:52:55,808",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0003 transitioned from APPLICATION_RESOURCES_CLEANINGUP to FINISHED\n"
    },
    {
        "timestamp": "2015-03-23 05:52:55,808",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler",
        "message": " Scheduling Log Deletion for application: application_1427088391284_0003, with delay of 172800 seconds\n"
    },
    {
        "timestamp": "2015-03-23 05:52:55,809",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Deleting absolute path : /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0003\n"
    },
    {
        "timestamp": "2015-03-23 05:54:35,826",
        "type": "WARN",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Event EventType: KILL_CONTAINER sent to absent container container_1427088391284_0004_01_000202\n"
    },
    {
        "timestamp": "2015-03-23 05:58:14,246",
        "type": "WARN",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Event EventType: FINISH_APPLICATION sent to absent application application_1427088391284_0004\n"
    },
    {
        "timestamp": "2015-03-23 05:58:43,109",
        "type": "INFO",
        "app": "SecurityLogger.org.apache.hadoop.ipc.Server",
        "message": " Auth successful for appattempt_1427088391284_0005_000001 (auth:SIMPLE)\n"
    },
    {
        "timestamp": "2015-03-23 05:58:43,405",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Start request for container_1427088391284_0005_01_000039 by user ubuntu\n"
    },
    {
        "timestamp": "2015-03-23 05:58:43,405",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Creating a new application reference for app application_1427088391284_0005\n"
    },
    {
        "timestamp": "2015-03-23 05:58:43,406",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0005 transitioned from NEW to INITING\n"
    },
    {
        "timestamp": "2015-03-23 05:58:43,406",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0005 transitioned from INITING to RUNNING\n"
    },
    {
        "timestamp": "2015-03-23 05:58:43,406",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Adding container_1427088391284_0005_01_000039 to application application_1427088391284_0005\n"
    },
    {
        "timestamp": "2015-03-23 05:58:43,407",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0005_01_000039 transitioned from NEW to LOCALIZING\n"
    },
    {
        "timestamp": "2015-03-23 05:58:43,407",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event CONTAINER_INIT for appId application_1427088391284_0005\n"
    },
    {
        "timestamp": "2015-03-23 05:58:43,407",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event APPLICATION_INIT for appId application_1427088391284_0005\n"
    },
    {
        "timestamp": "2015-03-23 05:58:43,407",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got APPLICATION_INIT for service mapreduce_shuffle\n"
    },
    {
        "timestamp": "2015-03-23 05:58:43,407",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Added token for job_1427088391284_0005\n"
    },
    {
        "timestamp": "2015-03-23 05:58:43,408",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/bb6b0ec1-0271-43ce-ba81-95dc1ef691ab/hive_2015-03-23_05-53-40_206_2508511279125148864-1/-mr-10007/5f8f1452-50ec-4d03-a5f3-849fcf124ac1/map.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 05:58:43,408",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/bb6b0ec1-0271-43ce-ba81-95dc1ef691ab/hive_2015-03-23_05-53-40_206_2508511279125148864-1/-mr-10007/5f8f1452-50ec-4d03-a5f3-849fcf124ac1/reduce.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 05:58:43,408",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0005/job.jar transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 05:58:43,408",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0005/job.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 05:58:43,408",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService",
        "message": " Created localizer for container_1427088391284_0005_01_000039\n"
    },
    {
        "timestamp": "2015-03-23 05:58:43,408",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tIP=172.31.17.2\tOPERATION=Start Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0005\tCONTAINERID=container_1427088391284_0005_01_000039\n"
    },
    {
        "timestamp": "2015-03-23 05:58:43,414",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService",
        "message": " Writing credentials to the nmPrivate file /tmp/hadoop-ubuntu/nm-local-dir/nmPrivate/container_1427088391284_0005_01_000039.tokens. Credentials list: \n"
    },
    {
        "timestamp": "2015-03-23 05:58:43,458",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Initializing user ubuntu\n"
    },
    {
        "timestamp": "2015-03-23 05:58:43,461",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Copying from /tmp/hadoop-ubuntu/nm-local-dir/nmPrivate/container_1427088391284_0005_01_000039.tokens to /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0005/container_1427088391284_0005_01_000039.tokens\n"
    },
    {
        "timestamp": "2015-03-23 05:58:43,462",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Localizer CWD set to /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0005 = file:/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0005\n"
    },
    {
        "timestamp": "2015-03-23 05:58:43,644",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/bb6b0ec1-0271-43ce-ba81-95dc1ef691ab/hive_2015-03-23_05-53-40_206_2508511279125148864-1/-mr-10007/5f8f1452-50ec-4d03-a5f3-849fcf124ac1/map.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/filecache/12/map.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 05:58:43,733",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/bb6b0ec1-0271-43ce-ba81-95dc1ef691ab/hive_2015-03-23_05-53-40_206_2508511279125148864-1/-mr-10007/5f8f1452-50ec-4d03-a5f3-849fcf124ac1/reduce.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/filecache/13/reduce.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 05:58:45,087",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0005/job.jar(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0005/filecache/10/job.jar) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 05:58:45,144",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0005/job.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0005/filecache/11/job.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 05:58:45,144",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0005_01_000039 transitioned from LOCALIZING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 05:58:45,213",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0005_01_000039 transitioned from LOCALIZED to RUNNING\n"
    },
    {
        "timestamp": "2015-03-23 05:58:45,223",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " launchContainer: [bash, /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0005/container_1427088391284_0005_01_000039/default_container_executor.sh]\n"
    },
    {
        "timestamp": "2015-03-23 05:58:47,017",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Starting resource-monitoring for container_1427088391284_0005_01_000039\n"
    },
    {
        "timestamp": "2015-03-23 05:58:47,055",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2381 for container-id container_1427088391284_0005_01_000039: 44.3 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:58:50,081",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2381 for container-id container_1427088391284_0005_01_000039: 57.5 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:58:53,124",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2381 for container-id container_1427088391284_0005_01_000039: 75.1 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:58:56,144",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2381 for container-id container_1427088391284_0005_01_000039: 84.4 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:58:59,167",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2381 for container-id container_1427088391284_0005_01_000039: 94.3 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:59:02,258",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2381 for container-id container_1427088391284_0005_01_000039: 105.1 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:59:05,356",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2381 for container-id container_1427088391284_0005_01_000039: 207.3 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:59:08,396",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2381 for container-id container_1427088391284_0005_01_000039: 208.0 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:59:11,488",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2381 for container-id container_1427088391284_0005_01_000039: 208.7 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 05:59:11,544",
        "type": "INFO",
        "app": "SecurityLogger.org.apache.hadoop.ipc.Server",
        "message": " Auth successful for appattempt_1427088391284_0005_000001 (auth:SIMPLE)\n"
    },
    {
        "timestamp": "2015-03-23 05:59:11,550",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Stopping container with container Id: container_1427088391284_0005_01_000039\n"
    },
    {
        "timestamp": "2015-03-23 05:59:11,550",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tIP=172.31.17.2\tOPERATION=Stop Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0005\tCONTAINERID=container_1427088391284_0005_01_000039\n"
    },
    {
        "timestamp": "2015-03-23 05:59:11,551",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0005_01_000039 transitioned from RUNNING to KILLING\n"
    },
    {
        "timestamp": "2015-03-23 05:59:11,551",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch",
        "message": " Cleaning up container container_1427088391284_0005_01_000039\n"
    },
    {
        "timestamp": "2015-03-23 05:59:11,743",
        "type": "WARN",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Exit code from container container_1427088391284_0005_01_000039 is : 143\n"
    },
    {
        "timestamp": "2015-03-23 05:59:11,761",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0005_01_000039 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL\n"
    },
    {
        "timestamp": "2015-03-23 05:59:11,762",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Deleting absolute path : /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0005/container_1427088391284_0005_01_000039\n"
    },
    {
        "timestamp": "2015-03-23 05:59:11,800",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tOPERATION=Container Finished - Killed\tTARGET=ContainerImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0005\tCONTAINERID=container_1427088391284_0005_01_000039\n"
    },
    {
        "timestamp": "2015-03-23 05:59:11,800",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0005_01_000039 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE\n"
    },
    {
        "timestamp": "2015-03-23 05:59:11,800",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Removing container_1427088391284_0005_01_000039 from application application_1427088391284_0005\n"
    },
    {
        "timestamp": "2015-03-23 05:59:11,800",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event CONTAINER_STOP for appId application_1427088391284_0005\n"
    },
    {
        "timestamp": "2015-03-23 05:59:14,489",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Stopping resource-monitoring for container_1427088391284_0005_01_000039\n"
    },
    {
        "timestamp": "2015-03-23 05:59:15,799",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl",
        "message": " Removed completed containers from NM context: [container_1427088391284_0005_01_000039]\n"
    },
    {
        "timestamp": "2015-03-23 05:59:31,553",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:59:31,989",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:59:32,003",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:59:32,184",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:59:32,490",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:59:32,962",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:59:32,975",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:59:33,022",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:59:33,032",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:59:33,118",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:59:33,178",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:59:33,246",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:59:33,324",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:59:33,379",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:59:33,430",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:59:33,542",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:59:33,568",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:59:33,588",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:59:33,650",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:59:33,707",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:59:33,724",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:59:33,732",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:59:33,775",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:59:33,859",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:59:33,862",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:59:33,865",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:59:34,017",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:59:34,030",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:59:34,079",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:59:34,217",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:59:34,258",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:59:34,274",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:59:34,320",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:59:34,390",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:59:34,455",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:59:34,498",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:59:34,543",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:59:34,613",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:59:34,625",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:59:34,782",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:59:34,829",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:59:34,871",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:59:35,112",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:59:35,179",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:59:35,391",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:59:35,647",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:59:36,308",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 05:59:46,609",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 06:00:11,842",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0005 transitioned from RUNNING to APPLICATION_RESOURCES_CLEANINGUP\n"
    },
    {
        "timestamp": "2015-03-23 06:00:11,843",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event APPLICATION_STOP for appId application_1427088391284_0005\n"
    },
    {
        "timestamp": "2015-03-23 06:00:11,843",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0005 transitioned from APPLICATION_RESOURCES_CLEANINGUP to FINISHED\n"
    },
    {
        "timestamp": "2015-03-23 06:00:11,843",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler",
        "message": " Scheduling Log Deletion for application: application_1427088391284_0005, with delay of 172800 seconds\n"
    },
    {
        "timestamp": "2015-03-23 06:00:11,844",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Deleting absolute path : /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0005\n"
    },
    {
        "timestamp": "2015-03-23 06:00:38,902",
        "type": "WARN",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Event EventType: KILL_CONTAINER sent to absent container container_1427088391284_0006_01_000056\n"
    },
    {
        "timestamp": "2015-03-23 06:02:03,233",
        "type": "WARN",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Event EventType: FINISH_APPLICATION sent to absent application application_1427088391284_0006\n"
    },
    {
        "timestamp": "2015-03-23 06:04:38,026",
        "type": "INFO",
        "app": "SecurityLogger.org.apache.hadoop.ipc.Server",
        "message": " Auth successful for appattempt_1427088391284_0007_000001 (auth:SIMPLE)\n"
    },
    {
        "timestamp": "2015-03-23 06:04:38,188",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Start request for container_1427088391284_0007_01_000087 by user ubuntu\n"
    },
    {
        "timestamp": "2015-03-23 06:04:38,188",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Creating a new application reference for app application_1427088391284_0007\n"
    },
    {
        "timestamp": "2015-03-23 06:04:38,189",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0007 transitioned from NEW to INITING\n"
    },
    {
        "timestamp": "2015-03-23 06:04:38,189",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0007 transitioned from INITING to RUNNING\n"
    },
    {
        "timestamp": "2015-03-23 06:04:38,189",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Adding container_1427088391284_0007_01_000087 to application application_1427088391284_0007\n"
    },
    {
        "timestamp": "2015-03-23 06:04:38,190",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0007_01_000087 transitioned from NEW to LOCALIZING\n"
    },
    {
        "timestamp": "2015-03-23 06:04:38,190",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event CONTAINER_INIT for appId application_1427088391284_0007\n"
    },
    {
        "timestamp": "2015-03-23 06:04:38,190",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event APPLICATION_INIT for appId application_1427088391284_0007\n"
    },
    {
        "timestamp": "2015-03-23 06:04:38,190",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got APPLICATION_INIT for service mapreduce_shuffle\n"
    },
    {
        "timestamp": "2015-03-23 06:04:38,190",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Added token for job_1427088391284_0007\n"
    },
    {
        "timestamp": "2015-03-23 06:04:38,190",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/b640e064-df3f-495d-a8d3-b2d6296c231b/hive_2015-03-23_06-02-57_173_6938534248492483294-1/-mr-10003/fb002c26-9af8-4524-869f-177ecd3af86d/map.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 06:04:38,190",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/b640e064-df3f-495d-a8d3-b2d6296c231b/hive_2015-03-23_06-02-57_173_6938534248492483294-1/-mr-10003/fb002c26-9af8-4524-869f-177ecd3af86d/reduce.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 06:04:38,191",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0007/job.jar transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 06:04:38,191",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0007/job.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 06:04:38,191",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService",
        "message": " Created localizer for container_1427088391284_0007_01_000087\n"
    },
    {
        "timestamp": "2015-03-23 06:04:38,191",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tIP=172.31.17.42\tOPERATION=Start Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0007\tCONTAINERID=container_1427088391284_0007_01_000087\n"
    },
    {
        "timestamp": "2015-03-23 06:04:38,196",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService",
        "message": " Writing credentials to the nmPrivate file /tmp/hadoop-ubuntu/nm-local-dir/nmPrivate/container_1427088391284_0007_01_000087.tokens. Credentials list: \n"
    },
    {
        "timestamp": "2015-03-23 06:04:38,216",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Initializing user ubuntu\n"
    },
    {
        "timestamp": "2015-03-23 06:04:38,244",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Copying from /tmp/hadoop-ubuntu/nm-local-dir/nmPrivate/container_1427088391284_0007_01_000087.tokens to /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0007/container_1427088391284_0007_01_000087.tokens\n"
    },
    {
        "timestamp": "2015-03-23 06:04:38,244",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Localizer CWD set to /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0007 = file:/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0007\n"
    },
    {
        "timestamp": "2015-03-23 06:04:38,443",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/b640e064-df3f-495d-a8d3-b2d6296c231b/hive_2015-03-23_06-02-57_173_6938534248492483294-1/-mr-10003/fb002c26-9af8-4524-869f-177ecd3af86d/map.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/filecache/14/map.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 06:04:38,512",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/b640e064-df3f-495d-a8d3-b2d6296c231b/hive_2015-03-23_06-02-57_173_6938534248492483294-1/-mr-10003/fb002c26-9af8-4524-869f-177ecd3af86d/reduce.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/filecache/15/reduce.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 06:04:39,158",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0007/job.jar(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0007/filecache/10/job.jar) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 06:04:39,347",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0007/job.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0007/filecache/11/job.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 06:04:39,348",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0007_01_000087 transitioned from LOCALIZING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 06:04:39,575",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0007_01_000087 transitioned from LOCALIZED to RUNNING\n"
    },
    {
        "timestamp": "2015-03-23 06:04:39,582",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " launchContainer: [bash, /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0007/container_1427088391284_0007_01_000087/default_container_executor.sh]\n"
    },
    {
        "timestamp": "2015-03-23 06:04:41,501",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Starting resource-monitoring for container_1427088391284_0007_01_000087\n"
    },
    {
        "timestamp": "2015-03-23 06:04:41,593",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2488 for container-id container_1427088391284_0007_01_000087: 42.6 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:04:44,730",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2488 for container-id container_1427088391284_0007_01_000087: 57.3 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:04:47,798",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2488 for container-id container_1427088391284_0007_01_000087: 75.3 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:04:50,841",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2488 for container-id container_1427088391284_0007_01_000087: 89.2 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:04:53,895",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2488 for container-id container_1427088391284_0007_01_000087: 94.9 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:04:56,945",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2488 for container-id container_1427088391284_0007_01_000087: 111.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:04:59,961",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2488 for container-id container_1427088391284_0007_01_000087: 111.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:05:02,973",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2488 for container-id container_1427088391284_0007_01_000087: 112.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:05:05,998",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2488 for container-id container_1427088391284_0007_01_000087: 118.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:05:09,010",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2488 for container-id container_1427088391284_0007_01_000087: 118.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:05:12,022",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2488 for container-id container_1427088391284_0007_01_000087: 118.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:05:15,037",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2488 for container-id container_1427088391284_0007_01_000087: 126.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:05:18,050",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2488 for container-id container_1427088391284_0007_01_000087: 126.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:05:21,065",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2488 for container-id container_1427088391284_0007_01_000087: 126.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:05:24,076",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2488 for container-id container_1427088391284_0007_01_000087: 126.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:05:27,092",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2488 for container-id container_1427088391284_0007_01_000087: 126.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:05:30,104",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2488 for container-id container_1427088391284_0007_01_000087: 129.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:05:33,115",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2488 for container-id container_1427088391284_0007_01_000087: 129.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:05:36,132",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2488 for container-id container_1427088391284_0007_01_000087: 129.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:05:39,144",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2488 for container-id container_1427088391284_0007_01_000087: 129.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:05:42,158",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2488 for container-id container_1427088391284_0007_01_000087: 133.2 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:05:45,174",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2488 for container-id container_1427088391284_0007_01_000087: 133.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:05:48,187",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2488 for container-id container_1427088391284_0007_01_000087: 133.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:05:51,205",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2488 for container-id container_1427088391284_0007_01_000087: 133.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:05:54,221",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2488 for container-id container_1427088391284_0007_01_000087: 133.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:05:57,233",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2488 for container-id container_1427088391284_0007_01_000087: 133.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:06:00,246",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2488 for container-id container_1427088391284_0007_01_000087: 136.1 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:06:03,259",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2488 for container-id container_1427088391284_0007_01_000087: 138.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:06:06,275",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2488 for container-id container_1427088391284_0007_01_000087: 143.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:06:09,287",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2488 for container-id container_1427088391284_0007_01_000087: 143.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:06:12,298",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2488 for container-id container_1427088391284_0007_01_000087: 143.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:06:15,314",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2488 for container-id container_1427088391284_0007_01_000087: 143.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:06:18,326",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2488 for container-id container_1427088391284_0007_01_000087: 143.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:06:21,344",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2488 for container-id container_1427088391284_0007_01_000087: 143.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:06:24,360",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2488 for container-id container_1427088391284_0007_01_000087: 143.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:06:27,372",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2488 for container-id container_1427088391284_0007_01_000087: 143.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:06:30,383",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2488 for container-id container_1427088391284_0007_01_000087: 143.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:06:33,399",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2488 for container-id container_1427088391284_0007_01_000087: 143.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:06:36,411",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2488 for container-id container_1427088391284_0007_01_000087: 147.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:06:39,423",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2488 for container-id container_1427088391284_0007_01_000087: 147.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:06:42,434",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2488 for container-id container_1427088391284_0007_01_000087: 147.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:06:45,451",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2488 for container-id container_1427088391284_0007_01_000087: 147.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:06:48,463",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2488 for container-id container_1427088391284_0007_01_000087: 147.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:06:51,474",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2488 for container-id container_1427088391284_0007_01_000087: 147.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:06:54,490",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2488 for container-id container_1427088391284_0007_01_000087: 147.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:06:57,502",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2488 for container-id container_1427088391284_0007_01_000087: 147.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:07:00,514",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2488 for container-id container_1427088391284_0007_01_000087: 147.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:07:03,530",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2488 for container-id container_1427088391284_0007_01_000087: 147.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:07:06,544",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2488 for container-id container_1427088391284_0007_01_000087: 147.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:07:09,555",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2488 for container-id container_1427088391284_0007_01_000087: 149.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:07:12,570",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2488 for container-id container_1427088391284_0007_01_000087: 149.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:07:15,582",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2488 for container-id container_1427088391284_0007_01_000087: 149.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:07:18,593",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2488 for container-id container_1427088391284_0007_01_000087: 149.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:07:21,612",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2488 for container-id container_1427088391284_0007_01_000087: 149.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:07:24,624",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2488 for container-id container_1427088391284_0007_01_000087: 149.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:07:27,635",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2488 for container-id container_1427088391284_0007_01_000087: 149.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:07:30,646",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2488 for container-id container_1427088391284_0007_01_000087: 149.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:07:33,662",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2488 for container-id container_1427088391284_0007_01_000087: 149.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:07:36,675",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2488 for container-id container_1427088391284_0007_01_000087: 149.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:07:39,687",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2488 for container-id container_1427088391284_0007_01_000087: 149.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:07:42,702",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2488 for container-id container_1427088391284_0007_01_000087: 149.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:07:45,713",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2488 for container-id container_1427088391284_0007_01_000087: 149.7 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:07:48,724",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2488 for container-id container_1427088391284_0007_01_000087: 149.7 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:07:51,829",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2488 for container-id container_1427088391284_0007_01_000087: 149.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:07:54,917",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2488 for container-id container_1427088391284_0007_01_000087: 156.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:07:57,950",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2488 for container-id container_1427088391284_0007_01_000087: 160.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:08:01,002",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2488 for container-id container_1427088391284_0007_01_000087: 176.2 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:08:04,030",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2488 for container-id container_1427088391284_0007_01_000087: 177.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:08:07,066",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2488 for container-id container_1427088391284_0007_01_000087: 169.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:08:10,191",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2488 for container-id container_1427088391284_0007_01_000087: 169.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:08:13,307",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2488 for container-id container_1427088391284_0007_01_000087: 169.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:08:16,333",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2488 for container-id container_1427088391284_0007_01_000087: 164.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:08:19,352",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2488 for container-id container_1427088391284_0007_01_000087: 164.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:08:22,414",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2488 for container-id container_1427088391284_0007_01_000087: 164.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:08:25,450",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2488 for container-id container_1427088391284_0007_01_000087: 164.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:08:28,493",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2488 for container-id container_1427088391284_0007_01_000087: 164.2 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:08:31,563",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2488 for container-id container_1427088391284_0007_01_000087: 164.2 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:08:34,584",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2488 for container-id container_1427088391284_0007_01_000087: 164.2 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:08:37,601",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2488 for container-id container_1427088391284_0007_01_000087: 164.2 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:08:40,652",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2488 for container-id container_1427088391284_0007_01_000087: 164.2 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:08:43,683",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2488 for container-id container_1427088391284_0007_01_000087: 164.2 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:08:46,775",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2488 for container-id container_1427088391284_0007_01_000087: 164.2 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:08:49,863",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2488 for container-id container_1427088391284_0007_01_000087: 164.2 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:08:52,880",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2488 for container-id container_1427088391284_0007_01_000087: 164.1 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:08:52,998",
        "type": "INFO",
        "app": "SecurityLogger.org.apache.hadoop.ipc.Server",
        "message": " Auth successful for appattempt_1427088391284_0007_000001 (auth:SIMPLE)\n"
    },
    {
        "timestamp": "2015-03-23 06:08:53,001",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Stopping container with container Id: container_1427088391284_0007_01_000087\n"
    },
    {
        "timestamp": "2015-03-23 06:08:53,042",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0007_01_000087 transitioned from RUNNING to KILLING\n"
    },
    {
        "timestamp": "2015-03-23 06:08:53,042",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch",
        "message": " Cleaning up container container_1427088391284_0007_01_000087\n"
    },
    {
        "timestamp": "2015-03-23 06:08:53,042",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tIP=172.31.17.42\tOPERATION=Stop Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0007\tCONTAINERID=container_1427088391284_0007_01_000087\n"
    },
    {
        "timestamp": "2015-03-23 06:08:53,115",
        "type": "WARN",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Exit code from container container_1427088391284_0007_01_000087 is : 143\n"
    },
    {
        "timestamp": "2015-03-23 06:08:53,131",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0007_01_000087 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL\n"
    },
    {
        "timestamp": "2015-03-23 06:08:53,132",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Deleting absolute path : /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0007/container_1427088391284_0007_01_000087\n"
    },
    {
        "timestamp": "2015-03-23 06:08:53,158",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tOPERATION=Container Finished - Killed\tTARGET=ContainerImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0007\tCONTAINERID=container_1427088391284_0007_01_000087\n"
    },
    {
        "timestamp": "2015-03-23 06:08:53,158",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0007_01_000087 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE\n"
    },
    {
        "timestamp": "2015-03-23 06:08:53,158",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Removing container_1427088391284_0007_01_000087 from application application_1427088391284_0007\n"
    },
    {
        "timestamp": "2015-03-23 06:08:53,159",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event CONTAINER_STOP for appId application_1427088391284_0007\n"
    },
    {
        "timestamp": "2015-03-23 06:08:55,881",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Stopping resource-monitoring for container_1427088391284_0007_01_000087\n"
    },
    {
        "timestamp": "2015-03-23 06:08:56,074",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl",
        "message": " Removed completed containers from NM context: [container_1427088391284_0007_01_000087]\n"
    },
    {
        "timestamp": "2015-03-23 06:10:15,487",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0007 transitioned from RUNNING to APPLICATION_RESOURCES_CLEANINGUP\n"
    },
    {
        "timestamp": "2015-03-23 06:10:15,488",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event APPLICATION_STOP for appId application_1427088391284_0007\n"
    },
    {
        "timestamp": "2015-03-23 06:10:15,488",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0007 transitioned from APPLICATION_RESOURCES_CLEANINGUP to FINISHED\n"
    },
    {
        "timestamp": "2015-03-23 06:10:15,488",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler",
        "message": " Scheduling Log Deletion for application: application_1427088391284_0007, with delay of 172800 seconds\n"
    },
    {
        "timestamp": "2015-03-23 06:10:15,488",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Deleting absolute path : /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0007\n"
    },
    {
        "timestamp": "2015-03-23 06:27:59,092",
        "type": "WARN",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Event EventType: KILL_CONTAINER sent to absent container container_1427088391284_0012_01_000260\n"
    },
    {
        "timestamp": "2015-03-23 06:31:22,696",
        "type": "WARN",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Event EventType: FINISH_APPLICATION sent to absent application application_1427088391284_0012\n"
    },
    {
        "timestamp": "2015-03-23 06:37:03,212",
        "type": "WARN",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Event EventType: KILL_CONTAINER sent to absent container container_1427088391284_0015_01_000121\n"
    },
    {
        "timestamp": "2015-03-23 06:38:00,375",
        "type": "INFO",
        "app": "SecurityLogger.org.apache.hadoop.ipc.Server",
        "message": " Auth successful for appattempt_1427088391284_0015_000001 (auth:SIMPLE)\n"
    },
    {
        "timestamp": "2015-03-23 06:38:00,672",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Start request for container_1427088391284_0015_01_000192 by user ubuntu\n"
    },
    {
        "timestamp": "2015-03-23 06:38:00,672",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Creating a new application reference for app application_1427088391284_0015\n"
    },
    {
        "timestamp": "2015-03-23 06:38:00,673",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0015 transitioned from NEW to INITING\n"
    },
    {
        "timestamp": "2015-03-23 06:38:00,673",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0015 transitioned from INITING to RUNNING\n"
    },
    {
        "timestamp": "2015-03-23 06:38:00,673",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Adding container_1427088391284_0015_01_000192 to application application_1427088391284_0015\n"
    },
    {
        "timestamp": "2015-03-23 06:38:00,674",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0015_01_000192 transitioned from NEW to LOCALIZING\n"
    },
    {
        "timestamp": "2015-03-23 06:38:00,674",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event CONTAINER_INIT for appId application_1427088391284_0015\n"
    },
    {
        "timestamp": "2015-03-23 06:38:00,674",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event APPLICATION_INIT for appId application_1427088391284_0015\n"
    },
    {
        "timestamp": "2015-03-23 06:38:00,674",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got APPLICATION_INIT for service mapreduce_shuffle\n"
    },
    {
        "timestamp": "2015-03-23 06:38:00,674",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Added token for job_1427088391284_0015\n"
    },
    {
        "timestamp": "2015-03-23 06:38:00,674",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/b498e214-a485-40a7-8c2c-910403601753/hive_2015-03-23_06-36-14_721_5214718705881551155-1/-mr-10003/e1efc90b-b6d2-459c-ace4-9fbc2a057d02/map.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 06:38:00,675",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/b498e214-a485-40a7-8c2c-910403601753/hive_2015-03-23_06-36-14_721_5214718705881551155-1/-mr-10003/e1efc90b-b6d2-459c-ace4-9fbc2a057d02/reduce.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 06:38:00,675",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0015/job.jar transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 06:38:00,675",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0015/job.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 06:38:00,675",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService",
        "message": " Created localizer for container_1427088391284_0015_01_000192\n"
    },
    {
        "timestamp": "2015-03-23 06:38:00,675",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tIP=172.31.17.131\tOPERATION=Start Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0015\tCONTAINERID=container_1427088391284_0015_01_000192\n"
    },
    {
        "timestamp": "2015-03-23 06:38:00,680",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService",
        "message": " Writing credentials to the nmPrivate file /tmp/hadoop-ubuntu/nm-local-dir/nmPrivate/container_1427088391284_0015_01_000192.tokens. Credentials list: \n"
    },
    {
        "timestamp": "2015-03-23 06:38:00,701",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Initializing user ubuntu\n"
    },
    {
        "timestamp": "2015-03-23 06:38:00,704",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Copying from /tmp/hadoop-ubuntu/nm-local-dir/nmPrivate/container_1427088391284_0015_01_000192.tokens to /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0015/container_1427088391284_0015_01_000192.tokens\n"
    },
    {
        "timestamp": "2015-03-23 06:38:00,704",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Localizer CWD set to /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0015 = file:/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0015\n"
    },
    {
        "timestamp": "2015-03-23 06:38:00,903",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/b498e214-a485-40a7-8c2c-910403601753/hive_2015-03-23_06-36-14_721_5214718705881551155-1/-mr-10003/e1efc90b-b6d2-459c-ace4-9fbc2a057d02/map.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/filecache/16/map.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 06:38:00,961",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/b498e214-a485-40a7-8c2c-910403601753/hive_2015-03-23_06-36-14_721_5214718705881551155-1/-mr-10003/e1efc90b-b6d2-459c-ace4-9fbc2a057d02/reduce.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/filecache/17/reduce.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 06:38:01,744",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0015/job.jar(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0015/filecache/10/job.jar) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 06:38:01,842",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0015/job.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0015/filecache/11/job.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 06:38:01,843",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0015_01_000192 transitioned from LOCALIZING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 06:38:01,911",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0015_01_000192 transitioned from LOCALIZED to RUNNING\n"
    },
    {
        "timestamp": "2015-03-23 06:38:01,919",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " launchContainer: [bash, /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0015/container_1427088391284_0015_01_000192/default_container_executor.sh]\n"
    },
    {
        "timestamp": "2015-03-23 06:38:01,968",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Starting resource-monitoring for container_1427088391284_0015_01_000192\n"
    },
    {
        "timestamp": "2015-03-23 06:38:05,025",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2688 for container-id container_1427088391284_0015_01_000192: 49.2 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:38:08,214",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2688 for container-id container_1427088391284_0015_01_000192: 59.7 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:38:11,282",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2688 for container-id container_1427088391284_0015_01_000192: 78.1 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:38:14,366",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2688 for container-id container_1427088391284_0015_01_000192: 81.9 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:38:17,400",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2688 for container-id container_1427088391284_0015_01_000192: 94.7 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:38:20,428",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2688 for container-id container_1427088391284_0015_01_000192: 114.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:38:23,439",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2688 for container-id container_1427088391284_0015_01_000192: 114.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:38:26,449",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2688 for container-id container_1427088391284_0015_01_000192: 120.1 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:38:29,467",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2688 for container-id container_1427088391284_0015_01_000192: 120.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:38:32,477",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2688 for container-id container_1427088391284_0015_01_000192: 123.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:38:35,487",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2688 for container-id container_1427088391284_0015_01_000192: 125.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:38:38,503",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2688 for container-id container_1427088391284_0015_01_000192: 129.1 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:38:41,513",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2688 for container-id container_1427088391284_0015_01_000192: 129.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:38:44,524",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2688 for container-id container_1427088391284_0015_01_000192: 129.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:38:47,538",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2688 for container-id container_1427088391284_0015_01_000192: 129.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:38:50,549",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2688 for container-id container_1427088391284_0015_01_000192: 136.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:38:53,561",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2688 for container-id container_1427088391284_0015_01_000192: 136.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:38:56,579",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2688 for container-id container_1427088391284_0015_01_000192: 136.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:38:59,589",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2688 for container-id container_1427088391284_0015_01_000192: 136.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:39:02,600",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2688 for container-id container_1427088391284_0015_01_000192: 136.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:39:05,614",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2688 for container-id container_1427088391284_0015_01_000192: 136.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:39:08,624",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2688 for container-id container_1427088391284_0015_01_000192: 136.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:39:11,634",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2688 for container-id container_1427088391284_0015_01_000192: 137.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:39:14,648",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2688 for container-id container_1427088391284_0015_01_000192: 137.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:39:17,665",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2688 for container-id container_1427088391284_0015_01_000192: 137.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:39:20,675",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2688 for container-id container_1427088391284_0015_01_000192: 137.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:39:23,688",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2688 for container-id container_1427088391284_0015_01_000192: 141.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:39:26,698",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2688 for container-id container_1427088391284_0015_01_000192: 141.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:39:29,708",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2688 for container-id container_1427088391284_0015_01_000192: 141.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:39:32,723",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2688 for container-id container_1427088391284_0015_01_000192: 141.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:39:35,733",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2688 for container-id container_1427088391284_0015_01_000192: 141.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:39:38,743",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2688 for container-id container_1427088391284_0015_01_000192: 141.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:39:41,759",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2688 for container-id container_1427088391284_0015_01_000192: 141.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:39:44,769",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2688 for container-id container_1427088391284_0015_01_000192: 143.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:39:47,805",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2688 for container-id container_1427088391284_0015_01_000192: 143.2 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:39:50,956",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2688 for container-id container_1427088391284_0015_01_000192: 143.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:39:53,978",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2688 for container-id container_1427088391284_0015_01_000192: 150.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:39:56,998",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2688 for container-id container_1427088391284_0015_01_000192: 154.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:40:00,088",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2688 for container-id container_1427088391284_0015_01_000192: 164.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:40:03,107",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2688 for container-id container_1427088391284_0015_01_000192: 157.7 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:40:06,136",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2688 for container-id container_1427088391284_0015_01_000192: 157.7 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:40:09,191",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2688 for container-id container_1427088391284_0015_01_000192: 155.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:40:12,211",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2688 for container-id container_1427088391284_0015_01_000192: 155.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:40:15,260",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2688 for container-id container_1427088391284_0015_01_000192: 155.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:40:18,355",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2688 for container-id container_1427088391284_0015_01_000192: 155.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:40:21,390",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2688 for container-id container_1427088391284_0015_01_000192: 155.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:40:24,418",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2688 for container-id container_1427088391284_0015_01_000192: 155.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:40:27,596",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2688 for container-id container_1427088391284_0015_01_000192: 155.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:40:30,617",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2688 for container-id container_1427088391284_0015_01_000192: 155.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:40:33,763",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2688 for container-id container_1427088391284_0015_01_000192: 155.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:40:36,807",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2688 for container-id container_1427088391284_0015_01_000192: 155.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:40:39,843",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2688 for container-id container_1427088391284_0015_01_000192: 155.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:40:42,874",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2688 for container-id container_1427088391284_0015_01_000192: 155.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:40:45,266",
        "type": "INFO",
        "app": "SecurityLogger.org.apache.hadoop.ipc.Server",
        "message": " Auth successful for appattempt_1427088391284_0015_000001 (auth:SIMPLE)\n"
    },
    {
        "timestamp": "2015-03-23 06:40:45,269",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Stopping container with container Id: container_1427088391284_0015_01_000192\n"
    },
    {
        "timestamp": "2015-03-23 06:40:45,269",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tIP=172.31.17.131\tOPERATION=Stop Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0015\tCONTAINERID=container_1427088391284_0015_01_000192\n"
    },
    {
        "timestamp": "2015-03-23 06:40:45,269",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0015_01_000192 transitioned from RUNNING to KILLING\n"
    },
    {
        "timestamp": "2015-03-23 06:40:45,269",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch",
        "message": " Cleaning up container container_1427088391284_0015_01_000192\n"
    },
    {
        "timestamp": "2015-03-23 06:40:45,336",
        "type": "WARN",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Exit code from container container_1427088391284_0015_01_000192 is : 143\n"
    },
    {
        "timestamp": "2015-03-23 06:40:45,384",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0015_01_000192 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL\n"
    },
    {
        "timestamp": "2015-03-23 06:40:45,385",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Deleting absolute path : /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0015/container_1427088391284_0015_01_000192\n"
    },
    {
        "timestamp": "2015-03-23 06:40:45,387",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tOPERATION=Container Finished - Killed\tTARGET=ContainerImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0015\tCONTAINERID=container_1427088391284_0015_01_000192\n"
    },
    {
        "timestamp": "2015-03-23 06:40:45,387",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0015_01_000192 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE\n"
    },
    {
        "timestamp": "2015-03-23 06:40:45,387",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Removing container_1427088391284_0015_01_000192 from application application_1427088391284_0015\n"
    },
    {
        "timestamp": "2015-03-23 06:40:45,387",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event CONTAINER_STOP for appId application_1427088391284_0015\n"
    },
    {
        "timestamp": "2015-03-23 06:40:45,874",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Stopping resource-monitoring for container_1427088391284_0015_01_000192\n"
    },
    {
        "timestamp": "2015-03-23 06:40:48,277",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl",
        "message": " Removed completed containers from NM context: [container_1427088391284_0015_01_000192]\n"
    },
    {
        "timestamp": "2015-03-23 06:41:39,426",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0015 transitioned from RUNNING to APPLICATION_RESOURCES_CLEANINGUP\n"
    },
    {
        "timestamp": "2015-03-23 06:41:39,427",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Deleting absolute path : /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0015\n"
    },
    {
        "timestamp": "2015-03-23 06:41:39,428",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event APPLICATION_STOP for appId application_1427088391284_0015\n"
    },
    {
        "timestamp": "2015-03-23 06:41:39,428",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0015 transitioned from APPLICATION_RESOURCES_CLEANINGUP to FINISHED\n"
    },
    {
        "timestamp": "2015-03-23 06:41:39,428",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler",
        "message": " Scheduling Log Deletion for application: application_1427088391284_0015, with delay of 172800 seconds\n"
    },
    {
        "timestamp": "2015-03-23 06:43:55,902",
        "type": "INFO",
        "app": "SecurityLogger.org.apache.hadoop.ipc.Server",
        "message": " Auth successful for appattempt_1427088391284_0016_000001 (auth:SIMPLE)\n"
    },
    {
        "timestamp": "2015-03-23 06:43:55,920",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Start request for container_1427088391284_0016_01_000173 by user ubuntu\n"
    },
    {
        "timestamp": "2015-03-23 06:43:55,920",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Creating a new application reference for app application_1427088391284_0016\n"
    },
    {
        "timestamp": "2015-03-23 06:43:55,920",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0016 transitioned from NEW to INITING\n"
    },
    {
        "timestamp": "2015-03-23 06:43:55,921",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0016 transitioned from INITING to RUNNING\n"
    },
    {
        "timestamp": "2015-03-23 06:43:55,921",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Adding container_1427088391284_0016_01_000173 to application application_1427088391284_0016\n"
    },
    {
        "timestamp": "2015-03-23 06:43:55,921",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0016_01_000173 transitioned from NEW to LOCALIZING\n"
    },
    {
        "timestamp": "2015-03-23 06:43:55,921",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event CONTAINER_INIT for appId application_1427088391284_0016\n"
    },
    {
        "timestamp": "2015-03-23 06:43:55,921",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event APPLICATION_INIT for appId application_1427088391284_0016\n"
    },
    {
        "timestamp": "2015-03-23 06:43:55,921",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got APPLICATION_INIT for service mapreduce_shuffle\n"
    },
    {
        "timestamp": "2015-03-23 06:43:55,922",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Added token for job_1427088391284_0016\n"
    },
    {
        "timestamp": "2015-03-23 06:43:55,922",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/8fb0ef47-2d9d-41dc-8417-8849ff01fa3c/hive_2015-03-23_06-42-32_899_7081738137692778050-1/-mr-10005/402de6e0-23b5-4b15-9527-feea59ac5274/map.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 06:43:55,922",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/8fb0ef47-2d9d-41dc-8417-8849ff01fa3c/hive_2015-03-23_06-42-32_899_7081738137692778050-1/-mr-10005/402de6e0-23b5-4b15-9527-feea59ac5274/reduce.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 06:43:55,922",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0016/job.jar transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 06:43:55,922",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0016/job.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 06:43:55,922",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService",
        "message": " Created localizer for container_1427088391284_0016_01_000173\n"
    },
    {
        "timestamp": "2015-03-23 06:43:55,923",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tIP=172.31.17.97\tOPERATION=Start Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0016\tCONTAINERID=container_1427088391284_0016_01_000173\n"
    },
    {
        "timestamp": "2015-03-23 06:43:55,927",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService",
        "message": " Writing credentials to the nmPrivate file /tmp/hadoop-ubuntu/nm-local-dir/nmPrivate/container_1427088391284_0016_01_000173.tokens. Credentials list: \n"
    },
    {
        "timestamp": "2015-03-23 06:43:55,950",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Initializing user ubuntu\n"
    },
    {
        "timestamp": "2015-03-23 06:43:55,978",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Copying from /tmp/hadoop-ubuntu/nm-local-dir/nmPrivate/container_1427088391284_0016_01_000173.tokens to /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0016/container_1427088391284_0016_01_000173.tokens\n"
    },
    {
        "timestamp": "2015-03-23 06:43:55,978",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Localizer CWD set to /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0016 = file:/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0016\n"
    },
    {
        "timestamp": "2015-03-23 06:43:56,113",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/8fb0ef47-2d9d-41dc-8417-8849ff01fa3c/hive_2015-03-23_06-42-32_899_7081738137692778050-1/-mr-10005/402de6e0-23b5-4b15-9527-feea59ac5274/map.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/filecache/18/map.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 06:43:56,156",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/8fb0ef47-2d9d-41dc-8417-8849ff01fa3c/hive_2015-03-23_06-42-32_899_7081738137692778050-1/-mr-10005/402de6e0-23b5-4b15-9527-feea59ac5274/reduce.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/filecache/19/reduce.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 06:43:56,634",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0016/job.jar(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0016/filecache/10/job.jar) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 06:43:56,699",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0016/job.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0016/filecache/11/job.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 06:43:56,699",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0016_01_000173 transitioned from LOCALIZING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 06:43:56,775",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0016_01_000173 transitioned from LOCALIZED to RUNNING\n"
    },
    {
        "timestamp": "2015-03-23 06:43:56,806",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " launchContainer: [bash, /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0016/container_1427088391284_0016_01_000173/default_container_executor.sh]\n"
    },
    {
        "timestamp": "2015-03-23 06:43:57,882",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Starting resource-monitoring for container_1427088391284_0016_01_000173\n"
    },
    {
        "timestamp": "2015-03-23 06:43:57,964",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2803 for container-id container_1427088391284_0016_01_000173: 40.6 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:44:01,069",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2803 for container-id container_1427088391284_0016_01_000173: 54.6 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:44:04,168",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2803 for container-id container_1427088391284_0016_01_000173: 73.1 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:44:07,182",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2803 for container-id container_1427088391284_0016_01_000173: 81.8 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:44:10,320",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2803 for container-id container_1427088391284_0016_01_000173: 94.2 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:44:13,333",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2803 for container-id container_1427088391284_0016_01_000173: 100.2 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:44:16,343",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2803 for container-id container_1427088391284_0016_01_000173: 108.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:44:19,386",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2803 for container-id container_1427088391284_0016_01_000173: 104.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:44:22,396",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2803 for container-id container_1427088391284_0016_01_000173: 106.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:44:25,406",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2803 for container-id container_1427088391284_0016_01_000173: 106.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:44:28,420",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2803 for container-id container_1427088391284_0016_01_000173: 109.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:44:31,438",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2803 for container-id container_1427088391284_0016_01_000173: 114.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:44:34,448",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2803 for container-id container_1427088391284_0016_01_000173: 114.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:44:37,462",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2803 for container-id container_1427088391284_0016_01_000173: 114.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:44:40,472",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2803 for container-id container_1427088391284_0016_01_000173: 114.7 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:44:43,482",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2803 for container-id container_1427088391284_0016_01_000173: 118.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:44:46,495",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2803 for container-id container_1427088391284_0016_01_000173: 118.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:44:49,505",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2803 for container-id container_1427088391284_0016_01_000173: 118.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:44:52,515",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2803 for container-id container_1427088391284_0016_01_000173: 119.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:44:55,528",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2803 for container-id container_1427088391284_0016_01_000173: 120.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:44:58,538",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2803 for container-id container_1427088391284_0016_01_000173: 120.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:45:01,550",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2803 for container-id container_1427088391284_0016_01_000173: 120.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:45:04,561",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2803 for container-id container_1427088391284_0016_01_000173: 121.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:45:07,574",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2803 for container-id container_1427088391284_0016_01_000173: 121.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:45:10,587",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2803 for container-id container_1427088391284_0016_01_000173: 121.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:45:13,598",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2803 for container-id container_1427088391284_0016_01_000173: 121.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:45:16,634",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2803 for container-id container_1427088391284_0016_01_000173: 122.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:45:19,653",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2803 for container-id container_1427088391284_0016_01_000173: 122.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:45:22,667",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2803 for container-id container_1427088391284_0016_01_000173: 122.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:45:25,678",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2803 for container-id container_1427088391284_0016_01_000173: 122.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:45:28,690",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2803 for container-id container_1427088391284_0016_01_000173: 122.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:45:31,744",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2803 for container-id container_1427088391284_0016_01_000173: 122.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:45:34,762",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2803 for container-id container_1427088391284_0016_01_000173: 122.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:45:37,800",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2803 for container-id container_1427088391284_0016_01_000173: 122.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:45:40,818",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2803 for container-id container_1427088391284_0016_01_000173: 122.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:45:43,948",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2803 for container-id container_1427088391284_0016_01_000173: 124.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:45:46,978",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2803 for container-id container_1427088391284_0016_01_000173: 124.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:45:50,040",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2803 for container-id container_1427088391284_0016_01_000173: 124.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:45:53,081",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2803 for container-id container_1427088391284_0016_01_000173: 124.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:45:56,119",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2803 for container-id container_1427088391284_0016_01_000173: 124.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:45:59,148",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2803 for container-id container_1427088391284_0016_01_000173: 124.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:46:02,201",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2803 for container-id container_1427088391284_0016_01_000173: 124.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:46:05,225",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2803 for container-id container_1427088391284_0016_01_000173: 124.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:46:08,260",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2803 for container-id container_1427088391284_0016_01_000173: 124.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:46:11,382",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2803 for container-id container_1427088391284_0016_01_000173: 124.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:46:14,440",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2803 for container-id container_1427088391284_0016_01_000173: 124.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:46:17,491",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2803 for container-id container_1427088391284_0016_01_000173: 124.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:46:20,534",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2803 for container-id container_1427088391284_0016_01_000173: 124.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:46:23,734",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2803 for container-id container_1427088391284_0016_01_000173: 124.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:46:26,871",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2803 for container-id container_1427088391284_0016_01_000173: 124.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:46:29,967",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2803 for container-id container_1427088391284_0016_01_000173: 124.1 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:46:33,009",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2803 for container-id container_1427088391284_0016_01_000173: 124.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:46:36,155",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2803 for container-id container_1427088391284_0016_01_000173: 129.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:46:39,216",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2803 for container-id container_1427088391284_0016_01_000173: 131.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:46:42,238",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2803 for container-id container_1427088391284_0016_01_000173: 131.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:46:45,343",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2803 for container-id container_1427088391284_0016_01_000173: 131.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:46:48,465",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2803 for container-id container_1427088391284_0016_01_000173: 133.2 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:46:51,554",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 2803 for container-id container_1427088391284_0016_01_000173: 136.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:46:52,334",
        "type": "INFO",
        "app": "SecurityLogger.org.apache.hadoop.ipc.Server",
        "message": " Auth successful for appattempt_1427088391284_0016_000001 (auth:SIMPLE)\n"
    },
    {
        "timestamp": "2015-03-23 06:46:52,340",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Stopping container with container Id: container_1427088391284_0016_01_000173\n"
    },
    {
        "timestamp": "2015-03-23 06:46:52,340",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tIP=172.31.17.97\tOPERATION=Stop Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0016\tCONTAINERID=container_1427088391284_0016_01_000173\n"
    },
    {
        "timestamp": "2015-03-23 06:46:52,345",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0016_01_000173 transitioned from RUNNING to KILLING\n"
    },
    {
        "timestamp": "2015-03-23 06:46:52,345",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch",
        "message": " Cleaning up container container_1427088391284_0016_01_000173\n"
    },
    {
        "timestamp": "2015-03-23 06:46:52,502",
        "type": "WARN",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Exit code from container container_1427088391284_0016_01_000173 is : 143\n"
    },
    {
        "timestamp": "2015-03-23 06:46:52,506",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0016_01_000173 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL\n"
    },
    {
        "timestamp": "2015-03-23 06:46:52,507",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Deleting absolute path : /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0016/container_1427088391284_0016_01_000173\n"
    },
    {
        "timestamp": "2015-03-23 06:46:52,509",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tOPERATION=Container Finished - Killed\tTARGET=ContainerImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0016\tCONTAINERID=container_1427088391284_0016_01_000173\n"
    },
    {
        "timestamp": "2015-03-23 06:46:52,509",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0016_01_000173 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE\n"
    },
    {
        "timestamp": "2015-03-23 06:46:52,509",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Removing container_1427088391284_0016_01_000173 from application application_1427088391284_0016\n"
    },
    {
        "timestamp": "2015-03-23 06:46:52,509",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event CONTAINER_STOP for appId application_1427088391284_0016\n"
    },
    {
        "timestamp": "2015-03-23 06:46:54,555",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Stopping resource-monitoring for container_1427088391284_0016_01_000173\n"
    },
    {
        "timestamp": "2015-03-23 06:46:55,353",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl",
        "message": " Removed completed containers from NM context: [container_1427088391284_0016_01_000173]\n"
    },
    {
        "timestamp": "2015-03-23 06:47:09,433",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0016 transitioned from RUNNING to APPLICATION_RESOURCES_CLEANINGUP\n"
    },
    {
        "timestamp": "2015-03-23 06:47:09,434",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event APPLICATION_STOP for appId application_1427088391284_0016\n"
    },
    {
        "timestamp": "2015-03-23 06:47:09,434",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0016 transitioned from APPLICATION_RESOURCES_CLEANINGUP to FINISHED\n"
    },
    {
        "timestamp": "2015-03-23 06:47:09,434",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler",
        "message": " Scheduling Log Deletion for application: application_1427088391284_0016, with delay of 172800 seconds\n"
    },
    {
        "timestamp": "2015-03-23 06:47:09,435",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Deleting absolute path : /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0016\n"
    },
    {
        "timestamp": "2015-03-23 06:47:39,398",
        "type": "INFO",
        "app": "SecurityLogger.org.apache.hadoop.ipc.Server",
        "message": " Auth successful for appattempt_1427088391284_0017_000001 (auth:SIMPLE)\n"
    },
    {
        "timestamp": "2015-03-23 06:47:39,706",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Start request for container_1427088391284_0017_01_000038 by user ubuntu\n"
    },
    {
        "timestamp": "2015-03-23 06:47:39,706",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Creating a new application reference for app application_1427088391284_0017\n"
    },
    {
        "timestamp": "2015-03-23 06:47:39,707",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0017 transitioned from NEW to INITING\n"
    },
    {
        "timestamp": "2015-03-23 06:47:39,707",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0017 transitioned from INITING to RUNNING\n"
    },
    {
        "timestamp": "2015-03-23 06:47:39,708",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Adding container_1427088391284_0017_01_000038 to application application_1427088391284_0017\n"
    },
    {
        "timestamp": "2015-03-23 06:47:39,708",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0017_01_000038 transitioned from NEW to LOCALIZING\n"
    },
    {
        "timestamp": "2015-03-23 06:47:39,709",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event CONTAINER_INIT for appId application_1427088391284_0017\n"
    },
    {
        "timestamp": "2015-03-23 06:47:39,709",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event APPLICATION_INIT for appId application_1427088391284_0017\n"
    },
    {
        "timestamp": "2015-03-23 06:47:39,709",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got APPLICATION_INIT for service mapreduce_shuffle\n"
    },
    {
        "timestamp": "2015-03-23 06:47:39,709",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Added token for job_1427088391284_0017\n"
    },
    {
        "timestamp": "2015-03-23 06:47:39,709",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/8fb0ef47-2d9d-41dc-8417-8849ff01fa3c/hive_2015-03-23_06-42-32_899_7081738137692778050-1/-mr-10007/84735a1b-d8f4-4465-90fe-8fa13faf6772/map.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 06:47:39,709",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/8fb0ef47-2d9d-41dc-8417-8849ff01fa3c/hive_2015-03-23_06-42-32_899_7081738137692778050-1/-mr-10007/84735a1b-d8f4-4465-90fe-8fa13faf6772/reduce.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 06:47:39,709",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0017/job.jar transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 06:47:39,710",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0017/job.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 06:47:39,710",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService",
        "message": " Created localizer for container_1427088391284_0017_01_000038\n"
    },
    {
        "timestamp": "2015-03-23 06:47:39,710",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tIP=172.31.17.71\tOPERATION=Start Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0017\tCONTAINERID=container_1427088391284_0017_01_000038\n"
    },
    {
        "timestamp": "2015-03-23 06:47:39,715",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService",
        "message": " Writing credentials to the nmPrivate file /tmp/hadoop-ubuntu/nm-local-dir/nmPrivate/container_1427088391284_0017_01_000038.tokens. Credentials list: \n"
    },
    {
        "timestamp": "2015-03-23 06:47:39,736",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Initializing user ubuntu\n"
    },
    {
        "timestamp": "2015-03-23 06:47:39,763",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Copying from /tmp/hadoop-ubuntu/nm-local-dir/nmPrivate/container_1427088391284_0017_01_000038.tokens to /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0017/container_1427088391284_0017_01_000038.tokens\n"
    },
    {
        "timestamp": "2015-03-23 06:47:39,763",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Localizer CWD set to /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0017 = file:/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0017\n"
    },
    {
        "timestamp": "2015-03-23 06:47:39,940",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/8fb0ef47-2d9d-41dc-8417-8849ff01fa3c/hive_2015-03-23_06-42-32_899_7081738137692778050-1/-mr-10007/84735a1b-d8f4-4465-90fe-8fa13faf6772/map.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/filecache/20/map.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 06:47:40,001",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/8fb0ef47-2d9d-41dc-8417-8849ff01fa3c/hive_2015-03-23_06-42-32_899_7081738137692778050-1/-mr-10007/84735a1b-d8f4-4465-90fe-8fa13faf6772/reduce.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/filecache/21/reduce.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 06:47:40,884",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0017/job.jar(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0017/filecache/10/job.jar) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 06:47:40,943",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0017/job.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0017/filecache/11/job.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 06:47:40,943",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0017_01_000038 transitioned from LOCALIZING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 06:47:41,027",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0017_01_000038 transitioned from LOCALIZED to RUNNING\n"
    },
    {
        "timestamp": "2015-03-23 06:47:41,034",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " launchContainer: [bash, /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0017/container_1427088391284_0017_01_000038/default_container_executor.sh]\n"
    },
    {
        "timestamp": "2015-03-23 06:47:42,558",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Starting resource-monitoring for container_1427088391284_0017_01_000038\n"
    },
    {
        "timestamp": "2015-03-23 06:47:42,570",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3082 for container-id container_1427088391284_0017_01_000038: 41.5 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:47:45,749",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3082 for container-id container_1427088391284_0017_01_000038: 56.3 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:47:48,814",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3082 for container-id container_1427088391284_0017_01_000038: 74.3 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:47:51,901",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3082 for container-id container_1427088391284_0017_01_000038: 82.7 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:47:54,946",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3082 for container-id container_1427088391284_0017_01_000038: 93.6 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:47:57,997",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3082 for container-id container_1427088391284_0017_01_000038: 105.1 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:48:01,097",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3082 for container-id container_1427088391284_0017_01_000038: 207.8 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:48:04,238",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3082 for container-id container_1427088391284_0017_01_000038: 208.6 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:48:07,370",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3082 for container-id container_1427088391284_0017_01_000038: 209.0 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:48:07,770",
        "type": "INFO",
        "app": "SecurityLogger.org.apache.hadoop.ipc.Server",
        "message": " Auth successful for appattempt_1427088391284_0017_000001 (auth:SIMPLE)\n"
    },
    {
        "timestamp": "2015-03-23 06:48:07,822",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Stopping container with container Id: container_1427088391284_0017_01_000038\n"
    },
    {
        "timestamp": "2015-03-23 06:48:07,822",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0017_01_000038 transitioned from RUNNING to KILLING\n"
    },
    {
        "timestamp": "2015-03-23 06:48:07,822",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch",
        "message": " Cleaning up container container_1427088391284_0017_01_000038\n"
    },
    {
        "timestamp": "2015-03-23 06:48:07,823",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tIP=172.31.17.71\tOPERATION=Stop Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0017\tCONTAINERID=container_1427088391284_0017_01_000038\n"
    },
    {
        "timestamp": "2015-03-23 06:48:07,880",
        "type": "WARN",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Exit code from container container_1427088391284_0017_01_000038 is : 143\n"
    },
    {
        "timestamp": "2015-03-23 06:48:07,898",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0017_01_000038 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL\n"
    },
    {
        "timestamp": "2015-03-23 06:48:07,898",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Deleting absolute path : /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0017/container_1427088391284_0017_01_000038\n"
    },
    {
        "timestamp": "2015-03-23 06:48:07,925",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tOPERATION=Container Finished - Killed\tTARGET=ContainerImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0017\tCONTAINERID=container_1427088391284_0017_01_000038\n"
    },
    {
        "timestamp": "2015-03-23 06:48:07,925",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0017_01_000038 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE\n"
    },
    {
        "timestamp": "2015-03-23 06:48:07,925",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Removing container_1427088391284_0017_01_000038 from application application_1427088391284_0017\n"
    },
    {
        "timestamp": "2015-03-23 06:48:07,925",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event CONTAINER_STOP for appId application_1427088391284_0017\n"
    },
    {
        "timestamp": "2015-03-23 06:48:10,370",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Stopping resource-monitoring for container_1427088391284_0017_01_000038\n"
    },
    {
        "timestamp": "2015-03-23 06:48:11,597",
        "type": "INFO",
        "app": "SecurityLogger.org.apache.hadoop.ipc.Server",
        "message": " Auth successful for appattempt_1427088391284_0017_000001 (auth:SIMPLE)\n"
    },
    {
        "timestamp": "2015-03-23 06:48:11,842",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl",
        "message": " Removed completed containers from NM context: [container_1427088391284_0017_01_000038]\n"
    },
    {
        "timestamp": "2015-03-23 06:48:12,401",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Start request for container_1427088391284_0017_01_000096 by user ubuntu\n"
    },
    {
        "timestamp": "2015-03-23 06:48:12,402",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Adding container_1427088391284_0017_01_000096 to application application_1427088391284_0017\n"
    },
    {
        "timestamp": "2015-03-23 06:48:12,402",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0017_01_000096 transitioned from NEW to LOCALIZING\n"
    },
    {
        "timestamp": "2015-03-23 06:48:12,402",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event CONTAINER_INIT for appId application_1427088391284_0017\n"
    },
    {
        "timestamp": "2015-03-23 06:48:12,402",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event APPLICATION_INIT for appId application_1427088391284_0017\n"
    },
    {
        "timestamp": "2015-03-23 06:48:12,402",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got APPLICATION_INIT for service mapreduce_shuffle\n"
    },
    {
        "timestamp": "2015-03-23 06:48:12,402",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Added token for job_1427088391284_0017\n"
    },
    {
        "timestamp": "2015-03-23 06:48:12,403",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0017_01_000096 transitioned from LOCALIZING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 06:48:12,410",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tIP=172.31.17.71\tOPERATION=Start Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0017\tCONTAINERID=container_1427088391284_0017_01_000096\n"
    },
    {
        "timestamp": "2015-03-23 06:48:12,461",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0017_01_000096 transitioned from LOCALIZED to RUNNING\n"
    },
    {
        "timestamp": "2015-03-23 06:48:12,468",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " launchContainer: [bash, /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0017/container_1427088391284_0017_01_000096/default_container_executor.sh]\n"
    },
    {
        "timestamp": "2015-03-23 06:48:13,371",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Starting resource-monitoring for container_1427088391284_0017_01_000096\n"
    },
    {
        "timestamp": "2015-03-23 06:48:13,384",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3128 for container-id container_1427088391284_0017_01_000096: 33.3 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:48:16,434",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3128 for container-id container_1427088391284_0017_01_000096: 53.9 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:48:19,474",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3128 for container-id container_1427088391284_0017_01_000096: 71.8 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:48:22,500",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3128 for container-id container_1427088391284_0017_01_000096: 80.5 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:48:25,528",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3128 for container-id container_1427088391284_0017_01_000096: 94.0 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:48:27,311",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 06:48:27,886",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 06:48:27,950",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 06:48:28,003",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 06:48:28,077",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 06:48:28,173",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 06:48:28,175",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 06:48:28,275",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 06:48:28,610",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3128 for container-id container_1427088391284_0017_01_000096: 101.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:48:28,615",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 06:48:28,721",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 06:48:28,797",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 06:48:29,065",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 06:48:29,145",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 06:48:29,219",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 06:48:29,267",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 06:48:29,269",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 06:48:29,296",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 06:48:29,519",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 06:48:29,674",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 06:48:29,676",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 06:48:29,686",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 06:48:29,770",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 06:48:29,772",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 06:48:29,888",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 06:48:29,961",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 06:48:29,963",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 06:48:29,967",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 06:48:30,009",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 06:48:30,018",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 06:48:30,155",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 06:48:30,214",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 06:48:30,250",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 06:48:30,490",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 06:48:30,601",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 06:48:30,739",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 06:48:30,800",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 06:48:30,826",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 06:48:30,828",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 06:48:30,887",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 06:48:31,086",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 06:48:31,462",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 06:48:31,644",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 06:48:31,648",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3128 for container-id container_1427088391284_0017_01_000096: 106.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:48:32,313",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 06:48:34,750",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3128 for container-id container_1427088391284_0017_01_000096: 111.1 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:48:35,632",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 06:48:37,792",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3128 for container-id container_1427088391284_0017_01_000096: 127.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:48:40,815",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3128 for container-id container_1427088391284_0017_01_000096: 126.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:48:41,452",
        "type": "INFO",
        "app": "SecurityLogger.org.apache.hadoop.ipc.Server",
        "message": " Auth successful for appattempt_1427088391284_0017_000001 (auth:SIMPLE)\n"
    },
    {
        "timestamp": "2015-03-23 06:48:41,486",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Stopping container with container Id: container_1427088391284_0017_01_000096\n"
    },
    {
        "timestamp": "2015-03-23 06:48:41,486",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tIP=172.31.17.71\tOPERATION=Stop Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0017\tCONTAINERID=container_1427088391284_0017_01_000096\n"
    },
    {
        "timestamp": "2015-03-23 06:48:41,487",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0017_01_000096 transitioned from RUNNING to KILLING\n"
    },
    {
        "timestamp": "2015-03-23 06:48:41,487",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch",
        "message": " Cleaning up container container_1427088391284_0017_01_000096\n"
    },
    {
        "timestamp": "2015-03-23 06:48:41,589",
        "type": "WARN",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Exit code from container container_1427088391284_0017_01_000096 is : 143\n"
    },
    {
        "timestamp": "2015-03-23 06:48:41,629",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0017_01_000096 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL\n"
    },
    {
        "timestamp": "2015-03-23 06:48:41,630",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Deleting absolute path : /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0017/container_1427088391284_0017_01_000096\n"
    },
    {
        "timestamp": "2015-03-23 06:48:41,632",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tOPERATION=Container Finished - Killed\tTARGET=ContainerImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0017\tCONTAINERID=container_1427088391284_0017_01_000096\n"
    },
    {
        "timestamp": "2015-03-23 06:48:41,632",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0017_01_000096 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE\n"
    },
    {
        "timestamp": "2015-03-23 06:48:41,632",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Removing container_1427088391284_0017_01_000096 from application application_1427088391284_0017\n"
    },
    {
        "timestamp": "2015-03-23 06:48:41,632",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event CONTAINER_STOP for appId application_1427088391284_0017\n"
    },
    {
        "timestamp": "2015-03-23 06:48:43,127",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 06:48:43,815",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Stopping resource-monitoring for container_1427088391284_0017_01_000096\n"
    },
    {
        "timestamp": "2015-03-23 06:48:44,494",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl",
        "message": " Removed completed containers from NM context: [container_1427088391284_0017_01_000096]\n"
    },
    {
        "timestamp": "2015-03-23 06:48:44,877",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 06:48:45,000",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 06:48:46,102",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 06:49:05,022",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 06:49:17,568",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0017 transitioned from RUNNING to APPLICATION_RESOURCES_CLEANINGUP\n"
    },
    {
        "timestamp": "2015-03-23 06:49:17,569",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event APPLICATION_STOP for appId application_1427088391284_0017\n"
    },
    {
        "timestamp": "2015-03-23 06:49:17,569",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0017 transitioned from APPLICATION_RESOURCES_CLEANINGUP to FINISHED\n"
    },
    {
        "timestamp": "2015-03-23 06:49:17,569",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler",
        "message": " Scheduling Log Deletion for application: application_1427088391284_0017, with delay of 172800 seconds\n"
    },
    {
        "timestamp": "2015-03-23 06:49:17,569",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Deleting absolute path : /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0017\n"
    },
    {
        "timestamp": "2015-03-23 06:54:24,674",
        "type": "INFO",
        "app": "SecurityLogger.org.apache.hadoop.ipc.Server",
        "message": " Auth successful for appattempt_1427088391284_0019_000001 (auth:SIMPLE)\n"
    },
    {
        "timestamp": "2015-03-23 06:54:24,755",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Start request for container_1427088391284_0019_01_000165 by user ubuntu\n"
    },
    {
        "timestamp": "2015-03-23 06:54:24,755",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Creating a new application reference for app application_1427088391284_0019\n"
    },
    {
        "timestamp": "2015-03-23 06:54:24,756",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0019 transitioned from NEW to INITING\n"
    },
    {
        "timestamp": "2015-03-23 06:54:24,756",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0019 transitioned from INITING to RUNNING\n"
    },
    {
        "timestamp": "2015-03-23 06:54:24,756",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Adding container_1427088391284_0019_01_000165 to application application_1427088391284_0019\n"
    },
    {
        "timestamp": "2015-03-23 06:54:24,757",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0019_01_000165 transitioned from NEW to LOCALIZING\n"
    },
    {
        "timestamp": "2015-03-23 06:54:24,757",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event CONTAINER_INIT for appId application_1427088391284_0019\n"
    },
    {
        "timestamp": "2015-03-23 06:54:24,757",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event APPLICATION_INIT for appId application_1427088391284_0019\n"
    },
    {
        "timestamp": "2015-03-23 06:54:24,757",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got APPLICATION_INIT for service mapreduce_shuffle\n"
    },
    {
        "timestamp": "2015-03-23 06:54:24,757",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Added token for job_1427088391284_0019\n"
    },
    {
        "timestamp": "2015-03-23 06:54:24,757",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/075f4c60-c47c-45cb-a507-d4dee367457f/hive_2015-03-23_06-52-37_054_3560792335653124532-1/-mr-10003/cc576741-cb2d-4056-84b7-904abd2535a9/map.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 06:54:24,758",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/075f4c60-c47c-45cb-a507-d4dee367457f/hive_2015-03-23_06-52-37_054_3560792335653124532-1/-mr-10003/cc576741-cb2d-4056-84b7-904abd2535a9/reduce.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 06:54:24,758",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0019/job.jar transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 06:54:24,758",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0019/job.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 06:54:24,758",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService",
        "message": " Created localizer for container_1427088391284_0019_01_000165\n"
    },
    {
        "timestamp": "2015-03-23 06:54:24,758",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tIP=172.31.17.131\tOPERATION=Start Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0019\tCONTAINERID=container_1427088391284_0019_01_000165\n"
    },
    {
        "timestamp": "2015-03-23 06:54:24,763",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService",
        "message": " Writing credentials to the nmPrivate file /tmp/hadoop-ubuntu/nm-local-dir/nmPrivate/container_1427088391284_0019_01_000165.tokens. Credentials list: \n"
    },
    {
        "timestamp": "2015-03-23 06:54:24,810",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Initializing user ubuntu\n"
    },
    {
        "timestamp": "2015-03-23 06:54:24,813",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Copying from /tmp/hadoop-ubuntu/nm-local-dir/nmPrivate/container_1427088391284_0019_01_000165.tokens to /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0019/container_1427088391284_0019_01_000165.tokens\n"
    },
    {
        "timestamp": "2015-03-23 06:54:24,813",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Localizer CWD set to /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0019 = file:/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0019\n"
    },
    {
        "timestamp": "2015-03-23 06:54:24,961",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/075f4c60-c47c-45cb-a507-d4dee367457f/hive_2015-03-23_06-52-37_054_3560792335653124532-1/-mr-10003/cc576741-cb2d-4056-84b7-904abd2535a9/map.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/filecache/22/map.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 06:54:25,056",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/075f4c60-c47c-45cb-a507-d4dee367457f/hive_2015-03-23_06-52-37_054_3560792335653124532-1/-mr-10003/cc576741-cb2d-4056-84b7-904abd2535a9/reduce.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/filecache/23/reduce.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 06:54:26,299",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0019/job.jar(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0019/filecache/10/job.jar) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 06:54:26,388",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0019/job.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0019/filecache/11/job.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 06:54:26,389",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0019_01_000165 transitioned from LOCALIZING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 06:54:26,456",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0019_01_000165 transitioned from LOCALIZED to RUNNING\n"
    },
    {
        "timestamp": "2015-03-23 06:54:26,466",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " launchContainer: [bash, /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0019/container_1427088391284_0019_01_000165/default_container_executor.sh]\n"
    },
    {
        "timestamp": "2015-03-23 06:54:28,828",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Starting resource-monitoring for container_1427088391284_0019_01_000165\n"
    },
    {
        "timestamp": "2015-03-23 06:54:28,844",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3238 for container-id container_1427088391284_0019_01_000165: 48.1 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:54:31,878",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3238 for container-id container_1427088391284_0019_01_000165: 60.2 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:54:34,964",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3238 for container-id container_1427088391284_0019_01_000165: 76.9 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:54:38,011",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3238 for container-id container_1427088391284_0019_01_000165: 90.9 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:54:41,051",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3238 for container-id container_1427088391284_0019_01_000165: 99.4 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:54:44,061",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3238 for container-id container_1427088391284_0019_01_000165: 112.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:54:47,074",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3238 for container-id container_1427088391284_0019_01_000165: 112.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:54:50,083",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3238 for container-id container_1427088391284_0019_01_000165: 112.7 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:54:53,093",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3238 for container-id container_1427088391284_0019_01_000165: 112.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:54:56,106",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3238 for container-id container_1427088391284_0019_01_000165: 114.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:54:59,116",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3238 for container-id container_1427088391284_0019_01_000165: 117.1 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:55:02,126",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3238 for container-id container_1427088391284_0019_01_000165: 119.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:55:05,139",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3238 for container-id container_1427088391284_0019_01_000165: 121.7 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:55:08,148",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3238 for container-id container_1427088391284_0019_01_000165: 121.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:55:11,158",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3238 for container-id container_1427088391284_0019_01_000165: 121.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:55:14,168",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3238 for container-id container_1427088391284_0019_01_000165: 131.2 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:55:17,181",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3238 for container-id container_1427088391284_0019_01_000165: 131.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:55:20,191",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3238 for container-id container_1427088391284_0019_01_000165: 131.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:55:23,200",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3238 for container-id container_1427088391284_0019_01_000165: 131.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:55:26,213",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3238 for container-id container_1427088391284_0019_01_000165: 131.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:55:29,223",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3238 for container-id container_1427088391284_0019_01_000165: 131.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:55:32,234",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3238 for container-id container_1427088391284_0019_01_000165: 134.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:55:35,248",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3238 for container-id container_1427088391284_0019_01_000165: 134.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:55:38,257",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3238 for container-id container_1427088391284_0019_01_000165: 134.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:55:41,267",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3238 for container-id container_1427088391284_0019_01_000165: 134.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:55:44,280",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3238 for container-id container_1427088391284_0019_01_000165: 134.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:55:47,289",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3238 for container-id container_1427088391284_0019_01_000165: 134.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:55:50,299",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3238 for container-id container_1427088391284_0019_01_000165: 136.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:55:53,308",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3238 for container-id container_1427088391284_0019_01_000165: 136.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:55:56,318",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3238 for container-id container_1427088391284_0019_01_000165: 136.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:55:59,327",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3238 for container-id container_1427088391284_0019_01_000165: 136.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:56:02,337",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3238 for container-id container_1427088391284_0019_01_000165: 136.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:56:05,350",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3238 for container-id container_1427088391284_0019_01_000165: 136.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:56:08,359",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3238 for container-id container_1427088391284_0019_01_000165: 138.7 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:56:11,396",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3238 for container-id container_1427088391284_0019_01_000165: 139.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:56:14,414",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3238 for container-id container_1427088391284_0019_01_000165: 140.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:56:17,467",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3238 for container-id container_1427088391284_0019_01_000165: 146.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:56:20,495",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3238 for container-id container_1427088391284_0019_01_000165: 156.1 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:56:23,522",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3238 for container-id container_1427088391284_0019_01_000165: 158.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:56:26,722",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3238 for container-id container_1427088391284_0019_01_000165: 158.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:56:29,757",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3238 for container-id container_1427088391284_0019_01_000165: 156.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:56:32,791",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3238 for container-id container_1427088391284_0019_01_000165: 156.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:56:35,808",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3238 for container-id container_1427088391284_0019_01_000165: 156.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:56:38,845",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3238 for container-id container_1427088391284_0019_01_000165: 156.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:56:41,931",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3238 for container-id container_1427088391284_0019_01_000165: 156.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:56:44,973",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3238 for container-id container_1427088391284_0019_01_000165: 156.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:56:47,989",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3238 for container-id container_1427088391284_0019_01_000165: 156.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:56:51,018",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3238 for container-id container_1427088391284_0019_01_000165: 156.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:56:54,037",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3238 for container-id container_1427088391284_0019_01_000165: 156.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:56:57,050",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3238 for container-id container_1427088391284_0019_01_000165: 156.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:57:00,076",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3238 for container-id container_1427088391284_0019_01_000165: 156.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:57:03,109",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3238 for container-id container_1427088391284_0019_01_000165: 156.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:57:06,142",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3238 for container-id container_1427088391284_0019_01_000165: 156.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:57:09,166",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3238 for container-id container_1427088391284_0019_01_000165: 156.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:57:12,060",
        "type": "INFO",
        "app": "SecurityLogger.org.apache.hadoop.ipc.Server",
        "message": " Auth successful for appattempt_1427088391284_0019_000001 (auth:SIMPLE)\n"
    },
    {
        "timestamp": "2015-03-23 06:57:12,062",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Stopping container with container Id: container_1427088391284_0019_01_000165\n"
    },
    {
        "timestamp": "2015-03-23 06:57:12,063",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tIP=172.31.17.131\tOPERATION=Stop Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0019\tCONTAINERID=container_1427088391284_0019_01_000165\n"
    },
    {
        "timestamp": "2015-03-23 06:57:12,063",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0019_01_000165 transitioned from RUNNING to KILLING\n"
    },
    {
        "timestamp": "2015-03-23 06:57:12,063",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch",
        "message": " Cleaning up container container_1427088391284_0019_01_000165\n"
    },
    {
        "timestamp": "2015-03-23 06:57:12,135",
        "type": "WARN",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Exit code from container container_1427088391284_0019_01_000165 is : 143\n"
    },
    {
        "timestamp": "2015-03-23 06:57:12,195",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3238 for container-id container_1427088391284_0019_01_000165: 0B of 4 GB physical memory used; 0B of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:57:12,197",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0019_01_000165 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL\n"
    },
    {
        "timestamp": "2015-03-23 06:57:12,198",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Deleting absolute path : /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0019/container_1427088391284_0019_01_000165\n"
    },
    {
        "timestamp": "2015-03-23 06:57:12,200",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tOPERATION=Container Finished - Killed\tTARGET=ContainerImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0019\tCONTAINERID=container_1427088391284_0019_01_000165\n"
    },
    {
        "timestamp": "2015-03-23 06:57:12,200",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0019_01_000165 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE\n"
    },
    {
        "timestamp": "2015-03-23 06:57:12,201",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Removing container_1427088391284_0019_01_000165 from application application_1427088391284_0019\n"
    },
    {
        "timestamp": "2015-03-23 06:57:12,201",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event CONTAINER_STOP for appId application_1427088391284_0019\n"
    },
    {
        "timestamp": "2015-03-23 06:57:15,088",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl",
        "message": " Removed completed containers from NM context: [container_1427088391284_0019_01_000165]\n"
    },
    {
        "timestamp": "2015-03-23 06:57:15,195",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Stopping resource-monitoring for container_1427088391284_0019_01_000165\n"
    },
    {
        "timestamp": "2015-03-23 06:57:29,393",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0019 transitioned from RUNNING to APPLICATION_RESOURCES_CLEANINGUP\n"
    },
    {
        "timestamp": "2015-03-23 06:57:29,394",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event APPLICATION_STOP for appId application_1427088391284_0019\n"
    },
    {
        "timestamp": "2015-03-23 06:57:29,394",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0019 transitioned from APPLICATION_RESOURCES_CLEANINGUP to FINISHED\n"
    },
    {
        "timestamp": "2015-03-23 06:57:29,394",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler",
        "message": " Scheduling Log Deletion for application: application_1427088391284_0019, with delay of 172800 seconds\n"
    },
    {
        "timestamp": "2015-03-23 06:57:29,395",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Deleting absolute path : /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0019\n"
    },
    {
        "timestamp": "2015-03-23 06:59:13,081",
        "type": "INFO",
        "app": "SecurityLogger.org.apache.hadoop.ipc.Server",
        "message": " Auth successful for appattempt_1427088391284_0020_000001 (auth:SIMPLE)\n"
    },
    {
        "timestamp": "2015-03-23 06:59:13,755",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Start request for container_1427088391284_0020_01_000047 by user ubuntu\n"
    },
    {
        "timestamp": "2015-03-23 06:59:13,756",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Creating a new application reference for app application_1427088391284_0020\n"
    },
    {
        "timestamp": "2015-03-23 06:59:13,756",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0020 transitioned from NEW to INITING\n"
    },
    {
        "timestamp": "2015-03-23 06:59:13,756",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0020 transitioned from INITING to RUNNING\n"
    },
    {
        "timestamp": "2015-03-23 06:59:13,757",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Adding container_1427088391284_0020_01_000047 to application application_1427088391284_0020\n"
    },
    {
        "timestamp": "2015-03-23 06:59:13,757",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0020_01_000047 transitioned from NEW to LOCALIZING\n"
    },
    {
        "timestamp": "2015-03-23 06:59:13,757",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event CONTAINER_INIT for appId application_1427088391284_0020\n"
    },
    {
        "timestamp": "2015-03-23 06:59:13,757",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event APPLICATION_INIT for appId application_1427088391284_0020\n"
    },
    {
        "timestamp": "2015-03-23 06:59:13,757",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got APPLICATION_INIT for service mapreduce_shuffle\n"
    },
    {
        "timestamp": "2015-03-23 06:59:13,757",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Added token for job_1427088391284_0020\n"
    },
    {
        "timestamp": "2015-03-23 06:59:13,758",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/506dfd0a-f6cc-46fd-bbf5-d1a477fae229/hive_2015-03-23_06-58-23_159_4860968238285282662-1/-mr-10005/56076107-bca2-43dd-a2da-37be9941e5fb/map.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 06:59:13,758",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/506dfd0a-f6cc-46fd-bbf5-d1a477fae229/hive_2015-03-23_06-58-23_159_4860968238285282662-1/-mr-10005/56076107-bca2-43dd-a2da-37be9941e5fb/reduce.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 06:59:13,758",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0020/job.jar transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 06:59:13,758",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0020/job.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 06:59:13,758",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService",
        "message": " Created localizer for container_1427088391284_0020_01_000047\n"
    },
    {
        "timestamp": "2015-03-23 06:59:13,758",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tIP=172.31.17.131\tOPERATION=Start Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0020\tCONTAINERID=container_1427088391284_0020_01_000047\n"
    },
    {
        "timestamp": "2015-03-23 06:59:13,763",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService",
        "message": " Writing credentials to the nmPrivate file /tmp/hadoop-ubuntu/nm-local-dir/nmPrivate/container_1427088391284_0020_01_000047.tokens. Credentials list: \n"
    },
    {
        "timestamp": "2015-03-23 06:59:13,786",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Initializing user ubuntu\n"
    },
    {
        "timestamp": "2015-03-23 06:59:13,789",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Copying from /tmp/hadoop-ubuntu/nm-local-dir/nmPrivate/container_1427088391284_0020_01_000047.tokens to /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0020/container_1427088391284_0020_01_000047.tokens\n"
    },
    {
        "timestamp": "2015-03-23 06:59:13,790",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Localizer CWD set to /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0020 = file:/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0020\n"
    },
    {
        "timestamp": "2015-03-23 06:59:13,959",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/506dfd0a-f6cc-46fd-bbf5-d1a477fae229/hive_2015-03-23_06-58-23_159_4860968238285282662-1/-mr-10005/56076107-bca2-43dd-a2da-37be9941e5fb/map.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/filecache/24/map.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 06:59:14,037",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/506dfd0a-f6cc-46fd-bbf5-d1a477fae229/hive_2015-03-23_06-58-23_159_4860968238285282662-1/-mr-10005/56076107-bca2-43dd-a2da-37be9941e5fb/reduce.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/filecache/25/reduce.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 06:59:14,650",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0020/job.jar(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0020/filecache/10/job.jar) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 06:59:14,800",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0020/job.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0020/filecache/11/job.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 06:59:14,801",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0020_01_000047 transitioned from LOCALIZING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 06:59:14,858",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0020_01_000047 transitioned from LOCALIZED to RUNNING\n"
    },
    {
        "timestamp": "2015-03-23 06:59:14,889",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " launchContainer: [bash, /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0020/container_1427088391284_0020_01_000047/default_container_executor.sh]\n"
    },
    {
        "timestamp": "2015-03-23 06:59:15,223",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Starting resource-monitoring for container_1427088391284_0020_01_000047\n"
    },
    {
        "timestamp": "2015-03-23 06:59:15,240",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3358 for container-id container_1427088391284_0020_01_000047: 15.5 MB of 4 GB physical memory used; 3.5 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:59:18,085",
        "type": "WARN",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Event EventType: KILL_CONTAINER sent to absent container container_1427088391284_0020_01_000244\n"
    },
    {
        "timestamp": "2015-03-23 06:59:18,265",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3358 for container-id container_1427088391284_0020_01_000047: 50 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:59:21,285",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3358 for container-id container_1427088391284_0020_01_000047: 62.2 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:59:24,370",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3358 for container-id container_1427088391284_0020_01_000047: 77.8 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:59:27,442",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3358 for container-id container_1427088391284_0020_01_000047: 89.4 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:59:30,483",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3358 for container-id container_1427088391284_0020_01_000047: 93.8 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:59:33,508",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3358 for container-id container_1427088391284_0020_01_000047: 103.9 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:59:36,551",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3358 for container-id container_1427088391284_0020_01_000047: 210.8 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:59:39,687",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3358 for container-id container_1427088391284_0020_01_000047: 211.8 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:59:42,725",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3358 for container-id container_1427088391284_0020_01_000047: 212.3 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:59:45,814",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3358 for container-id container_1427088391284_0020_01_000047: 212.3 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:59:48,829",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3358 for container-id container_1427088391284_0020_01_000047: 212.6 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:59:52,112",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3358 for container-id container_1427088391284_0020_01_000047: 212.6 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:59:55,156",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3358 for container-id container_1427088391284_0020_01_000047: 212.6 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 06:59:58,173",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3358 for container-id container_1427088391284_0020_01_000047: 212.6 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:00:01,232",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3358 for container-id container_1427088391284_0020_01_000047: 212.6 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:00:04,309",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3358 for container-id container_1427088391284_0020_01_000047: 212.6 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:00:07,342",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3358 for container-id container_1427088391284_0020_01_000047: 212.6 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:00:10,361",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3358 for container-id container_1427088391284_0020_01_000047: 212.6 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:00:12,151",
        "type": "INFO",
        "app": "SecurityLogger.org.apache.hadoop.ipc.Server",
        "message": " Auth successful for appattempt_1427088391284_0020_000001 (auth:SIMPLE)\n"
    },
    {
        "timestamp": "2015-03-23 07:00:12,154",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Stopping container with container Id: container_1427088391284_0020_01_000047\n"
    },
    {
        "timestamp": "2015-03-23 07:00:12,154",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tIP=172.31.17.131\tOPERATION=Stop Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0020\tCONTAINERID=container_1427088391284_0020_01_000047\n"
    },
    {
        "timestamp": "2015-03-23 07:00:12,155",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0020_01_000047 transitioned from RUNNING to KILLING\n"
    },
    {
        "timestamp": "2015-03-23 07:00:12,155",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch",
        "message": " Cleaning up container container_1427088391284_0020_01_000047\n"
    },
    {
        "timestamp": "2015-03-23 07:00:12,336",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:00:12,340",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:00:12,518",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:00:12,520",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:00:12,522",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:00:12,524",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:00:12,559",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:00:12,561",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:00:12,566",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:00:12,567",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:00:12,568",
        "type": "WARN",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Exit code from container container_1427088391284_0020_01_000047 is : 143\n"
    },
    {
        "timestamp": "2015-03-23 07:00:12,591",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0020_01_000047 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL\n"
    },
    {
        "timestamp": "2015-03-23 07:00:12,591",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Deleting absolute path : /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0020/container_1427088391284_0020_01_000047\n"
    },
    {
        "timestamp": "2015-03-23 07:00:12,629",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tOPERATION=Container Finished - Killed\tTARGET=ContainerImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0020\tCONTAINERID=container_1427088391284_0020_01_000047\n"
    },
    {
        "timestamp": "2015-03-23 07:00:12,629",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0020_01_000047 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE\n"
    },
    {
        "timestamp": "2015-03-23 07:00:12,629",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Removing container_1427088391284_0020_01_000047 from application application_1427088391284_0020\n"
    },
    {
        "timestamp": "2015-03-23 07:00:12,629",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event CONTAINER_STOP for appId application_1427088391284_0020\n"
    },
    {
        "timestamp": "2015-03-23 07:00:12,637",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:00:12,638",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:00:12,682",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:00:12,737",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:00:12,846",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:00:12,855",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:00:12,863",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:00:12,873",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:00:12,892",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:00:12,915",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:00:12,918",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:00:12,971",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:00:13,024",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:00:13,054",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:00:13,091",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:00:13,093",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:00:13,115",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:00:13,160",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:00:13,173",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:00:13,271",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:00:13,315",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:00:13,362",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Stopping resource-monitoring for container_1427088391284_0020_01_000047\n"
    },
    {
        "timestamp": "2015-03-23 07:00:13,376",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:00:13,390",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:00:13,627",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:00:13,770",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:00:13,844",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:00:14,006",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:00:14,276",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:00:14,377",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:00:14,408",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:00:15,124",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:00:15,366",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl",
        "message": " Removed completed containers from NM context: [container_1427088391284_0020_01_000047]\n"
    },
    {
        "timestamp": "2015-03-23 07:00:22,448",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:00:29,402",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:00:29,861",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:00:30,177",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:00:30,658",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:00:32,996",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:00:33,436",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:02:31,830",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0020 transitioned from RUNNING to APPLICATION_RESOURCES_CLEANINGUP\n"
    },
    {
        "timestamp": "2015-03-23 07:02:31,831",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event APPLICATION_STOP for appId application_1427088391284_0020\n"
    },
    {
        "timestamp": "2015-03-23 07:02:31,831",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0020 transitioned from APPLICATION_RESOURCES_CLEANINGUP to FINISHED\n"
    },
    {
        "timestamp": "2015-03-23 07:02:31,831",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler",
        "message": " Scheduling Log Deletion for application: application_1427088391284_0020, with delay of 172800 seconds\n"
    },
    {
        "timestamp": "2015-03-23 07:02:31,831",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Deleting absolute path : /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0020\n"
    },
    {
        "timestamp": "2015-03-23 07:03:29,642",
        "type": "INFO",
        "app": "SecurityLogger.org.apache.hadoop.ipc.Server",
        "message": " Auth successful for appattempt_1427088391284_0021_000001 (auth:SIMPLE)\n"
    },
    {
        "timestamp": "2015-03-23 07:03:29,722",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Start request for container_1427088391284_0021_01_000085 by user ubuntu\n"
    },
    {
        "timestamp": "2015-03-23 07:03:29,722",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Creating a new application reference for app application_1427088391284_0021\n"
    },
    {
        "timestamp": "2015-03-23 07:03:29,723",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0021 transitioned from NEW to INITING\n"
    },
    {
        "timestamp": "2015-03-23 07:03:29,723",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0021 transitioned from INITING to RUNNING\n"
    },
    {
        "timestamp": "2015-03-23 07:03:29,723",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Adding container_1427088391284_0021_01_000085 to application application_1427088391284_0021\n"
    },
    {
        "timestamp": "2015-03-23 07:03:29,724",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0021_01_000085 transitioned from NEW to LOCALIZING\n"
    },
    {
        "timestamp": "2015-03-23 07:03:29,724",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event CONTAINER_INIT for appId application_1427088391284_0021\n"
    },
    {
        "timestamp": "2015-03-23 07:03:29,724",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event APPLICATION_INIT for appId application_1427088391284_0021\n"
    },
    {
        "timestamp": "2015-03-23 07:03:29,724",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got APPLICATION_INIT for service mapreduce_shuffle\n"
    },
    {
        "timestamp": "2015-03-23 07:03:29,724",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Added token for job_1427088391284_0021\n"
    },
    {
        "timestamp": "2015-03-23 07:03:29,725",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/506dfd0a-f6cc-46fd-bbf5-d1a477fae229/hive_2015-03-23_06-58-23_159_4860968238285282662-1/-mr-10007/1a5cc6c0-fd3b-494f-823d-9189aa5b3aca/map.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 07:03:29,725",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/506dfd0a-f6cc-46fd-bbf5-d1a477fae229/hive_2015-03-23_06-58-23_159_4860968238285282662-1/-mr-10007/1a5cc6c0-fd3b-494f-823d-9189aa5b3aca/reduce.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 07:03:29,725",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0021/job.jar transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 07:03:29,725",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0021/job.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 07:03:29,725",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService",
        "message": " Created localizer for container_1427088391284_0021_01_000085\n"
    },
    {
        "timestamp": "2015-03-23 07:03:29,725",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tIP=172.31.17.125\tOPERATION=Start Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0021\tCONTAINERID=container_1427088391284_0021_01_000085\n"
    },
    {
        "timestamp": "2015-03-23 07:03:29,730",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService",
        "message": " Writing credentials to the nmPrivate file /tmp/hadoop-ubuntu/nm-local-dir/nmPrivate/container_1427088391284_0021_01_000085.tokens. Credentials list: \n"
    },
    {
        "timestamp": "2015-03-23 07:03:29,757",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Initializing user ubuntu\n"
    },
    {
        "timestamp": "2015-03-23 07:03:29,784",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Copying from /tmp/hadoop-ubuntu/nm-local-dir/nmPrivate/container_1427088391284_0021_01_000085.tokens to /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0021/container_1427088391284_0021_01_000085.tokens\n"
    },
    {
        "timestamp": "2015-03-23 07:03:29,785",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Localizer CWD set to /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0021 = file:/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0021\n"
    },
    {
        "timestamp": "2015-03-23 07:03:29,912",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/506dfd0a-f6cc-46fd-bbf5-d1a477fae229/hive_2015-03-23_06-58-23_159_4860968238285282662-1/-mr-10007/1a5cc6c0-fd3b-494f-823d-9189aa5b3aca/map.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/filecache/26/map.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 07:03:29,964",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/506dfd0a-f6cc-46fd-bbf5-d1a477fae229/hive_2015-03-23_06-58-23_159_4860968238285282662-1/-mr-10007/1a5cc6c0-fd3b-494f-823d-9189aa5b3aca/reduce.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/filecache/27/reduce.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 07:03:30,510",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0021/job.jar(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0021/filecache/10/job.jar) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 07:03:30,582",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0021/job.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0021/filecache/11/job.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 07:03:30,583",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0021_01_000085 transitioned from LOCALIZING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 07:03:30,644",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0021_01_000085 transitioned from LOCALIZED to RUNNING\n"
    },
    {
        "timestamp": "2015-03-23 07:03:30,655",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " launchContainer: [bash, /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0021/container_1427088391284_0021_01_000085/default_container_executor.sh]\n"
    },
    {
        "timestamp": "2015-03-23 07:03:31,392",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Starting resource-monitoring for container_1427088391284_0021_01_000085\n"
    },
    {
        "timestamp": "2015-03-23 07:03:31,415",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3456 for container-id container_1427088391284_0021_01_000085: 19.7 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:03:34,435",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3456 for container-id container_1427088391284_0021_01_000085: 49.6 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:03:37,471",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3456 for container-id container_1427088391284_0021_01_000085: 64.0 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:03:40,510",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3456 for container-id container_1427088391284_0021_01_000085: 77.8 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:03:43,600",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3456 for container-id container_1427088391284_0021_01_000085: 90.7 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:03:46,618",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3456 for container-id container_1427088391284_0021_01_000085: 89.4 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:03:49,627",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3456 for container-id container_1427088391284_0021_01_000085: 92.7 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:03:52,641",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3456 for container-id container_1427088391284_0021_01_000085: 92.7 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:03:55,657",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3456 for container-id container_1427088391284_0021_01_000085: 94.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:03:58,691",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3456 for container-id container_1427088391284_0021_01_000085: 101.2 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:04:01,739",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3456 for container-id container_1427088391284_0021_01_000085: 105.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:04:04,752",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3456 for container-id container_1427088391284_0021_01_000085: 126.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:04:07,793",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3456 for container-id container_1427088391284_0021_01_000085: 119.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:04:07,975",
        "type": "INFO",
        "app": "SecurityLogger.org.apache.hadoop.ipc.Server",
        "message": " Auth successful for appattempt_1427088391284_0021_000001 (auth:SIMPLE)\n"
    },
    {
        "timestamp": "2015-03-23 07:04:08,000",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Stopping container with container Id: container_1427088391284_0021_01_000085\n"
    },
    {
        "timestamp": "2015-03-23 07:04:08,000",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tIP=172.31.17.125\tOPERATION=Stop Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0021\tCONTAINERID=container_1427088391284_0021_01_000085\n"
    },
    {
        "timestamp": "2015-03-23 07:04:08,000",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0021_01_000085 transitioned from RUNNING to KILLING\n"
    },
    {
        "timestamp": "2015-03-23 07:04:08,000",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch",
        "message": " Cleaning up container container_1427088391284_0021_01_000085\n"
    },
    {
        "timestamp": "2015-03-23 07:04:08,035",
        "type": "WARN",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Exit code from container container_1427088391284_0021_01_000085 is : 143\n"
    },
    {
        "timestamp": "2015-03-23 07:04:08,078",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0021_01_000085 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL\n"
    },
    {
        "timestamp": "2015-03-23 07:04:08,078",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Deleting absolute path : /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0021/container_1427088391284_0021_01_000085\n"
    },
    {
        "timestamp": "2015-03-23 07:04:08,081",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tOPERATION=Container Finished - Killed\tTARGET=ContainerImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0021\tCONTAINERID=container_1427088391284_0021_01_000085\n"
    },
    {
        "timestamp": "2015-03-23 07:04:08,081",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0021_01_000085 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE\n"
    },
    {
        "timestamp": "2015-03-23 07:04:08,081",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Removing container_1427088391284_0021_01_000085 from application application_1427088391284_0021\n"
    },
    {
        "timestamp": "2015-03-23 07:04:08,081",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event CONTAINER_STOP for appId application_1427088391284_0021\n"
    },
    {
        "timestamp": "2015-03-23 07:04:10,793",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Stopping resource-monitoring for container_1427088391284_0021_01_000085\n"
    },
    {
        "timestamp": "2015-03-23 07:04:16,034",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0021 transitioned from RUNNING to APPLICATION_RESOURCES_CLEANINGUP\n"
    },
    {
        "timestamp": "2015-03-23 07:04:16,035",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event APPLICATION_STOP for appId application_1427088391284_0021\n"
    },
    {
        "timestamp": "2015-03-23 07:04:16,035",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0021 transitioned from APPLICATION_RESOURCES_CLEANINGUP to FINISHED\n"
    },
    {
        "timestamp": "2015-03-23 07:04:16,035",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler",
        "message": " Scheduling Log Deletion for application: application_1427088391284_0021, with delay of 172800 seconds\n"
    },
    {
        "timestamp": "2015-03-23 07:04:16,035",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Deleting absolute path : /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0021\n"
    },
    {
        "timestamp": "2015-03-23 07:15:08,863",
        "type": "INFO",
        "app": "SecurityLogger.org.apache.hadoop.ipc.Server",
        "message": " Auth successful for appattempt_1427088391284_0024_000001 (auth:SIMPLE)\n"
    },
    {
        "timestamp": "2015-03-23 07:15:08,915",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Start request for container_1427088391284_0024_01_000163 by user ubuntu\n"
    },
    {
        "timestamp": "2015-03-23 07:15:08,915",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Creating a new application reference for app application_1427088391284_0024\n"
    },
    {
        "timestamp": "2015-03-23 07:15:08,919",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0024 transitioned from NEW to INITING\n"
    },
    {
        "timestamp": "2015-03-23 07:15:08,919",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0024 transitioned from INITING to RUNNING\n"
    },
    {
        "timestamp": "2015-03-23 07:15:08,919",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Adding container_1427088391284_0024_01_000163 to application application_1427088391284_0024\n"
    },
    {
        "timestamp": "2015-03-23 07:15:08,920",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0024_01_000163 transitioned from NEW to LOCALIZING\n"
    },
    {
        "timestamp": "2015-03-23 07:15:08,920",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event CONTAINER_INIT for appId application_1427088391284_0024\n"
    },
    {
        "timestamp": "2015-03-23 07:15:08,920",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event APPLICATION_INIT for appId application_1427088391284_0024\n"
    },
    {
        "timestamp": "2015-03-23 07:15:08,920",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got APPLICATION_INIT for service mapreduce_shuffle\n"
    },
    {
        "timestamp": "2015-03-23 07:15:08,920",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Added token for job_1427088391284_0024\n"
    },
    {
        "timestamp": "2015-03-23 07:15:08,920",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/df3e0453-6d48-4311-a4a7-7246521fde5e/hive_2015-03-23_07-13-42_128_7590570837664593432-1/-mr-10005/a59d9f74-f1ab-4b46-b4a6-3b25f349d85c/map.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 07:15:08,920",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/df3e0453-6d48-4311-a4a7-7246521fde5e/hive_2015-03-23_07-13-42_128_7590570837664593432-1/-mr-10005/a59d9f74-f1ab-4b46-b4a6-3b25f349d85c/reduce.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 07:15:08,920",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0024/job.jar transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 07:15:08,920",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0024/job.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 07:15:08,921",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService",
        "message": " Created localizer for container_1427088391284_0024_01_000163\n"
    },
    {
        "timestamp": "2015-03-23 07:15:08,921",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tIP=172.31.17.95\tOPERATION=Start Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0024\tCONTAINERID=container_1427088391284_0024_01_000163\n"
    },
    {
        "timestamp": "2015-03-23 07:15:08,925",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService",
        "message": " Writing credentials to the nmPrivate file /tmp/hadoop-ubuntu/nm-local-dir/nmPrivate/container_1427088391284_0024_01_000163.tokens. Credentials list: \n"
    },
    {
        "timestamp": "2015-03-23 07:15:08,992",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Initializing user ubuntu\n"
    },
    {
        "timestamp": "2015-03-23 07:15:08,995",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Copying from /tmp/hadoop-ubuntu/nm-local-dir/nmPrivate/container_1427088391284_0024_01_000163.tokens to /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0024/container_1427088391284_0024_01_000163.tokens\n"
    },
    {
        "timestamp": "2015-03-23 07:15:08,996",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Localizer CWD set to /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0024 = file:/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0024\n"
    },
    {
        "timestamp": "2015-03-23 07:15:09,206",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/df3e0453-6d48-4311-a4a7-7246521fde5e/hive_2015-03-23_07-13-42_128_7590570837664593432-1/-mr-10005/a59d9f74-f1ab-4b46-b4a6-3b25f349d85c/map.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/filecache/28/map.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 07:15:09,267",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/df3e0453-6d48-4311-a4a7-7246521fde5e/hive_2015-03-23_07-13-42_128_7590570837664593432-1/-mr-10005/a59d9f74-f1ab-4b46-b4a6-3b25f349d85c/reduce.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/filecache/29/reduce.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 07:15:09,729",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0024/job.jar(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0024/filecache/10/job.jar) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 07:15:09,791",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0024/job.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0024/filecache/11/job.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 07:15:09,792",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0024_01_000163 transitioned from LOCALIZING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 07:15:09,967",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0024_01_000163 transitioned from LOCALIZED to RUNNING\n"
    },
    {
        "timestamp": "2015-03-23 07:15:09,967",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " launchContainer: [bash, /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0024/container_1427088391284_0024_01_000163/default_container_executor.sh]\n"
    },
    {
        "timestamp": "2015-03-23 07:15:10,831",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Starting resource-monitoring for container_1427088391284_0024_01_000163\n"
    },
    {
        "timestamp": "2015-03-23 07:15:10,848",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3690 for container-id container_1427088391284_0024_01_000163: 25.8 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:15:13,871",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3690 for container-id container_1427088391284_0024_01_000163: 50.3 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:15:16,941",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3690 for container-id container_1427088391284_0024_01_000163: 66.3 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:15:20,027",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3690 for container-id container_1427088391284_0024_01_000163: 80.1 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:15:23,155",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3690 for container-id container_1427088391284_0024_01_000163: 87.1 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:15:26,444",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3690 for container-id container_1427088391284_0024_01_000163: 99.3 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:15:29,453",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3690 for container-id container_1427088391284_0024_01_000163: 110.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:15:32,462",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3690 for container-id container_1427088391284_0024_01_000163: 110.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:15:35,475",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3690 for container-id container_1427088391284_0024_01_000163: 112.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:15:38,484",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3690 for container-id container_1427088391284_0024_01_000163: 116.1 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:15:41,493",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3690 for container-id container_1427088391284_0024_01_000163: 116.1 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:15:44,502",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3690 for container-id container_1427088391284_0024_01_000163: 123.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:15:47,515",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3690 for container-id container_1427088391284_0024_01_000163: 123.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:15:50,524",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3690 for container-id container_1427088391284_0024_01_000163: 123.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:15:53,534",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3690 for container-id container_1427088391284_0024_01_000163: 123.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:15:56,546",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3690 for container-id container_1427088391284_0024_01_000163: 123.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:15:59,555",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3690 for container-id container_1427088391284_0024_01_000163: 127.2 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:16:02,564",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3690 for container-id container_1427088391284_0024_01_000163: 127.2 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:16:05,576",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3690 for container-id container_1427088391284_0024_01_000163: 127.2 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:16:08,585",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3690 for container-id container_1427088391284_0024_01_000163: 127.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:16:11,594",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3690 for container-id container_1427088391284_0024_01_000163: 128.7 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:16:14,606",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3690 for container-id container_1427088391284_0024_01_000163: 128.7 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:16:17,615",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3690 for container-id container_1427088391284_0024_01_000163: 128.7 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:16:20,624",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3690 for container-id container_1427088391284_0024_01_000163: 128.7 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:16:23,633",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3690 for container-id container_1427088391284_0024_01_000163: 128.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:16:26,645",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3690 for container-id container_1427088391284_0024_01_000163: 130.1 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:16:29,654",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3690 for container-id container_1427088391284_0024_01_000163: 130.1 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:16:32,663",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3690 for container-id container_1427088391284_0024_01_000163: 130.1 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:16:35,675",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3690 for container-id container_1427088391284_0024_01_000163: 130.1 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:16:38,685",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3690 for container-id container_1427088391284_0024_01_000163: 130.1 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:16:41,694",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3690 for container-id container_1427088391284_0024_01_000163: 130.1 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:16:44,706",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3690 for container-id container_1427088391284_0024_01_000163: 130.1 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:16:47,715",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3690 for container-id container_1427088391284_0024_01_000163: 130.1 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:16:50,724",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3690 for container-id container_1427088391284_0024_01_000163: 130.1 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:16:53,736",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3690 for container-id container_1427088391284_0024_01_000163: 131.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:16:56,745",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3690 for container-id container_1427088391284_0024_01_000163: 131.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:16:59,753",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3690 for container-id container_1427088391284_0024_01_000163: 131.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:17:02,763",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3690 for container-id container_1427088391284_0024_01_000163: 131.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:17:05,776",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3690 for container-id container_1427088391284_0024_01_000163: 131.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:17:08,785",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3690 for container-id container_1427088391284_0024_01_000163: 131.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:17:11,794",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3690 for container-id container_1427088391284_0024_01_000163: 131.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:17:14,806",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3690 for container-id container_1427088391284_0024_01_000163: 131.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:17:17,815",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3690 for container-id container_1427088391284_0024_01_000163: 131.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:17:20,824",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3690 for container-id container_1427088391284_0024_01_000163: 131.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:17:23,836",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3690 for container-id container_1427088391284_0024_01_000163: 131.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:17:26,845",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3690 for container-id container_1427088391284_0024_01_000163: 131.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:17:29,854",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3690 for container-id container_1427088391284_0024_01_000163: 131.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:17:32,890",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3690 for container-id container_1427088391284_0024_01_000163: 131.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:17:35,991",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3690 for container-id container_1427088391284_0024_01_000163: 136.7 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:17:39,119",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3690 for container-id container_1427088391284_0024_01_000163: 139.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:17:42,154",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3690 for container-id container_1427088391284_0024_01_000163: 139.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:17:45,346",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3690 for container-id container_1427088391284_0024_01_000163: 141.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:17:48,272",
        "type": "INFO",
        "app": "SecurityLogger.org.apache.hadoop.ipc.Server",
        "message": " Auth successful for appattempt_1427088391284_0024_000001 (auth:SIMPLE)\n"
    },
    {
        "timestamp": "2015-03-23 07:17:48,346",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Stopping container with container Id: container_1427088391284_0024_01_000163\n"
    },
    {
        "timestamp": "2015-03-23 07:17:48,346",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tIP=172.31.17.95\tOPERATION=Stop Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0024\tCONTAINERID=container_1427088391284_0024_01_000163\n"
    },
    {
        "timestamp": "2015-03-23 07:17:48,347",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0024_01_000163 transitioned from RUNNING to KILLING\n"
    },
    {
        "timestamp": "2015-03-23 07:17:48,347",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch",
        "message": " Cleaning up container container_1427088391284_0024_01_000163\n"
    },
    {
        "timestamp": "2015-03-23 07:17:48,490",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3690 for container-id container_1427088391284_0024_01_000163: 150.7 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:17:48,508",
        "type": "WARN",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Exit code from container container_1427088391284_0024_01_000163 is : 143\n"
    },
    {
        "timestamp": "2015-03-23 07:17:48,554",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0024_01_000163 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL\n"
    },
    {
        "timestamp": "2015-03-23 07:17:48,555",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Deleting absolute path : /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0024/container_1427088391284_0024_01_000163\n"
    },
    {
        "timestamp": "2015-03-23 07:17:48,557",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tOPERATION=Container Finished - Killed\tTARGET=ContainerImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0024\tCONTAINERID=container_1427088391284_0024_01_000163\n"
    },
    {
        "timestamp": "2015-03-23 07:17:48,557",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0024_01_000163 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE\n"
    },
    {
        "timestamp": "2015-03-23 07:17:48,557",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Removing container_1427088391284_0024_01_000163 from application application_1427088391284_0024\n"
    },
    {
        "timestamp": "2015-03-23 07:17:48,557",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event CONTAINER_STOP for appId application_1427088391284_0024\n"
    },
    {
        "timestamp": "2015-03-23 07:17:51,491",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Stopping resource-monitoring for container_1427088391284_0024_01_000163\n"
    },
    {
        "timestamp": "2015-03-23 07:17:57,481",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl",
        "message": " Removed completed containers from NM context: [container_1427088391284_0024_01_000163]\n"
    },
    {
        "timestamp": "2015-03-23 07:17:57,481",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0024 transitioned from RUNNING to APPLICATION_RESOURCES_CLEANINGUP\n"
    },
    {
        "timestamp": "2015-03-23 07:17:57,482",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event APPLICATION_STOP for appId application_1427088391284_0024\n"
    },
    {
        "timestamp": "2015-03-23 07:17:57,482",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0024 transitioned from APPLICATION_RESOURCES_CLEANINGUP to FINISHED\n"
    },
    {
        "timestamp": "2015-03-23 07:17:57,482",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler",
        "message": " Scheduling Log Deletion for application: application_1427088391284_0024, with delay of 172800 seconds\n"
    },
    {
        "timestamp": "2015-03-23 07:17:57,482",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Deleting absolute path : /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0024\n"
    },
    {
        "timestamp": "2015-03-23 07:18:57,394",
        "type": "INFO",
        "app": "SecurityLogger.org.apache.hadoop.ipc.Server",
        "message": " Auth successful for appattempt_1427088391284_0025_000001 (auth:SIMPLE)\n"
    },
    {
        "timestamp": "2015-03-23 07:18:57,522",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Start request for container_1427088391284_0025_01_000056 by user ubuntu\n"
    },
    {
        "timestamp": "2015-03-23 07:18:57,522",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Creating a new application reference for app application_1427088391284_0025\n"
    },
    {
        "timestamp": "2015-03-23 07:18:57,523",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0025 transitioned from NEW to INITING\n"
    },
    {
        "timestamp": "2015-03-23 07:18:57,523",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0025 transitioned from INITING to RUNNING\n"
    },
    {
        "timestamp": "2015-03-23 07:18:57,523",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Adding container_1427088391284_0025_01_000056 to application application_1427088391284_0025\n"
    },
    {
        "timestamp": "2015-03-23 07:18:57,524",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0025_01_000056 transitioned from NEW to LOCALIZING\n"
    },
    {
        "timestamp": "2015-03-23 07:18:57,524",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event CONTAINER_INIT for appId application_1427088391284_0025\n"
    },
    {
        "timestamp": "2015-03-23 07:18:57,524",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event APPLICATION_INIT for appId application_1427088391284_0025\n"
    },
    {
        "timestamp": "2015-03-23 07:18:57,524",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got APPLICATION_INIT for service mapreduce_shuffle\n"
    },
    {
        "timestamp": "2015-03-23 07:18:57,524",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Added token for job_1427088391284_0025\n"
    },
    {
        "timestamp": "2015-03-23 07:18:57,524",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/df3e0453-6d48-4311-a4a7-7246521fde5e/hive_2015-03-23_07-13-42_128_7590570837664593432-1/-mr-10007/c372c4eb-0400-4426-9e4f-30128f8160c7/map.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 07:18:57,524",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/df3e0453-6d48-4311-a4a7-7246521fde5e/hive_2015-03-23_07-13-42_128_7590570837664593432-1/-mr-10007/c372c4eb-0400-4426-9e4f-30128f8160c7/reduce.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 07:18:57,524",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0025/job.jar transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 07:18:57,525",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0025/job.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 07:18:57,525",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService",
        "message": " Created localizer for container_1427088391284_0025_01_000056\n"
    },
    {
        "timestamp": "2015-03-23 07:18:57,525",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tIP=172.31.17.140\tOPERATION=Start Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0025\tCONTAINERID=container_1427088391284_0025_01_000056\n"
    },
    {
        "timestamp": "2015-03-23 07:18:57,537",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService",
        "message": " Writing credentials to the nmPrivate file /tmp/hadoop-ubuntu/nm-local-dir/nmPrivate/container_1427088391284_0025_01_000056.tokens. Credentials list: \n"
    },
    {
        "timestamp": "2015-03-23 07:18:57,557",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Initializing user ubuntu\n"
    },
    {
        "timestamp": "2015-03-23 07:18:57,560",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Copying from /tmp/hadoop-ubuntu/nm-local-dir/nmPrivate/container_1427088391284_0025_01_000056.tokens to /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0025/container_1427088391284_0025_01_000056.tokens\n"
    },
    {
        "timestamp": "2015-03-23 07:18:57,561",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Localizer CWD set to /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0025 = file:/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0025\n"
    },
    {
        "timestamp": "2015-03-23 07:18:57,725",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/df3e0453-6d48-4311-a4a7-7246521fde5e/hive_2015-03-23_07-13-42_128_7590570837664593432-1/-mr-10007/c372c4eb-0400-4426-9e4f-30128f8160c7/map.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/filecache/30/map.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 07:18:57,753",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/df3e0453-6d48-4311-a4a7-7246521fde5e/hive_2015-03-23_07-13-42_128_7590570837664593432-1/-mr-10007/c372c4eb-0400-4426-9e4f-30128f8160c7/reduce.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/filecache/31/reduce.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 07:18:58,255",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0025/job.jar(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0025/filecache/10/job.jar) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 07:18:58,439",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0025/job.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0025/filecache/11/job.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 07:18:58,440",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0025_01_000056 transitioned from LOCALIZING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 07:18:58,498",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0025_01_000056 transitioned from LOCALIZED to RUNNING\n"
    },
    {
        "timestamp": "2015-03-23 07:18:58,528",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " launchContainer: [bash, /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0025/container_1427088391284_0025_01_000056/default_container_executor.sh]\n"
    },
    {
        "timestamp": "2015-03-23 07:19:00,493",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Starting resource-monitoring for container_1427088391284_0025_01_000056\n"
    },
    {
        "timestamp": "2015-03-23 07:19:00,511",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3847 for container-id container_1427088391284_0025_01_000056: 46.6 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:19:03,553",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3847 for container-id container_1427088391284_0025_01_000056: 57.7 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:19:06,603",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3847 for container-id container_1427088391284_0025_01_000056: 74.8 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:19:09,620",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3847 for container-id container_1427088391284_0025_01_000056: 82.3 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:19:12,644",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3847 for container-id container_1427088391284_0025_01_000056: 91.8 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:19:15,846",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3847 for container-id container_1427088391284_0025_01_000056: 101 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:19:18,857",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3847 for container-id container_1427088391284_0025_01_000056: 102.7 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:19:21,865",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3847 for container-id container_1427088391284_0025_01_000056: 104.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:19:24,878",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3847 for container-id container_1427088391284_0025_01_000056: 104.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:19:27,886",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3847 for container-id container_1427088391284_0025_01_000056: 104.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:19:31,056",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3847 for container-id container_1427088391284_0025_01_000056: 105.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:19:34,079",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3847 for container-id container_1427088391284_0025_01_000056: 113.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:19:37,123",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3847 for container-id container_1427088391284_0025_01_000056: 119.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:19:40,150",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 3847 for container-id container_1427088391284_0025_01_000056: 118.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:19:40,795",
        "type": "INFO",
        "app": "SecurityLogger.org.apache.hadoop.ipc.Server",
        "message": " Auth successful for appattempt_1427088391284_0025_000001 (auth:SIMPLE)\n"
    },
    {
        "timestamp": "2015-03-23 07:19:40,825",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Stopping container with container Id: container_1427088391284_0025_01_000056\n"
    },
    {
        "timestamp": "2015-03-23 07:19:40,825",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tIP=172.31.17.140\tOPERATION=Stop Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0025\tCONTAINERID=container_1427088391284_0025_01_000056\n"
    },
    {
        "timestamp": "2015-03-23 07:19:40,825",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0025_01_000056 transitioned from RUNNING to KILLING\n"
    },
    {
        "timestamp": "2015-03-23 07:19:40,825",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch",
        "message": " Cleaning up container container_1427088391284_0025_01_000056\n"
    },
    {
        "timestamp": "2015-03-23 07:19:40,875",
        "type": "WARN",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Exit code from container container_1427088391284_0025_01_000056 is : 143\n"
    },
    {
        "timestamp": "2015-03-23 07:19:40,923",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0025_01_000056 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL\n"
    },
    {
        "timestamp": "2015-03-23 07:19:40,924",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Deleting absolute path : /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0025/container_1427088391284_0025_01_000056\n"
    },
    {
        "timestamp": "2015-03-23 07:19:40,926",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tOPERATION=Container Finished - Killed\tTARGET=ContainerImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0025\tCONTAINERID=container_1427088391284_0025_01_000056\n"
    },
    {
        "timestamp": "2015-03-23 07:19:40,926",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0025_01_000056 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE\n"
    },
    {
        "timestamp": "2015-03-23 07:19:40,926",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Removing container_1427088391284_0025_01_000056 from application application_1427088391284_0025\n"
    },
    {
        "timestamp": "2015-03-23 07:19:40,926",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event CONTAINER_STOP for appId application_1427088391284_0025\n"
    },
    {
        "timestamp": "2015-03-23 07:19:43,150",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Stopping resource-monitoring for container_1427088391284_0025_01_000056\n"
    },
    {
        "timestamp": "2015-03-23 07:19:49,865",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl",
        "message": " Removed completed containers from NM context: [container_1427088391284_0025_01_000056]\n"
    },
    {
        "timestamp": "2015-03-23 07:19:49,865",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0025 transitioned from RUNNING to APPLICATION_RESOURCES_CLEANINGUP\n"
    },
    {
        "timestamp": "2015-03-23 07:19:49,866",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event APPLICATION_STOP for appId application_1427088391284_0025\n"
    },
    {
        "timestamp": "2015-03-23 07:19:49,866",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0025 transitioned from APPLICATION_RESOURCES_CLEANINGUP to FINISHED\n"
    },
    {
        "timestamp": "2015-03-23 07:19:49,866",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler",
        "message": " Scheduling Log Deletion for application: application_1427088391284_0025, with delay of 172800 seconds\n"
    },
    {
        "timestamp": "2015-03-23 07:19:49,866",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Deleting absolute path : /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0025\n"
    },
    {
        "timestamp": "2015-03-23 07:32:21,305",
        "type": "INFO",
        "app": "SecurityLogger.org.apache.hadoop.ipc.Server",
        "message": " Auth successful for appattempt_1427088391284_0029_000001 (auth:SIMPLE)\n"
    },
    {
        "timestamp": "2015-03-23 07:32:22,093",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Start request for container_1427088391284_0029_01_000023 by user ubuntu\n"
    },
    {
        "timestamp": "2015-03-23 07:32:22,094",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Creating a new application reference for app application_1427088391284_0029\n"
    },
    {
        "timestamp": "2015-03-23 07:32:22,094",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0029 transitioned from NEW to INITING\n"
    },
    {
        "timestamp": "2015-03-23 07:32:22,095",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0029 transitioned from INITING to RUNNING\n"
    },
    {
        "timestamp": "2015-03-23 07:32:22,095",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Adding container_1427088391284_0029_01_000023 to application application_1427088391284_0029\n"
    },
    {
        "timestamp": "2015-03-23 07:32:22,095",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0029_01_000023 transitioned from NEW to LOCALIZING\n"
    },
    {
        "timestamp": "2015-03-23 07:32:22,095",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event CONTAINER_INIT for appId application_1427088391284_0029\n"
    },
    {
        "timestamp": "2015-03-23 07:32:22,095",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event APPLICATION_INIT for appId application_1427088391284_0029\n"
    },
    {
        "timestamp": "2015-03-23 07:32:22,095",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got APPLICATION_INIT for service mapreduce_shuffle\n"
    },
    {
        "timestamp": "2015-03-23 07:32:22,096",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Added token for job_1427088391284_0029\n"
    },
    {
        "timestamp": "2015-03-23 07:32:22,096",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/375e7bcc-00c9-4dd2-aea0-43059feb84bc/hive_2015-03-23_07-28-10_627_2464749601500768868-1/-mr-10007/7c0e72ce-a111-4ddb-87c6-c7f7f8d8c486/map.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 07:32:22,096",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/375e7bcc-00c9-4dd2-aea0-43059feb84bc/hive_2015-03-23_07-28-10_627_2464749601500768868-1/-mr-10007/7c0e72ce-a111-4ddb-87c6-c7f7f8d8c486/reduce.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 07:32:22,096",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0029/job.jar transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 07:32:22,096",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0029/job.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 07:32:22,096",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService",
        "message": " Created localizer for container_1427088391284_0029_01_000023\n"
    },
    {
        "timestamp": "2015-03-23 07:32:22,097",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tIP=172.31.17.101\tOPERATION=Start Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0029\tCONTAINERID=container_1427088391284_0029_01_000023\n"
    },
    {
        "timestamp": "2015-03-23 07:32:22,101",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService",
        "message": " Writing credentials to the nmPrivate file /tmp/hadoop-ubuntu/nm-local-dir/nmPrivate/container_1427088391284_0029_01_000023.tokens. Credentials list: \n"
    },
    {
        "timestamp": "2015-03-23 07:32:22,146",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Initializing user ubuntu\n"
    },
    {
        "timestamp": "2015-03-23 07:32:22,149",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Copying from /tmp/hadoop-ubuntu/nm-local-dir/nmPrivate/container_1427088391284_0029_01_000023.tokens to /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0029/container_1427088391284_0029_01_000023.tokens\n"
    },
    {
        "timestamp": "2015-03-23 07:32:22,150",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Localizer CWD set to /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0029 = file:/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0029\n"
    },
    {
        "timestamp": "2015-03-23 07:32:22,306",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/375e7bcc-00c9-4dd2-aea0-43059feb84bc/hive_2015-03-23_07-28-10_627_2464749601500768868-1/-mr-10007/7c0e72ce-a111-4ddb-87c6-c7f7f8d8c486/map.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/filecache/32/map.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 07:32:22,335",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/375e7bcc-00c9-4dd2-aea0-43059feb84bc/hive_2015-03-23_07-28-10_627_2464749601500768868-1/-mr-10007/7c0e72ce-a111-4ddb-87c6-c7f7f8d8c486/reduce.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/filecache/33/reduce.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 07:32:22,829",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0029/job.jar(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0029/filecache/10/job.jar) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 07:32:22,884",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0029/job.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0029/filecache/11/job.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 07:32:22,884",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0029_01_000023 transitioned from LOCALIZING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 07:32:22,955",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0029_01_000023 transitioned from LOCALIZED to RUNNING\n"
    },
    {
        "timestamp": "2015-03-23 07:32:22,961",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " launchContainer: [bash, /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0029/container_1427088391284_0029_01_000023/default_container_executor.sh]\n"
    },
    {
        "timestamp": "2015-03-23 07:32:25,183",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Starting resource-monitoring for container_1427088391284_0029_01_000023\n"
    },
    {
        "timestamp": "2015-03-23 07:32:25,199",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4077 for container-id container_1427088391284_0029_01_000023: 46.9 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:32:28,212",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4077 for container-id container_1427088391284_0029_01_000023: 58.6 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:32:31,299",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4077 for container-id container_1427088391284_0029_01_000023: 76.3 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:32:34,320",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4077 for container-id container_1427088391284_0029_01_000023: 81.2 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:32:37,346",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4077 for container-id container_1427088391284_0029_01_000023: 89.1 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:32:40,377",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4077 for container-id container_1427088391284_0029_01_000023: 100.0 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:32:43,458",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4077 for container-id container_1427088391284_0029_01_000023: 202.4 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:32:46,495",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4077 for container-id container_1427088391284_0029_01_000023: 202.7 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:32:49,563",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4077 for container-id container_1427088391284_0029_01_000023: 203.3 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:32:51,561",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch",
        "message": " Container container_1427088391284_0029_01_000023 succeeded \n"
    },
    {
        "timestamp": "2015-03-23 07:32:51,562",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0029_01_000023 transitioned from RUNNING to EXITED_WITH_SUCCESS\n"
    },
    {
        "timestamp": "2015-03-23 07:32:51,562",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch",
        "message": " Cleaning up container container_1427088391284_0029_01_000023\n"
    },
    {
        "timestamp": "2015-03-23 07:32:51,641",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Deleting absolute path : /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0029/container_1427088391284_0029_01_000023\n"
    },
    {
        "timestamp": "2015-03-23 07:32:51,644",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tOPERATION=Container Finished - Succeeded\tTARGET=ContainerImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0029\tCONTAINERID=container_1427088391284_0029_01_000023\n"
    },
    {
        "timestamp": "2015-03-23 07:32:51,644",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0029_01_000023 transitioned from EXITED_WITH_SUCCESS to DONE\n"
    },
    {
        "timestamp": "2015-03-23 07:32:51,644",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Removing container_1427088391284_0029_01_000023 from application application_1427088391284_0029\n"
    },
    {
        "timestamp": "2015-03-23 07:32:51,644",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event CONTAINER_STOP for appId application_1427088391284_0029\n"
    },
    {
        "timestamp": "2015-03-23 07:32:52,588",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Stopping resource-monitoring for container_1427088391284_0029_01_000023\n"
    },
    {
        "timestamp": "2015-03-23 07:32:52,931",
        "type": "INFO",
        "app": "SecurityLogger.org.apache.hadoop.ipc.Server",
        "message": " Auth successful for appattempt_1427088391284_0029_000001 (auth:SIMPLE)\n"
    },
    {
        "timestamp": "2015-03-23 07:32:53,281",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Stopping container with container Id: container_1427088391284_0029_01_000023\n"
    },
    {
        "timestamp": "2015-03-23 07:32:53,282",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tIP=172.31.17.101\tOPERATION=Stop Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0029\tCONTAINERID=container_1427088391284_0029_01_000023\n"
    },
    {
        "timestamp": "2015-03-23 07:32:56,099",
        "type": "INFO",
        "app": "SecurityLogger.org.apache.hadoop.ipc.Server",
        "message": " Auth successful for appattempt_1427088391284_0029_000001 (auth:SIMPLE)\n"
    },
    {
        "timestamp": "2015-03-23 07:32:56,150",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Start request for container_1427088391284_0029_01_000086 by user ubuntu\n"
    },
    {
        "timestamp": "2015-03-23 07:32:56,151",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Adding container_1427088391284_0029_01_000086 to application application_1427088391284_0029\n"
    },
    {
        "timestamp": "2015-03-23 07:32:56,151",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0029_01_000086 transitioned from NEW to LOCALIZING\n"
    },
    {
        "timestamp": "2015-03-23 07:32:56,151",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event CONTAINER_INIT for appId application_1427088391284_0029\n"
    },
    {
        "timestamp": "2015-03-23 07:32:56,151",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event APPLICATION_INIT for appId application_1427088391284_0029\n"
    },
    {
        "timestamp": "2015-03-23 07:32:56,151",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got APPLICATION_INIT for service mapreduce_shuffle\n"
    },
    {
        "timestamp": "2015-03-23 07:32:56,151",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Added token for job_1427088391284_0029\n"
    },
    {
        "timestamp": "2015-03-23 07:32:56,152",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0029_01_000086 transitioned from LOCALIZING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 07:32:56,158",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tIP=172.31.17.101\tOPERATION=Start Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0029\tCONTAINERID=container_1427088391284_0029_01_000086\n"
    },
    {
        "timestamp": "2015-03-23 07:32:56,217",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0029_01_000086 transitioned from LOCALIZED to RUNNING\n"
    },
    {
        "timestamp": "2015-03-23 07:32:56,224",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " launchContainer: [bash, /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0029/container_1427088391284_0029_01_000086/default_container_executor.sh]\n"
    },
    {
        "timestamp": "2015-03-23 07:32:56,313",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl",
        "message": " Removed completed containers from NM context: [container_1427088391284_0029_01_000023]\n"
    },
    {
        "timestamp": "2015-03-23 07:32:58,588",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Starting resource-monitoring for container_1427088391284_0029_01_000086\n"
    },
    {
        "timestamp": "2015-03-23 07:32:58,669",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4130 for container-id container_1427088391284_0029_01_000086: 47.2 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:33:01,721",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4130 for container-id container_1427088391284_0029_01_000086: 57.8 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:33:04,742",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4130 for container-id container_1427088391284_0029_01_000086: 78.3 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:33:07,768",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4130 for container-id container_1427088391284_0029_01_000086: 84.7 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:33:10,794",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4130 for container-id container_1427088391284_0029_01_000086: 93.2 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:33:12,994",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:33:13,305",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:33:13,358",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:33:13,368",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:33:13,419",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:33:13,485",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:33:13,611",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:33:13,613",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:33:13,720",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:33:13,767",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:33:13,770",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:33:13,776",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:33:13,777",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:33:13,856",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:33:13,861",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4130 for container-id container_1427088391284_0029_01_000086: 102.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:33:13,947",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:33:14,005",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:33:14,016",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:33:14,139",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:33:14,141",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:33:14,145",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:33:14,193",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:33:14,289",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:33:14,331",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:33:14,439",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:33:14,444",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:33:14,446",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:33:14,496",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:33:14,584",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:33:14,634",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:33:14,637",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:33:14,647",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:33:14,651",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:33:14,678",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:33:14,742",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:33:14,953",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:33:14,999",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:33:15,003",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:33:15,145",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:33:15,291",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:33:15,347",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:33:15,627",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:33:15,801",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:33:15,821",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:33:15,885",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:33:15,907",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:33:15,982",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:33:16,344",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:33:16,753",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:33:16,870",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4130 for container-id container_1427088391284_0029_01_000086: 102.2 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:33:19,879",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4130 for container-id container_1427088391284_0029_01_000086: 104.1 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:33:22,916",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4130 for container-id container_1427088391284_0029_01_000086: 109.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:33:25,998",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4130 for container-id container_1427088391284_0029_01_000086: 114.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:33:29,041",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4130 for container-id container_1427088391284_0029_01_000086: 128.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:33:31,938",
        "type": "INFO",
        "app": "SecurityLogger.org.apache.hadoop.ipc.Server",
        "message": " Auth successful for appattempt_1427088391284_0029_000001 (auth:SIMPLE)\n"
    },
    {
        "timestamp": "2015-03-23 07:33:31,979",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Stopping container with container Id: container_1427088391284_0029_01_000086\n"
    },
    {
        "timestamp": "2015-03-23 07:33:31,979",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tIP=172.31.17.101\tOPERATION=Stop Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0029\tCONTAINERID=container_1427088391284_0029_01_000086\n"
    },
    {
        "timestamp": "2015-03-23 07:33:31,979",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0029_01_000086 transitioned from RUNNING to KILLING\n"
    },
    {
        "timestamp": "2015-03-23 07:33:31,979",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch",
        "message": " Cleaning up container container_1427088391284_0029_01_000086\n"
    },
    {
        "timestamp": "2015-03-23 07:33:32,005",
        "type": "WARN",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Exit code from container container_1427088391284_0029_01_000086 is : 143\n"
    },
    {
        "timestamp": "2015-03-23 07:33:32,083",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4130 for container-id container_1427088391284_0029_01_000086: 0B of 4 GB physical memory used; 0B of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:33:32,085",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0029_01_000086 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL\n"
    },
    {
        "timestamp": "2015-03-23 07:33:32,086",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Deleting absolute path : /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0029/container_1427088391284_0029_01_000086\n"
    },
    {
        "timestamp": "2015-03-23 07:33:32,088",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tOPERATION=Container Finished - Killed\tTARGET=ContainerImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0029\tCONTAINERID=container_1427088391284_0029_01_000086\n"
    },
    {
        "timestamp": "2015-03-23 07:33:32,088",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0029_01_000086 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE\n"
    },
    {
        "timestamp": "2015-03-23 07:33:32,088",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Removing container_1427088391284_0029_01_000086 from application application_1427088391284_0029\n"
    },
    {
        "timestamp": "2015-03-23 07:33:32,088",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event CONTAINER_STOP for appId application_1427088391284_0029\n"
    },
    {
        "timestamp": "2015-03-23 07:33:35,006",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl",
        "message": " Removed completed containers from NM context: [container_1427088391284_0029_01_000086]\n"
    },
    {
        "timestamp": "2015-03-23 07:33:35,083",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Stopping resource-monitoring for container_1427088391284_0029_01_000086\n"
    },
    {
        "timestamp": "2015-03-23 07:33:42,017",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0029 transitioned from RUNNING to APPLICATION_RESOURCES_CLEANINGUP\n"
    },
    {
        "timestamp": "2015-03-23 07:33:42,018",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event APPLICATION_STOP for appId application_1427088391284_0029\n"
    },
    {
        "timestamp": "2015-03-23 07:33:42,018",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0029 transitioned from APPLICATION_RESOURCES_CLEANINGUP to FINISHED\n"
    },
    {
        "timestamp": "2015-03-23 07:33:42,018",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler",
        "message": " Scheduling Log Deletion for application: application_1427088391284_0029, with delay of 172800 seconds\n"
    },
    {
        "timestamp": "2015-03-23 07:33:42,018",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Deleting absolute path : /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0029\n"
    },
    {
        "timestamp": "2015-03-23 07:38:03,906",
        "type": "INFO",
        "app": "SecurityLogger.org.apache.hadoop.ipc.Server",
        "message": " Auth successful for appattempt_1427088391284_0031_000001 (auth:SIMPLE)\n"
    },
    {
        "timestamp": "2015-03-23 07:38:03,913",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Start request for container_1427088391284_0031_01_000142 by user ubuntu\n"
    },
    {
        "timestamp": "2015-03-23 07:38:03,913",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Creating a new application reference for app application_1427088391284_0031\n"
    },
    {
        "timestamp": "2015-03-23 07:38:03,914",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0031 transitioned from NEW to INITING\n"
    },
    {
        "timestamp": "2015-03-23 07:38:03,914",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0031 transitioned from INITING to RUNNING\n"
    },
    {
        "timestamp": "2015-03-23 07:38:03,914",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Adding container_1427088391284_0031_01_000142 to application application_1427088391284_0031\n"
    },
    {
        "timestamp": "2015-03-23 07:38:03,915",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0031_01_000142 transitioned from NEW to LOCALIZING\n"
    },
    {
        "timestamp": "2015-03-23 07:38:03,915",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event CONTAINER_INIT for appId application_1427088391284_0031\n"
    },
    {
        "timestamp": "2015-03-23 07:38:03,915",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event APPLICATION_INIT for appId application_1427088391284_0031\n"
    },
    {
        "timestamp": "2015-03-23 07:38:03,915",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got APPLICATION_INIT for service mapreduce_shuffle\n"
    },
    {
        "timestamp": "2015-03-23 07:38:03,915",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Added token for job_1427088391284_0031\n"
    },
    {
        "timestamp": "2015-03-23 07:38:03,915",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/0e58e0f8-5d97-4013-9ef9-0ebd45f66d93/hive_2015-03-23_07-36-23_257_5266898328579080744-1/-mr-10003/b24f6a47-f496-416c-ae1d-7004b9e5acbd/map.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 07:38:03,916",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/0e58e0f8-5d97-4013-9ef9-0ebd45f66d93/hive_2015-03-23_07-36-23_257_5266898328579080744-1/-mr-10003/b24f6a47-f496-416c-ae1d-7004b9e5acbd/reduce.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 07:38:03,916",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0031/job.jar transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 07:38:03,916",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0031/job.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 07:38:03,916",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService",
        "message": " Created localizer for container_1427088391284_0031_01_000142\n"
    },
    {
        "timestamp": "2015-03-23 07:38:03,916",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tIP=172.31.16.243\tOPERATION=Start Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0031\tCONTAINERID=container_1427088391284_0031_01_000142\n"
    },
    {
        "timestamp": "2015-03-23 07:38:03,921",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService",
        "message": " Writing credentials to the nmPrivate file /tmp/hadoop-ubuntu/nm-local-dir/nmPrivate/container_1427088391284_0031_01_000142.tokens. Credentials list: \n"
    },
    {
        "timestamp": "2015-03-23 07:38:04,028",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Initializing user ubuntu\n"
    },
    {
        "timestamp": "2015-03-23 07:38:04,031",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Copying from /tmp/hadoop-ubuntu/nm-local-dir/nmPrivate/container_1427088391284_0031_01_000142.tokens to /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0031/container_1427088391284_0031_01_000142.tokens\n"
    },
    {
        "timestamp": "2015-03-23 07:38:04,032",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Localizer CWD set to /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0031 = file:/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0031\n"
    },
    {
        "timestamp": "2015-03-23 07:38:04,215",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/0e58e0f8-5d97-4013-9ef9-0ebd45f66d93/hive_2015-03-23_07-36-23_257_5266898328579080744-1/-mr-10003/b24f6a47-f496-416c-ae1d-7004b9e5acbd/map.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/filecache/34/map.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 07:38:04,243",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/0e58e0f8-5d97-4013-9ef9-0ebd45f66d93/hive_2015-03-23_07-36-23_257_5266898328579080744-1/-mr-10003/b24f6a47-f496-416c-ae1d-7004b9e5acbd/reduce.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/filecache/35/reduce.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 07:38:04,738",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0031/job.jar(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0031/filecache/10/job.jar) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 07:38:04,794",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0031/job.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0031/filecache/11/job.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 07:38:04,794",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0031_01_000142 transitioned from LOCALIZING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 07:38:04,931",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0031_01_000142 transitioned from LOCALIZED to RUNNING\n"
    },
    {
        "timestamp": "2015-03-23 07:38:04,937",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " launchContainer: [bash, /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0031/container_1427088391284_0031_01_000142/default_container_executor.sh]\n"
    },
    {
        "timestamp": "2015-03-23 07:38:05,112",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Starting resource-monitoring for container_1427088391284_0031_01_000142\n"
    },
    {
        "timestamp": "2015-03-23 07:38:05,124",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4295 for container-id container_1427088391284_0031_01_000142: 1.4 MB of 4 GB physical memory used; 10.8 MB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:38:08,233",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4295 for container-id container_1427088391284_0031_01_000142: 49.3 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:38:11,246",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4295 for container-id container_1427088391284_0031_01_000142: 61.6 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:38:14,266",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4295 for container-id container_1427088391284_0031_01_000142: 77.7 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:38:17,367",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4295 for container-id container_1427088391284_0031_01_000142: 85.5 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:38:20,402",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4295 for container-id container_1427088391284_0031_01_000142: 98.6 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:38:23,411",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4295 for container-id container_1427088391284_0031_01_000142: 114.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:38:26,420",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4295 for container-id container_1427088391284_0031_01_000142: 114.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:38:29,434",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4295 for container-id container_1427088391284_0031_01_000142: 115.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:38:32,443",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4295 for container-id container_1427088391284_0031_01_000142: 118.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:38:35,452",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4295 for container-id container_1427088391284_0031_01_000142: 118.2 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:38:38,464",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4295 for container-id container_1427088391284_0031_01_000142: 120.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:38:41,473",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4295 for container-id container_1427088391284_0031_01_000142: 123.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:38:44,482",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4295 for container-id container_1427088391284_0031_01_000142: 126.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:38:47,495",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4295 for container-id container_1427088391284_0031_01_000142: 126.7 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:38:50,504",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4295 for container-id container_1427088391284_0031_01_000142: 126.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:38:53,512",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4295 for container-id container_1427088391284_0031_01_000142: 132.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:38:56,521",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4295 for container-id container_1427088391284_0031_01_000142: 132.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:38:59,534",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4295 for container-id container_1427088391284_0031_01_000142: 132.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:39:02,543",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4295 for container-id container_1427088391284_0031_01_000142: 132.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:39:05,552",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4295 for container-id container_1427088391284_0031_01_000142: 139.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:39:08,565",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4295 for container-id container_1427088391284_0031_01_000142: 139.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:39:11,574",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4295 for container-id container_1427088391284_0031_01_000142: 139.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:39:14,583",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4295 for container-id container_1427088391284_0031_01_000142: 139.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:39:17,596",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4295 for container-id container_1427088391284_0031_01_000142: 139.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:39:20,604",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4295 for container-id container_1427088391284_0031_01_000142: 139.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:39:23,613",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4295 for container-id container_1427088391284_0031_01_000142: 140.1 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:39:26,625",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4295 for container-id container_1427088391284_0031_01_000142: 144.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:39:29,634",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4295 for container-id container_1427088391284_0031_01_000142: 149.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:39:32,643",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4295 for container-id container_1427088391284_0031_01_000142: 149.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:39:35,651",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4295 for container-id container_1427088391284_0031_01_000142: 149.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:39:38,660",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4295 for container-id container_1427088391284_0031_01_000142: 149.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:39:41,669",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4295 for container-id container_1427088391284_0031_01_000142: 149.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:39:44,678",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4295 for container-id container_1427088391284_0031_01_000142: 149.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:39:47,691",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4295 for container-id container_1427088391284_0031_01_000142: 149.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:39:50,700",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4295 for container-id container_1427088391284_0031_01_000142: 149.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:39:53,708",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4295 for container-id container_1427088391284_0031_01_000142: 149.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:39:56,721",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4295 for container-id container_1427088391284_0031_01_000142: 149.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:39:59,729",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4295 for container-id container_1427088391284_0031_01_000142: 155.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:40:02,739",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4295 for container-id container_1427088391284_0031_01_000142: 155.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:40:05,752",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4295 for container-id container_1427088391284_0031_01_000142: 155.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:40:08,761",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4295 for container-id container_1427088391284_0031_01_000142: 155.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:40:11,770",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4295 for container-id container_1427088391284_0031_01_000142: 155.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:40:14,782",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4295 for container-id container_1427088391284_0031_01_000142: 155.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:40:17,800",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4295 for container-id container_1427088391284_0031_01_000142: 154.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:40:20,812",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4295 for container-id container_1427088391284_0031_01_000142: 155.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:40:23,825",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4295 for container-id container_1427088391284_0031_01_000142: 162.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:40:27,025",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4295 for container-id container_1427088391284_0031_01_000142: 167.7 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:40:30,048",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4295 for container-id container_1427088391284_0031_01_000142: 182.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:40:33,067",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4295 for container-id container_1427088391284_0031_01_000142: 183.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:40:36,097",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4295 for container-id container_1427088391284_0031_01_000142: 173.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:40:39,112",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4295 for container-id container_1427088391284_0031_01_000142: 173.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:40:42,149",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4295 for container-id container_1427088391284_0031_01_000142: 170.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:40:45,170",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4295 for container-id container_1427088391284_0031_01_000142: 170.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:40:48,202",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4295 for container-id container_1427088391284_0031_01_000142: 170.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:40:51,227",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4295 for container-id container_1427088391284_0031_01_000142: 170.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:40:54,267",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4295 for container-id container_1427088391284_0031_01_000142: 170.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:40:57,285",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4295 for container-id container_1427088391284_0031_01_000142: 170.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:41:00,299",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4295 for container-id container_1427088391284_0031_01_000142: 170.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:41:03,340",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4295 for container-id container_1427088391284_0031_01_000142: 170.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:41:06,419",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4295 for container-id container_1427088391284_0031_01_000142: 170.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:41:09,439",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4295 for container-id container_1427088391284_0031_01_000142: 170.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:41:12,468",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4295 for container-id container_1427088391284_0031_01_000142: 170.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:41:15,495",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4295 for container-id container_1427088391284_0031_01_000142: 170.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:41:18,515",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4295 for container-id container_1427088391284_0031_01_000142: 170.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:41:21,537",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4295 for container-id container_1427088391284_0031_01_000142: 170.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:41:24,565",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4295 for container-id container_1427088391284_0031_01_000142: 170.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:41:25,248",
        "type": "INFO",
        "app": "SecurityLogger.org.apache.hadoop.ipc.Server",
        "message": " Auth successful for appattempt_1427088391284_0031_000001 (auth:SIMPLE)\n"
    },
    {
        "timestamp": "2015-03-23 07:41:25,250",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Stopping container with container Id: container_1427088391284_0031_01_000142\n"
    },
    {
        "timestamp": "2015-03-23 07:41:25,250",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tIP=172.31.16.243\tOPERATION=Stop Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0031\tCONTAINERID=container_1427088391284_0031_01_000142\n"
    },
    {
        "timestamp": "2015-03-23 07:41:25,250",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0031_01_000142 transitioned from RUNNING to KILLING\n"
    },
    {
        "timestamp": "2015-03-23 07:41:25,251",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch",
        "message": " Cleaning up container container_1427088391284_0031_01_000142\n"
    },
    {
        "timestamp": "2015-03-23 07:41:25,361",
        "type": "WARN",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Exit code from container container_1427088391284_0031_01_000142 is : 143\n"
    },
    {
        "timestamp": "2015-03-23 07:41:25,393",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0031_01_000142 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL\n"
    },
    {
        "timestamp": "2015-03-23 07:41:25,394",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Deleting absolute path : /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0031/container_1427088391284_0031_01_000142\n"
    },
    {
        "timestamp": "2015-03-23 07:41:25,396",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tOPERATION=Container Finished - Killed\tTARGET=ContainerImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0031\tCONTAINERID=container_1427088391284_0031_01_000142\n"
    },
    {
        "timestamp": "2015-03-23 07:41:25,396",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0031_01_000142 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE\n"
    },
    {
        "timestamp": "2015-03-23 07:41:25,396",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Removing container_1427088391284_0031_01_000142 from application application_1427088391284_0031\n"
    },
    {
        "timestamp": "2015-03-23 07:41:25,396",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event CONTAINER_STOP for appId application_1427088391284_0031\n"
    },
    {
        "timestamp": "2015-03-23 07:41:27,565",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Stopping resource-monitoring for container_1427088391284_0031_01_000142\n"
    },
    {
        "timestamp": "2015-03-23 07:41:28,259",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl",
        "message": " Removed completed containers from NM context: [container_1427088391284_0031_01_000142]\n"
    },
    {
        "timestamp": "2015-03-23 07:41:39,315",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0031 transitioned from RUNNING to APPLICATION_RESOURCES_CLEANINGUP\n"
    },
    {
        "timestamp": "2015-03-23 07:41:39,316",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event APPLICATION_STOP for appId application_1427088391284_0031\n"
    },
    {
        "timestamp": "2015-03-23 07:41:39,316",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0031 transitioned from APPLICATION_RESOURCES_CLEANINGUP to FINISHED\n"
    },
    {
        "timestamp": "2015-03-23 07:41:39,316",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler",
        "message": " Scheduling Log Deletion for application: application_1427088391284_0031, with delay of 172800 seconds\n"
    },
    {
        "timestamp": "2015-03-23 07:41:39,317",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Deleting absolute path : /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0031\n"
    },
    {
        "timestamp": "2015-03-23 07:47:08,309",
        "type": "INFO",
        "app": "SecurityLogger.org.apache.hadoop.ipc.Server",
        "message": " Auth successful for appattempt_1427088391284_0033_000001 (auth:SIMPLE)\n"
    },
    {
        "timestamp": "2015-03-23 07:47:08,509",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Start request for container_1427088391284_0033_01_000013 by user ubuntu\n"
    },
    {
        "timestamp": "2015-03-23 07:47:08,509",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Creating a new application reference for app application_1427088391284_0033\n"
    },
    {
        "timestamp": "2015-03-23 07:47:08,510",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0033 transitioned from NEW to INITING\n"
    },
    {
        "timestamp": "2015-03-23 07:47:08,510",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0033 transitioned from INITING to RUNNING\n"
    },
    {
        "timestamp": "2015-03-23 07:47:08,510",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Adding container_1427088391284_0033_01_000013 to application application_1427088391284_0033\n"
    },
    {
        "timestamp": "2015-03-23 07:47:08,510",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0033_01_000013 transitioned from NEW to LOCALIZING\n"
    },
    {
        "timestamp": "2015-03-23 07:47:08,511",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event CONTAINER_INIT for appId application_1427088391284_0033\n"
    },
    {
        "timestamp": "2015-03-23 07:47:08,511",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event APPLICATION_INIT for appId application_1427088391284_0033\n"
    },
    {
        "timestamp": "2015-03-23 07:47:08,511",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got APPLICATION_INIT for service mapreduce_shuffle\n"
    },
    {
        "timestamp": "2015-03-23 07:47:08,511",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Added token for job_1427088391284_0033\n"
    },
    {
        "timestamp": "2015-03-23 07:47:08,511",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/0791ee76-16ee-4e9d-8b4d-8a170e8f575b/hive_2015-03-23_07-42-33_393_6776348628762449545-1/-mr-10007/749b7837-38b8-46b7-b18a-e646342f55d8/map.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 07:47:08,511",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/0791ee76-16ee-4e9d-8b4d-8a170e8f575b/hive_2015-03-23_07-42-33_393_6776348628762449545-1/-mr-10007/749b7837-38b8-46b7-b18a-e646342f55d8/reduce.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 07:47:08,511",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0033/job.jar transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 07:47:08,511",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0033/job.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 07:47:08,511",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService",
        "message": " Created localizer for container_1427088391284_0033_01_000013\n"
    },
    {
        "timestamp": "2015-03-23 07:47:08,512",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tIP=172.31.16.248\tOPERATION=Start Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0033\tCONTAINERID=container_1427088391284_0033_01_000013\n"
    },
    {
        "timestamp": "2015-03-23 07:47:08,516",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService",
        "message": " Writing credentials to the nmPrivate file /tmp/hadoop-ubuntu/nm-local-dir/nmPrivate/container_1427088391284_0033_01_000013.tokens. Credentials list: \n"
    },
    {
        "timestamp": "2015-03-23 07:47:08,562",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Initializing user ubuntu\n"
    },
    {
        "timestamp": "2015-03-23 07:47:08,565",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Copying from /tmp/hadoop-ubuntu/nm-local-dir/nmPrivate/container_1427088391284_0033_01_000013.tokens to /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0033/container_1427088391284_0033_01_000013.tokens\n"
    },
    {
        "timestamp": "2015-03-23 07:47:08,565",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Localizer CWD set to /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0033 = file:/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0033\n"
    },
    {
        "timestamp": "2015-03-23 07:47:08,803",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/0791ee76-16ee-4e9d-8b4d-8a170e8f575b/hive_2015-03-23_07-42-33_393_6776348628762449545-1/-mr-10007/749b7837-38b8-46b7-b18a-e646342f55d8/map.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/filecache/36/map.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 07:47:08,843",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/0791ee76-16ee-4e9d-8b4d-8a170e8f575b/hive_2015-03-23_07-42-33_393_6776348628762449545-1/-mr-10007/749b7837-38b8-46b7-b18a-e646342f55d8/reduce.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/filecache/37/reduce.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 07:47:09,368",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0033/job.jar(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0033/filecache/10/job.jar) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 07:47:09,517",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0033/job.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0033/filecache/11/job.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 07:47:09,518",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0033_01_000013 transitioned from LOCALIZING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 07:47:09,601",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0033_01_000013 transitioned from LOCALIZED to RUNNING\n"
    },
    {
        "timestamp": "2015-03-23 07:47:09,608",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " launchContainer: [bash, /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0033/container_1427088391284_0033_01_000013/default_container_executor.sh]\n"
    },
    {
        "timestamp": "2015-03-23 07:47:12,619",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Starting resource-monitoring for container_1427088391284_0033_01_000013\n"
    },
    {
        "timestamp": "2015-03-23 07:47:12,629",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4460 for container-id container_1427088391284_0033_01_000013: 48.3 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:47:15,747",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4460 for container-id container_1427088391284_0033_01_000013: 60.5 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:47:18,786",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4460 for container-id container_1427088391284_0033_01_000013: 77.4 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:47:21,838",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4460 for container-id container_1427088391284_0033_01_000013: 94.3 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:47:24,878",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4460 for container-id container_1427088391284_0033_01_000013: 100.3 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:47:27,943",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4460 for container-id container_1427088391284_0033_01_000013: 129.5 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:47:30,979",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4460 for container-id container_1427088391284_0033_01_000013: 206.2 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:47:34,009",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4460 for container-id container_1427088391284_0033_01_000013: 206.8 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:47:36,986",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch",
        "message": " Container container_1427088391284_0033_01_000013 succeeded \n"
    },
    {
        "timestamp": "2015-03-23 07:47:36,986",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0033_01_000013 transitioned from RUNNING to EXITED_WITH_SUCCESS\n"
    },
    {
        "timestamp": "2015-03-23 07:47:36,986",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch",
        "message": " Cleaning up container container_1427088391284_0033_01_000013\n"
    },
    {
        "timestamp": "2015-03-23 07:47:37,042",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4460 for container-id container_1427088391284_0033_01_000013: 0B of 4 GB physical memory used; 0B of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:47:37,054",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Deleting absolute path : /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0033/container_1427088391284_0033_01_000013\n"
    },
    {
        "timestamp": "2015-03-23 07:47:37,056",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tOPERATION=Container Finished - Succeeded\tTARGET=ContainerImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0033\tCONTAINERID=container_1427088391284_0033_01_000013\n"
    },
    {
        "timestamp": "2015-03-23 07:47:37,056",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0033_01_000013 transitioned from EXITED_WITH_SUCCESS to DONE\n"
    },
    {
        "timestamp": "2015-03-23 07:47:37,056",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Removing container_1427088391284_0033_01_000013 from application application_1427088391284_0033\n"
    },
    {
        "timestamp": "2015-03-23 07:47:37,056",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event CONTAINER_STOP for appId application_1427088391284_0033\n"
    },
    {
        "timestamp": "2015-03-23 07:47:37,129",
        "type": "INFO",
        "app": "SecurityLogger.org.apache.hadoop.ipc.Server",
        "message": " Auth successful for appattempt_1427088391284_0033_000001 (auth:SIMPLE)\n"
    },
    {
        "timestamp": "2015-03-23 07:47:37,173",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Stopping container with container Id: container_1427088391284_0033_01_000013\n"
    },
    {
        "timestamp": "2015-03-23 07:47:37,173",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tIP=172.31.16.248\tOPERATION=Stop Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0033\tCONTAINERID=container_1427088391284_0033_01_000013\n"
    },
    {
        "timestamp": "2015-03-23 07:47:40,042",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Stopping resource-monitoring for container_1427088391284_0033_01_000013\n"
    },
    {
        "timestamp": "2015-03-23 07:47:40,194",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl",
        "message": " Removed completed containers from NM context: [container_1427088391284_0033_01_000013]\n"
    },
    {
        "timestamp": "2015-03-23 07:47:55,407",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:47:55,738",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:47:55,801",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:47:55,951",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:47:56,133",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:47:56,164",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:47:56,183",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:47:56,193",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:47:56,237",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:47:56,320",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:47:56,328",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:47:56,467",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:47:56,491",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:47:56,585",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:47:56,593",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:47:56,659",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:47:56,719",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:47:56,770",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:47:56,846",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:47:56,856",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:47:56,858",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:47:56,868",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:47:56,896",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:47:56,905",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:47:56,911",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:47:56,942",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:47:56,960",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:47:56,982",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:47:56,989",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:47:57,108",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:47:57,263",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:47:57,306",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:47:57,668",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:47:57,680",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:47:57,799",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:47:57,831",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:47:57,925",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:47:57,929",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:47:57,967",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:47:58,165",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:47:58,189",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:47:58,306",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:47:58,411",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:47:58,421",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:47:58,480",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:47:58,590",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:48:17,113",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:48:17,165",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:48:41,230",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 07:48:49,406",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0033 transitioned from RUNNING to APPLICATION_RESOURCES_CLEANINGUP\n"
    },
    {
        "timestamp": "2015-03-23 07:48:49,407",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event APPLICATION_STOP for appId application_1427088391284_0033\n"
    },
    {
        "timestamp": "2015-03-23 07:48:49,407",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0033 transitioned from APPLICATION_RESOURCES_CLEANINGUP to FINISHED\n"
    },
    {
        "timestamp": "2015-03-23 07:48:49,408",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler",
        "message": " Scheduling Log Deletion for application: application_1427088391284_0033, with delay of 172800 seconds\n"
    },
    {
        "timestamp": "2015-03-23 07:48:49,408",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Deleting absolute path : /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0033\n"
    },
    {
        "timestamp": "2015-03-23 07:53:12,970",
        "type": "INFO",
        "app": "SecurityLogger.org.apache.hadoop.ipc.Server",
        "message": " Auth successful for appattempt_1427088391284_0035_000001 (auth:SIMPLE)\n"
    },
    {
        "timestamp": "2015-03-23 07:53:13,365",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Start request for container_1427088391284_0035_01_000100 by user ubuntu\n"
    },
    {
        "timestamp": "2015-03-23 07:53:13,365",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Creating a new application reference for app application_1427088391284_0035\n"
    },
    {
        "timestamp": "2015-03-23 07:53:13,366",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0035 transitioned from NEW to INITING\n"
    },
    {
        "timestamp": "2015-03-23 07:53:13,366",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0035 transitioned from INITING to RUNNING\n"
    },
    {
        "timestamp": "2015-03-23 07:53:13,366",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Adding container_1427088391284_0035_01_000100 to application application_1427088391284_0035\n"
    },
    {
        "timestamp": "2015-03-23 07:53:13,367",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0035_01_000100 transitioned from NEW to LOCALIZING\n"
    },
    {
        "timestamp": "2015-03-23 07:53:13,367",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event CONTAINER_INIT for appId application_1427088391284_0035\n"
    },
    {
        "timestamp": "2015-03-23 07:53:13,367",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event APPLICATION_INIT for appId application_1427088391284_0035\n"
    },
    {
        "timestamp": "2015-03-23 07:53:13,367",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got APPLICATION_INIT for service mapreduce_shuffle\n"
    },
    {
        "timestamp": "2015-03-23 07:53:13,367",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Added token for job_1427088391284_0035\n"
    },
    {
        "timestamp": "2015-03-23 07:53:13,367",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/59ae480c-39ea-454c-87ca-9468093fc979/hive_2015-03-23_07-51-30_695_1981469612471560189-1/-mr-10003/e9d7416d-0d94-4961-973d-5edfbbb9a72e/map.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 07:53:13,367",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/59ae480c-39ea-454c-87ca-9468093fc979/hive_2015-03-23_07-51-30_695_1981469612471560189-1/-mr-10003/e9d7416d-0d94-4961-973d-5edfbbb9a72e/reduce.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 07:53:13,368",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0035/job.jar transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 07:53:13,368",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0035/job.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 07:53:13,368",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService",
        "message": " Created localizer for container_1427088391284_0035_01_000100\n"
    },
    {
        "timestamp": "2015-03-23 07:53:13,368",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tIP=172.31.17.105\tOPERATION=Start Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0035\tCONTAINERID=container_1427088391284_0035_01_000100\n"
    },
    {
        "timestamp": "2015-03-23 07:53:13,373",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService",
        "message": " Writing credentials to the nmPrivate file /tmp/hadoop-ubuntu/nm-local-dir/nmPrivate/container_1427088391284_0035_01_000100.tokens. Credentials list: \n"
    },
    {
        "timestamp": "2015-03-23 07:53:13,428",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Initializing user ubuntu\n"
    },
    {
        "timestamp": "2015-03-23 07:53:13,432",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Copying from /tmp/hadoop-ubuntu/nm-local-dir/nmPrivate/container_1427088391284_0035_01_000100.tokens to /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0035/container_1427088391284_0035_01_000100.tokens\n"
    },
    {
        "timestamp": "2015-03-23 07:53:13,432",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Localizer CWD set to /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0035 = file:/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0035\n"
    },
    {
        "timestamp": "2015-03-23 07:53:13,711",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/59ae480c-39ea-454c-87ca-9468093fc979/hive_2015-03-23_07-51-30_695_1981469612471560189-1/-mr-10003/e9d7416d-0d94-4961-973d-5edfbbb9a72e/map.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/filecache/38/map.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 07:53:13,762",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/59ae480c-39ea-454c-87ca-9468093fc979/hive_2015-03-23_07-51-30_695_1981469612471560189-1/-mr-10003/e9d7416d-0d94-4961-973d-5edfbbb9a72e/reduce.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/filecache/39/reduce.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 07:53:14,239",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0035/job.jar(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0035/filecache/10/job.jar) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 07:53:14,292",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0035/job.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0035/filecache/11/job.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 07:53:14,293",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0035_01_000100 transitioned from LOCALIZING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 07:53:14,351",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0035_01_000100 transitioned from LOCALIZED to RUNNING\n"
    },
    {
        "timestamp": "2015-03-23 07:53:14,357",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " launchContainer: [bash, /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0035/container_1427088391284_0035_01_000100/default_container_executor.sh]\n"
    },
    {
        "timestamp": "2015-03-23 07:53:16,060",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Starting resource-monitoring for container_1427088391284_0035_01_000100\n"
    },
    {
        "timestamp": "2015-03-23 07:53:16,073",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4580 for container-id container_1427088391284_0035_01_000100: 42.5 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:53:19,091",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4580 for container-id container_1427088391284_0035_01_000100: 56.4 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:53:22,146",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4580 for container-id container_1427088391284_0035_01_000100: 75.0 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:53:25,231",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4580 for container-id container_1427088391284_0035_01_000100: 83.0 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:53:28,248",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4580 for container-id container_1427088391284_0035_01_000100: 93.2 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:53:31,277",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4580 for container-id container_1427088391284_0035_01_000100: 101.7 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:53:34,286",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4580 for container-id container_1427088391284_0035_01_000100: 115.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:53:37,294",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4580 for container-id container_1427088391284_0035_01_000100: 117.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:53:40,307",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4580 for container-id container_1427088391284_0035_01_000100: 119.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:53:43,316",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4580 for container-id container_1427088391284_0035_01_000100: 123.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:53:46,324",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4580 for container-id container_1427088391284_0035_01_000100: 123.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:53:49,333",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4580 for container-id container_1427088391284_0035_01_000100: 130.7 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:53:52,345",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4580 for container-id container_1427088391284_0035_01_000100: 130.7 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:53:55,353",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4580 for container-id container_1427088391284_0035_01_000100: 130.7 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:53:58,361",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4580 for container-id container_1427088391284_0035_01_000100: 130.7 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:54:01,401",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4580 for container-id container_1427088391284_0035_01_000100: 130.7 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:54:04,419",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4580 for container-id container_1427088391284_0035_01_000100: 134.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:54:07,428",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4580 for container-id container_1427088391284_0035_01_000100: 134.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:54:10,441",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4580 for container-id container_1427088391284_0035_01_000100: 134.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:54:13,450",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4580 for container-id container_1427088391284_0035_01_000100: 134.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:54:16,463",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4580 for container-id container_1427088391284_0035_01_000100: 134.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:54:19,475",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4580 for container-id container_1427088391284_0035_01_000100: 134.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:54:22,483",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4580 for container-id container_1427088391284_0035_01_000100: 136.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:54:25,496",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4580 for container-id container_1427088391284_0035_01_000100: 143.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:54:28,505",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4580 for container-id container_1427088391284_0035_01_000100: 143.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:54:31,514",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4580 for container-id container_1427088391284_0035_01_000100: 143.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:54:34,523",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4580 for container-id container_1427088391284_0035_01_000100: 143.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:54:37,532",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4580 for container-id container_1427088391284_0035_01_000100: 143.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:54:40,544",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4580 for container-id container_1427088391284_0035_01_000100: 143.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:54:43,552",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4580 for container-id container_1427088391284_0035_01_000100: 143.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:54:46,561",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4580 for container-id container_1427088391284_0035_01_000100: 150.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:54:49,573",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4580 for container-id container_1427088391284_0035_01_000100: 150.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:54:52,582",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4580 for container-id container_1427088391284_0035_01_000100: 150.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:54:55,591",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4580 for container-id container_1427088391284_0035_01_000100: 151.2 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:54:58,621",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4580 for container-id container_1427088391284_0035_01_000100: 151.1 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:55:01,669",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4580 for container-id container_1427088391284_0035_01_000100: 151.2 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:55:04,687",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4580 for container-id container_1427088391284_0035_01_000100: 159.1 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:55:07,725",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4580 for container-id container_1427088391284_0035_01_000100: 163.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:55:10,807",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4580 for container-id container_1427088391284_0035_01_000100: 168.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:55:13,838",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4580 for container-id container_1427088391284_0035_01_000100: 168.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:55:16,886",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4580 for container-id container_1427088391284_0035_01_000100: 166.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:55:19,927",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4580 for container-id container_1427088391284_0035_01_000100: 166.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:55:22,940",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4580 for container-id container_1427088391284_0035_01_000100: 166.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:55:25,974",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4580 for container-id container_1427088391284_0035_01_000100: 166.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:55:29,032",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4580 for container-id container_1427088391284_0035_01_000100: 166.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:55:32,045",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4580 for container-id container_1427088391284_0035_01_000100: 166.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:55:35,058",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4580 for container-id container_1427088391284_0035_01_000100: 166.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:55:38,117",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4580 for container-id container_1427088391284_0035_01_000100: 166.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:55:41,203",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4580 for container-id container_1427088391284_0035_01_000100: 166.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:55:44,330",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4580 for container-id container_1427088391284_0035_01_000100: 166.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:55:47,370",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4580 for container-id container_1427088391284_0035_01_000100: 166.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:55:50,402",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4580 for container-id container_1427088391284_0035_01_000100: 166.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:55:53,437",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4580 for container-id container_1427088391284_0035_01_000100: 166.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:55:56,473",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4580 for container-id container_1427088391284_0035_01_000100: 166.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:55:59,561",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4580 for container-id container_1427088391284_0035_01_000100: 166.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 07:56:02,376",
        "type": "INFO",
        "app": "SecurityLogger.org.apache.hadoop.ipc.Server",
        "message": " Auth successful for appattempt_1427088391284_0035_000001 (auth:SIMPLE)\n"
    },
    {
        "timestamp": "2015-03-23 07:56:02,379",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Stopping container with container Id: container_1427088391284_0035_01_000100\n"
    },
    {
        "timestamp": "2015-03-23 07:56:02,379",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tIP=172.31.17.105\tOPERATION=Stop Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0035\tCONTAINERID=container_1427088391284_0035_01_000100\n"
    },
    {
        "timestamp": "2015-03-23 07:56:02,380",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0035_01_000100 transitioned from RUNNING to KILLING\n"
    },
    {
        "timestamp": "2015-03-23 07:56:02,380",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch",
        "message": " Cleaning up container container_1427088391284_0035_01_000100\n"
    },
    {
        "timestamp": "2015-03-23 07:56:02,483",
        "type": "WARN",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Exit code from container container_1427088391284_0035_01_000100 is : 143\n"
    },
    {
        "timestamp": "2015-03-23 07:56:02,531",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0035_01_000100 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL\n"
    },
    {
        "timestamp": "2015-03-23 07:56:02,532",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Deleting absolute path : /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0035/container_1427088391284_0035_01_000100\n"
    },
    {
        "timestamp": "2015-03-23 07:56:02,534",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tOPERATION=Container Finished - Killed\tTARGET=ContainerImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0035\tCONTAINERID=container_1427088391284_0035_01_000100\n"
    },
    {
        "timestamp": "2015-03-23 07:56:02,535",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0035_01_000100 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE\n"
    },
    {
        "timestamp": "2015-03-23 07:56:02,535",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Removing container_1427088391284_0035_01_000100 from application application_1427088391284_0035\n"
    },
    {
        "timestamp": "2015-03-23 07:56:02,535",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event CONTAINER_STOP for appId application_1427088391284_0035\n"
    },
    {
        "timestamp": "2015-03-23 07:56:02,561",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Stopping resource-monitoring for container_1427088391284_0035_01_000100\n"
    },
    {
        "timestamp": "2015-03-23 07:56:05,390",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl",
        "message": " Removed completed containers from NM context: [container_1427088391284_0035_01_000100]\n"
    },
    {
        "timestamp": "2015-03-23 07:58:35,941",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0035 transitioned from RUNNING to APPLICATION_RESOURCES_CLEANINGUP\n"
    },
    {
        "timestamp": "2015-03-23 07:58:35,942",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event APPLICATION_STOP for appId application_1427088391284_0035\n"
    },
    {
        "timestamp": "2015-03-23 07:58:35,942",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0035 transitioned from APPLICATION_RESOURCES_CLEANINGUP to FINISHED\n"
    },
    {
        "timestamp": "2015-03-23 07:58:35,942",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler",
        "message": " Scheduling Log Deletion for application: application_1427088391284_0035, with delay of 172800 seconds\n"
    },
    {
        "timestamp": "2015-03-23 07:58:35,943",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Deleting absolute path : /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0035\n"
    },
    {
        "timestamp": "2015-03-23 08:00:21,145",
        "type": "WARN",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Event EventType: KILL_CONTAINER sent to absent container container_1427088391284_0036_01_000220\n"
    },
    {
        "timestamp": "2015-03-23 08:00:23,208",
        "type": "WARN",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Event EventType: KILL_CONTAINER sent to absent container container_1427088391284_0036_01_000234\n"
    },
    {
        "timestamp": "2015-03-23 08:03:45,793",
        "type": "WARN",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Event EventType: FINISH_APPLICATION sent to absent application application_1427088391284_0036\n"
    },
    {
        "timestamp": "2015-03-23 08:04:15,861",
        "type": "WARN",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Event EventType: KILL_CONTAINER sent to absent container container_1427088391284_0037_01_000067\n"
    },
    {
        "timestamp": "2015-03-23 08:05:31,850",
        "type": "WARN",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Event EventType: FINISH_APPLICATION sent to absent application application_1427088391284_0037\n"
    },
    {
        "timestamp": "2015-03-23 08:06:02,306",
        "type": "INFO",
        "app": "SecurityLogger.org.apache.hadoop.ipc.Server",
        "message": " Auth successful for appattempt_1427088391284_0038_000001 (auth:SIMPLE)\n"
    },
    {
        "timestamp": "2015-03-23 08:06:02,967",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Start request for container_1427088391284_0038_01_000019 by user ubuntu\n"
    },
    {
        "timestamp": "2015-03-23 08:06:02,967",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Creating a new application reference for app application_1427088391284_0038\n"
    },
    {
        "timestamp": "2015-03-23 08:06:02,968",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0038 transitioned from NEW to INITING\n"
    },
    {
        "timestamp": "2015-03-23 08:06:02,968",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0038 transitioned from INITING to RUNNING\n"
    },
    {
        "timestamp": "2015-03-23 08:06:02,968",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Adding container_1427088391284_0038_01_000019 to application application_1427088391284_0038\n"
    },
    {
        "timestamp": "2015-03-23 08:06:02,969",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0038_01_000019 transitioned from NEW to LOCALIZING\n"
    },
    {
        "timestamp": "2015-03-23 08:06:02,969",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event CONTAINER_INIT for appId application_1427088391284_0038\n"
    },
    {
        "timestamp": "2015-03-23 08:06:02,969",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event APPLICATION_INIT for appId application_1427088391284_0038\n"
    },
    {
        "timestamp": "2015-03-23 08:06:02,969",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got APPLICATION_INIT for service mapreduce_shuffle\n"
    },
    {
        "timestamp": "2015-03-23 08:06:02,969",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Added token for job_1427088391284_0038\n"
    },
    {
        "timestamp": "2015-03-23 08:06:02,969",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/5698ba89-3dcc-41fd-a4b7-c500b088846b/hive_2015-03-23_07-59-30_107_3637327864679408176-1/-mr-10009/34258a29-8dae-4660-b4f8-efe4c530d9e3/map.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 08:06:02,969",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/5698ba89-3dcc-41fd-a4b7-c500b088846b/hive_2015-03-23_07-59-30_107_3637327864679408176-1/-mr-10009/34258a29-8dae-4660-b4f8-efe4c530d9e3/reduce.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 08:06:02,970",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0038/job.jar transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 08:06:02,970",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0038/job.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 08:06:02,970",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService",
        "message": " Created localizer for container_1427088391284_0038_01_000019\n"
    },
    {
        "timestamp": "2015-03-23 08:06:02,970",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tIP=172.31.17.21\tOPERATION=Start Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0038\tCONTAINERID=container_1427088391284_0038_01_000019\n"
    },
    {
        "timestamp": "2015-03-23 08:06:03,011",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService",
        "message": " Writing credentials to the nmPrivate file /tmp/hadoop-ubuntu/nm-local-dir/nmPrivate/container_1427088391284_0038_01_000019.tokens. Credentials list: \n"
    },
    {
        "timestamp": "2015-03-23 08:06:03,033",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Initializing user ubuntu\n"
    },
    {
        "timestamp": "2015-03-23 08:06:03,061",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Copying from /tmp/hadoop-ubuntu/nm-local-dir/nmPrivate/container_1427088391284_0038_01_000019.tokens to /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0038/container_1427088391284_0038_01_000019.tokens\n"
    },
    {
        "timestamp": "2015-03-23 08:06:03,061",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Localizer CWD set to /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0038 = file:/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0038\n"
    },
    {
        "timestamp": "2015-03-23 08:06:03,290",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/5698ba89-3dcc-41fd-a4b7-c500b088846b/hive_2015-03-23_07-59-30_107_3637327864679408176-1/-mr-10009/34258a29-8dae-4660-b4f8-efe4c530d9e3/map.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/filecache/40/map.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 08:06:03,450",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/5698ba89-3dcc-41fd-a4b7-c500b088846b/hive_2015-03-23_07-59-30_107_3637327864679408176-1/-mr-10009/34258a29-8dae-4660-b4f8-efe4c530d9e3/reduce.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/filecache/41/reduce.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 08:06:04,106",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0038/job.jar(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0038/filecache/10/job.jar) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 08:06:04,136",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0038/job.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0038/filecache/11/job.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 08:06:04,136",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0038_01_000019 transitioned from LOCALIZING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 08:06:04,221",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0038_01_000019 transitioned from LOCALIZED to RUNNING\n"
    },
    {
        "timestamp": "2015-03-23 08:06:04,228",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " launchContainer: [bash, /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0038/container_1427088391284_0038_01_000019/default_container_executor.sh]\n"
    },
    {
        "timestamp": "2015-03-23 08:06:05,604",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Starting resource-monitoring for container_1427088391284_0038_01_000019\n"
    },
    {
        "timestamp": "2015-03-23 08:06:05,617",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4770 for container-id container_1427088391284_0038_01_000019: 40.9 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:06:08,649",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4770 for container-id container_1427088391284_0038_01_000019: 55.1 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:06:11,671",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4770 for container-id container_1427088391284_0038_01_000019: 72.3 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:06:14,803",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4770 for container-id container_1427088391284_0038_01_000019: 82.5 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:06:17,851",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4770 for container-id container_1427088391284_0038_01_000019: 91.8 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:06:20,865",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4770 for container-id container_1427088391284_0038_01_000019: 97.8 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:06:23,882",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4770 for container-id container_1427088391284_0038_01_000019: 204.2 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:06:26,910",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4770 for container-id container_1427088391284_0038_01_000019: 204.8 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:06:29,922",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4770 for container-id container_1427088391284_0038_01_000019: 205.3 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:06:31,243",
        "type": "INFO",
        "app": "SecurityLogger.org.apache.hadoop.ipc.Server",
        "message": " Auth successful for appattempt_1427088391284_0038_000001 (auth:SIMPLE)\n"
    },
    {
        "timestamp": "2015-03-23 08:06:31,292",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Stopping container with container Id: container_1427088391284_0038_01_000019\n"
    },
    {
        "timestamp": "2015-03-23 08:06:31,292",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tIP=172.31.17.21\tOPERATION=Stop Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0038\tCONTAINERID=container_1427088391284_0038_01_000019\n"
    },
    {
        "timestamp": "2015-03-23 08:06:31,292",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0038_01_000019 transitioned from RUNNING to KILLING\n"
    },
    {
        "timestamp": "2015-03-23 08:06:31,292",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch",
        "message": " Cleaning up container container_1427088391284_0038_01_000019\n"
    },
    {
        "timestamp": "2015-03-23 08:06:31,316",
        "type": "WARN",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Exit code from container container_1427088391284_0038_01_000019 is : 143\n"
    },
    {
        "timestamp": "2015-03-23 08:06:31,364",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0038_01_000019 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL\n"
    },
    {
        "timestamp": "2015-03-23 08:06:31,365",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Deleting absolute path : /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0038/container_1427088391284_0038_01_000019\n"
    },
    {
        "timestamp": "2015-03-23 08:06:31,367",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tOPERATION=Container Finished - Killed\tTARGET=ContainerImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0038\tCONTAINERID=container_1427088391284_0038_01_000019\n"
    },
    {
        "timestamp": "2015-03-23 08:06:31,367",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0038_01_000019 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE\n"
    },
    {
        "timestamp": "2015-03-23 08:06:31,367",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Removing container_1427088391284_0038_01_000019 from application application_1427088391284_0038\n"
    },
    {
        "timestamp": "2015-03-23 08:06:31,367",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event CONTAINER_STOP for appId application_1427088391284_0038\n"
    },
    {
        "timestamp": "2015-03-23 08:06:32,923",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Stopping resource-monitoring for container_1427088391284_0038_01_000019\n"
    },
    {
        "timestamp": "2015-03-23 08:06:34,300",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl",
        "message": " Removed completed containers from NM context: [container_1427088391284_0038_01_000019]\n"
    },
    {
        "timestamp": "2015-03-23 08:06:50,974",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 08:07:29,646",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0038 transitioned from RUNNING to APPLICATION_RESOURCES_CLEANINGUP\n"
    },
    {
        "timestamp": "2015-03-23 08:07:29,647",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event APPLICATION_STOP for appId application_1427088391284_0038\n"
    },
    {
        "timestamp": "2015-03-23 08:07:29,647",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0038 transitioned from APPLICATION_RESOURCES_CLEANINGUP to FINISHED\n"
    },
    {
        "timestamp": "2015-03-23 08:07:29,647",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler",
        "message": " Scheduling Log Deletion for application: application_1427088391284_0038, with delay of 172800 seconds\n"
    },
    {
        "timestamp": "2015-03-23 08:07:29,647",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Deleting absolute path : /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0038\n"
    },
    {
        "timestamp": "2015-03-23 08:10:00,411",
        "type": "INFO",
        "app": "SecurityLogger.org.apache.hadoop.ipc.Server",
        "message": " Auth successful for appattempt_1427088391284_0039_000001 (auth:SIMPLE)\n"
    },
    {
        "timestamp": "2015-03-23 08:10:00,629",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Start request for container_1427088391284_0039_01_000217 by user ubuntu\n"
    },
    {
        "timestamp": "2015-03-23 08:10:00,630",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Creating a new application reference for app application_1427088391284_0039\n"
    },
    {
        "timestamp": "2015-03-23 08:10:00,630",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0039 transitioned from NEW to INITING\n"
    },
    {
        "timestamp": "2015-03-23 08:10:00,630",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0039 transitioned from INITING to RUNNING\n"
    },
    {
        "timestamp": "2015-03-23 08:10:00,630",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Adding container_1427088391284_0039_01_000217 to application application_1427088391284_0039\n"
    },
    {
        "timestamp": "2015-03-23 08:10:00,631",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0039_01_000217 transitioned from NEW to LOCALIZING\n"
    },
    {
        "timestamp": "2015-03-23 08:10:00,631",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event CONTAINER_INIT for appId application_1427088391284_0039\n"
    },
    {
        "timestamp": "2015-03-23 08:10:00,631",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event APPLICATION_INIT for appId application_1427088391284_0039\n"
    },
    {
        "timestamp": "2015-03-23 08:10:00,631",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got APPLICATION_INIT for service mapreduce_shuffle\n"
    },
    {
        "timestamp": "2015-03-23 08:10:00,631",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Added token for job_1427088391284_0039\n"
    },
    {
        "timestamp": "2015-03-23 08:10:00,632",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/ef684482-be63-4b87-b4e4-180ea4391a83/hive_2015-03-23_08-08-21_409_3435124625394566529-1/-mr-10003/cc5167ef-4f89-4e26-adaa-54ba4ace2674/map.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 08:10:00,632",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/ef684482-be63-4b87-b4e4-180ea4391a83/hive_2015-03-23_08-08-21_409_3435124625394566529-1/-mr-10003/cc5167ef-4f89-4e26-adaa-54ba4ace2674/reduce.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 08:10:00,632",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0039/job.jar transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 08:10:00,632",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0039/job.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 08:10:00,632",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService",
        "message": " Created localizer for container_1427088391284_0039_01_000217\n"
    },
    {
        "timestamp": "2015-03-23 08:10:00,632",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tIP=172.31.17.20\tOPERATION=Start Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0039\tCONTAINERID=container_1427088391284_0039_01_000217\n"
    },
    {
        "timestamp": "2015-03-23 08:10:00,642",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService",
        "message": " Writing credentials to the nmPrivate file /tmp/hadoop-ubuntu/nm-local-dir/nmPrivate/container_1427088391284_0039_01_000217.tokens. Credentials list: \n"
    },
    {
        "timestamp": "2015-03-23 08:10:00,694",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Initializing user ubuntu\n"
    },
    {
        "timestamp": "2015-03-23 08:10:00,697",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Copying from /tmp/hadoop-ubuntu/nm-local-dir/nmPrivate/container_1427088391284_0039_01_000217.tokens to /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0039/container_1427088391284_0039_01_000217.tokens\n"
    },
    {
        "timestamp": "2015-03-23 08:10:00,697",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Localizer CWD set to /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0039 = file:/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0039\n"
    },
    {
        "timestamp": "2015-03-23 08:10:01,087",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/ef684482-be63-4b87-b4e4-180ea4391a83/hive_2015-03-23_08-08-21_409_3435124625394566529-1/-mr-10003/cc5167ef-4f89-4e26-adaa-54ba4ace2674/map.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/filecache/42/map.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 08:10:01,141",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/ef684482-be63-4b87-b4e4-180ea4391a83/hive_2015-03-23_08-08-21_409_3435124625394566529-1/-mr-10003/cc5167ef-4f89-4e26-adaa-54ba4ace2674/reduce.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/filecache/43/reduce.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 08:10:01,751",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0039/job.jar(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0039/filecache/10/job.jar) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 08:10:01,859",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0039/job.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0039/filecache/11/job.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 08:10:01,860",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0039_01_000217 transitioned from LOCALIZING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 08:10:02,108",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0039_01_000217 transitioned from LOCALIZED to RUNNING\n"
    },
    {
        "timestamp": "2015-03-23 08:10:02,115",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " launchContainer: [bash, /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0039/container_1427088391284_0039_01_000217/default_container_executor.sh]\n"
    },
    {
        "timestamp": "2015-03-23 08:10:02,931",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Starting resource-monitoring for container_1427088391284_0039_01_000217\n"
    },
    {
        "timestamp": "2015-03-23 08:10:03,016",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4877 for container-id container_1427088391284_0039_01_000217: 27.9 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:10:06,046",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4877 for container-id container_1427088391284_0039_01_000217: 50.2 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:10:09,140",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4877 for container-id container_1427088391284_0039_01_000217: 67.8 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:10:12,165",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4877 for container-id container_1427088391284_0039_01_000217: 81.1 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:10:15,176",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4877 for container-id container_1427088391284_0039_01_000217: 95 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:10:18,297",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4877 for container-id container_1427088391284_0039_01_000217: 93.9 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:10:21,306",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4877 for container-id container_1427088391284_0039_01_000217: 110.7 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:10:24,315",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4877 for container-id container_1427088391284_0039_01_000217: 108.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:10:27,328",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4877 for container-id container_1427088391284_0039_01_000217: 108.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:10:30,337",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4877 for container-id container_1427088391284_0039_01_000217: 115.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:10:33,346",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4877 for container-id container_1427088391284_0039_01_000217: 115.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:10:36,355",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4877 for container-id container_1427088391284_0039_01_000217: 125.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:10:39,367",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4877 for container-id container_1427088391284_0039_01_000217: 125.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:10:42,377",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4877 for container-id container_1427088391284_0039_01_000217: 125.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:10:45,385",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4877 for container-id container_1427088391284_0039_01_000217: 125.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:10:48,398",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4877 for container-id container_1427088391284_0039_01_000217: 125.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:10:51,411",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4877 for container-id container_1427088391284_0039_01_000217: 126.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:10:54,420",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4877 for container-id container_1427088391284_0039_01_000217: 126.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:10:57,432",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4877 for container-id container_1427088391284_0039_01_000217: 126.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:11:00,442",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4877 for container-id container_1427088391284_0039_01_000217: 126.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:11:03,450",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4877 for container-id container_1427088391284_0039_01_000217: 126.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:11:06,465",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4877 for container-id container_1427088391284_0039_01_000217: 128.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:11:09,474",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4877 for container-id container_1427088391284_0039_01_000217: 130.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:11:12,484",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4877 for container-id container_1427088391284_0039_01_000217: 137.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:11:15,493",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4877 for container-id container_1427088391284_0039_01_000217: 137.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:11:18,507",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4877 for container-id container_1427088391284_0039_01_000217: 137.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:11:21,517",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4877 for container-id container_1427088391284_0039_01_000217: 137.7 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:11:24,527",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4877 for container-id container_1427088391284_0039_01_000217: 137.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:11:27,540",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4877 for container-id container_1427088391284_0039_01_000217: 137.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:11:30,585",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4877 for container-id container_1427088391284_0039_01_000217: 145.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:11:33,672",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4877 for container-id container_1427088391284_0039_01_000217: 152.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:11:36,713",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4877 for container-id container_1427088391284_0039_01_000217: 155.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:11:39,747",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4877 for container-id container_1427088391284_0039_01_000217: 172.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:11:42,784",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4877 for container-id container_1427088391284_0039_01_000217: 173.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:11:45,828",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4877 for container-id container_1427088391284_0039_01_000217: 170.2 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:11:48,850",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4877 for container-id container_1427088391284_0039_01_000217: 170.2 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:11:51,868",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4877 for container-id container_1427088391284_0039_01_000217: 170.2 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:11:54,892",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4877 for container-id container_1427088391284_0039_01_000217: 170.2 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:11:57,927",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4877 for container-id container_1427088391284_0039_01_000217: 170.2 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:12:01,008",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4877 for container-id container_1427088391284_0039_01_000217: 170.2 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:12:04,021",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4877 for container-id container_1427088391284_0039_01_000217: 170.2 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:12:07,147",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4877 for container-id container_1427088391284_0039_01_000217: 170.2 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:12:10,173",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4877 for container-id container_1427088391284_0039_01_000217: 170.2 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:12:13,203",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4877 for container-id container_1427088391284_0039_01_000217: 170.2 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:12:16,242",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4877 for container-id container_1427088391284_0039_01_000217: 170.2 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:12:19,273",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4877 for container-id container_1427088391284_0039_01_000217: 170.2 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:12:22,301",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4877 for container-id container_1427088391284_0039_01_000217: 170.2 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:12:25,329",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4877 for container-id container_1427088391284_0039_01_000217: 170.2 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:12:28,349",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4877 for container-id container_1427088391284_0039_01_000217: 170.2 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:12:30,504",
        "type": "INFO",
        "app": "SecurityLogger.org.apache.hadoop.ipc.Server",
        "message": " Auth successful for appattempt_1427088391284_0039_000001 (auth:SIMPLE)\n"
    },
    {
        "timestamp": "2015-03-23 08:12:30,508",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Stopping container with container Id: container_1427088391284_0039_01_000217\n"
    },
    {
        "timestamp": "2015-03-23 08:12:30,508",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tIP=172.31.17.20\tOPERATION=Stop Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0039\tCONTAINERID=container_1427088391284_0039_01_000217\n"
    },
    {
        "timestamp": "2015-03-23 08:12:30,508",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0039_01_000217 transitioned from RUNNING to KILLING\n"
    },
    {
        "timestamp": "2015-03-23 08:12:30,508",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch",
        "message": " Cleaning up container container_1427088391284_0039_01_000217\n"
    },
    {
        "timestamp": "2015-03-23 08:12:30,537",
        "type": "WARN",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Exit code from container container_1427088391284_0039_01_000217 is : 143\n"
    },
    {
        "timestamp": "2015-03-23 08:12:30,583",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0039_01_000217 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL\n"
    },
    {
        "timestamp": "2015-03-23 08:12:30,584",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Deleting absolute path : /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0039/container_1427088391284_0039_01_000217\n"
    },
    {
        "timestamp": "2015-03-23 08:12:30,587",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tOPERATION=Container Finished - Killed\tTARGET=ContainerImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0039\tCONTAINERID=container_1427088391284_0039_01_000217\n"
    },
    {
        "timestamp": "2015-03-23 08:12:30,587",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0039_01_000217 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE\n"
    },
    {
        "timestamp": "2015-03-23 08:12:30,587",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Removing container_1427088391284_0039_01_000217 from application application_1427088391284_0039\n"
    },
    {
        "timestamp": "2015-03-23 08:12:30,587",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event CONTAINER_STOP for appId application_1427088391284_0039\n"
    },
    {
        "timestamp": "2015-03-23 08:12:31,349",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Stopping resource-monitoring for container_1427088391284_0039_01_000217\n"
    },
    {
        "timestamp": "2015-03-23 08:12:33,516",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl",
        "message": " Removed completed containers from NM context: [container_1427088391284_0039_01_000217]\n"
    },
    {
        "timestamp": "2015-03-23 08:12:49,634",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0039 transitioned from RUNNING to APPLICATION_RESOURCES_CLEANINGUP\n"
    },
    {
        "timestamp": "2015-03-23 08:12:49,635",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event APPLICATION_STOP for appId application_1427088391284_0039\n"
    },
    {
        "timestamp": "2015-03-23 08:12:49,635",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0039 transitioned from APPLICATION_RESOURCES_CLEANINGUP to FINISHED\n"
    },
    {
        "timestamp": "2015-03-23 08:12:49,635",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler",
        "message": " Scheduling Log Deletion for application: application_1427088391284_0039, with delay of 172800 seconds\n"
    },
    {
        "timestamp": "2015-03-23 08:12:49,635",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Deleting absolute path : /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0039\n"
    },
    {
        "timestamp": "2015-03-23 08:14:35,878",
        "type": "INFO",
        "app": "SecurityLogger.org.apache.hadoop.ipc.Server",
        "message": " Auth successful for appattempt_1427088391284_0040_000001 (auth:SIMPLE)\n"
    },
    {
        "timestamp": "2015-03-23 08:14:36,354",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Start request for container_1427088391284_0040_01_000125 by user ubuntu\n"
    },
    {
        "timestamp": "2015-03-23 08:14:36,354",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Creating a new application reference for app application_1427088391284_0040\n"
    },
    {
        "timestamp": "2015-03-23 08:14:36,354",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0040 transitioned from NEW to INITING\n"
    },
    {
        "timestamp": "2015-03-23 08:14:36,355",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0040 transitioned from INITING to RUNNING\n"
    },
    {
        "timestamp": "2015-03-23 08:14:36,355",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Adding container_1427088391284_0040_01_000125 to application application_1427088391284_0040\n"
    },
    {
        "timestamp": "2015-03-23 08:14:36,355",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0040_01_000125 transitioned from NEW to LOCALIZING\n"
    },
    {
        "timestamp": "2015-03-23 08:14:36,355",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event CONTAINER_INIT for appId application_1427088391284_0040\n"
    },
    {
        "timestamp": "2015-03-23 08:14:36,355",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event APPLICATION_INIT for appId application_1427088391284_0040\n"
    },
    {
        "timestamp": "2015-03-23 08:14:36,355",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got APPLICATION_INIT for service mapreduce_shuffle\n"
    },
    {
        "timestamp": "2015-03-23 08:14:36,356",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Added token for job_1427088391284_0040\n"
    },
    {
        "timestamp": "2015-03-23 08:14:36,356",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/928a6bd2-21cd-4e4d-8f4a-3d14312fcdf7/hive_2015-03-23_08-13-42_966_5760904413752083122-1/-mr-10005/f71e1466-a5e4-4f87-bee3-130320e5aa7b/map.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 08:14:36,356",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/928a6bd2-21cd-4e4d-8f4a-3d14312fcdf7/hive_2015-03-23_08-13-42_966_5760904413752083122-1/-mr-10005/f71e1466-a5e4-4f87-bee3-130320e5aa7b/reduce.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 08:14:36,356",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0040/job.jar transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 08:14:36,356",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0040/job.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 08:14:36,356",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService",
        "message": " Created localizer for container_1427088391284_0040_01_000125\n"
    },
    {
        "timestamp": "2015-03-23 08:14:36,357",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tIP=172.31.16.214\tOPERATION=Start Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0040\tCONTAINERID=container_1427088391284_0040_01_000125\n"
    },
    {
        "timestamp": "2015-03-23 08:14:36,361",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService",
        "message": " Writing credentials to the nmPrivate file /tmp/hadoop-ubuntu/nm-local-dir/nmPrivate/container_1427088391284_0040_01_000125.tokens. Credentials list: \n"
    },
    {
        "timestamp": "2015-03-23 08:14:36,407",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Initializing user ubuntu\n"
    },
    {
        "timestamp": "2015-03-23 08:14:36,411",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Copying from /tmp/hadoop-ubuntu/nm-local-dir/nmPrivate/container_1427088391284_0040_01_000125.tokens to /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0040/container_1427088391284_0040_01_000125.tokens\n"
    },
    {
        "timestamp": "2015-03-23 08:14:36,411",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Localizer CWD set to /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0040 = file:/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0040\n"
    },
    {
        "timestamp": "2015-03-23 08:14:36,663",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/928a6bd2-21cd-4e4d-8f4a-3d14312fcdf7/hive_2015-03-23_08-13-42_966_5760904413752083122-1/-mr-10005/f71e1466-a5e4-4f87-bee3-130320e5aa7b/map.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/filecache/44/map.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 08:14:36,824",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/928a6bd2-21cd-4e4d-8f4a-3d14312fcdf7/hive_2015-03-23_08-13-42_966_5760904413752083122-1/-mr-10005/f71e1466-a5e4-4f87-bee3-130320e5aa7b/reduce.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/filecache/45/reduce.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 08:14:37,412",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0040/job.jar(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0040/filecache/10/job.jar) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 08:14:37,487",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0040/job.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0040/filecache/11/job.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 08:14:37,487",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0040_01_000125 transitioned from LOCALIZING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 08:14:37,565",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0040_01_000125 transitioned from LOCALIZED to RUNNING\n"
    },
    {
        "timestamp": "2015-03-23 08:14:37,599",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " launchContainer: [bash, /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0040/container_1427088391284_0040_01_000125/default_container_executor.sh]\n"
    },
    {
        "timestamp": "2015-03-23 08:14:40,355",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Starting resource-monitoring for container_1427088391284_0040_01_000125\n"
    },
    {
        "timestamp": "2015-03-23 08:14:40,369",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4994 for container-id container_1427088391284_0040_01_000125: 49.7 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:14:43,393",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4994 for container-id container_1427088391284_0040_01_000125: 59.4 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:14:46,474",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4994 for container-id container_1427088391284_0040_01_000125: 78.0 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:14:49,512",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4994 for container-id container_1427088391284_0040_01_000125: 87.7 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:14:52,542",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4994 for container-id container_1427088391284_0040_01_000125: 100.3 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:14:55,627",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4994 for container-id container_1427088391284_0040_01_000125: 109.9 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:14:58,648",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4994 for container-id container_1427088391284_0040_01_000125: 216.7 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:15:01,730",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4994 for container-id container_1427088391284_0040_01_000125: 218.3 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:15:04,747",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4994 for container-id container_1427088391284_0040_01_000125: 218.3 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:15:07,794",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4994 for container-id container_1427088391284_0040_01_000125: 218.6 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:15:09,195",
        "type": "INFO",
        "app": "SecurityLogger.org.apache.hadoop.ipc.Server",
        "message": " Auth successful for appattempt_1427088391284_0040_000001 (auth:SIMPLE)\n"
    },
    {
        "timestamp": "2015-03-23 08:15:09,540",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Start request for container_1427088391284_0040_01_000179 by user ubuntu\n"
    },
    {
        "timestamp": "2015-03-23 08:15:09,540",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Adding container_1427088391284_0040_01_000179 to application application_1427088391284_0040\n"
    },
    {
        "timestamp": "2015-03-23 08:15:09,541",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0040_01_000179 transitioned from NEW to LOCALIZING\n"
    },
    {
        "timestamp": "2015-03-23 08:15:09,541",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event CONTAINER_INIT for appId application_1427088391284_0040\n"
    },
    {
        "timestamp": "2015-03-23 08:15:09,541",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event APPLICATION_INIT for appId application_1427088391284_0040\n"
    },
    {
        "timestamp": "2015-03-23 08:15:09,541",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got APPLICATION_INIT for service mapreduce_shuffle\n"
    },
    {
        "timestamp": "2015-03-23 08:15:09,541",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Added token for job_1427088391284_0040\n"
    },
    {
        "timestamp": "2015-03-23 08:15:09,542",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0040_01_000179 transitioned from LOCALIZING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 08:15:09,545",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tIP=172.31.16.214\tOPERATION=Start Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0040\tCONTAINERID=container_1427088391284_0040_01_000179\n"
    },
    {
        "timestamp": "2015-03-23 08:15:09,627",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0040_01_000179 transitioned from LOCALIZED to RUNNING\n"
    },
    {
        "timestamp": "2015-03-23 08:15:09,633",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " launchContainer: [bash, /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0040/container_1427088391284_0040_01_000179/default_container_executor.sh]\n"
    },
    {
        "timestamp": "2015-03-23 08:15:10,801",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Starting resource-monitoring for container_1427088391284_0040_01_000179\n"
    },
    {
        "timestamp": "2015-03-23 08:15:10,829",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5031 for container-id container_1427088391284_0040_01_000179: 20.9 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:15:10,877",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4994 for container-id container_1427088391284_0040_01_000125: 218.6 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:15:13,915",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5031 for container-id container_1427088391284_0040_01_000179: 46.1 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:15:14,017",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4994 for container-id container_1427088391284_0040_01_000125: 218.9 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:15:17,048",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5031 for container-id container_1427088391284_0040_01_000179: 51.6 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:15:17,141",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4994 for container-id container_1427088391284_0040_01_000125: 218.9 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:15:20,172",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5031 for container-id container_1427088391284_0040_01_000179: 58.2 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:15:20,205",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4994 for container-id container_1427088391284_0040_01_000125: 218.9 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:15:23,237",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5031 for container-id container_1427088391284_0040_01_000179: 66.0 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:15:23,279",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4994 for container-id container_1427088391284_0040_01_000125: 218.9 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:15:26,310",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5031 for container-id container_1427088391284_0040_01_000179: 71.4 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:15:26,350",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4994 for container-id container_1427088391284_0040_01_000125: 218.9 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:15:29,391",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5031 for container-id container_1427088391284_0040_01_000179: 75.6 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:15:29,425",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4994 for container-id container_1427088391284_0040_01_000125: 218.9 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:15:32,458",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5031 for container-id container_1427088391284_0040_01_000179: 79.9 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:15:32,495",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4994 for container-id container_1427088391284_0040_01_000125: 218.9 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:15:35,540",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5031 for container-id container_1427088391284_0040_01_000179: 83.7 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:15:35,630",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4994 for container-id container_1427088391284_0040_01_000125: 218.9 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:15:38,656",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5031 for container-id container_1427088391284_0040_01_000179: 92.5 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:15:38,693",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4994 for container-id container_1427088391284_0040_01_000125: 218.9 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:15:41,725",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5031 for container-id container_1427088391284_0040_01_000179: 85.9 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:15:41,763",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4994 for container-id container_1427088391284_0040_01_000125: 218.9 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:15:44,829",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5031 for container-id container_1427088391284_0040_01_000179: 91.1 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:15:44,842",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4994 for container-id container_1427088391284_0040_01_000125: 218.9 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:15:47,876",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5031 for container-id container_1427088391284_0040_01_000179: 101.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:15:47,983",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4994 for container-id container_1427088391284_0040_01_000125: 218.9 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:15:51,008",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5031 for container-id container_1427088391284_0040_01_000179: 109.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:15:51,042",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4994 for container-id container_1427088391284_0040_01_000125: 218.9 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:15:54,081",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5031 for container-id container_1427088391284_0040_01_000179: 109.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:15:54,090",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4994 for container-id container_1427088391284_0040_01_000125: 218.9 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:15:57,127",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5031 for container-id container_1427088391284_0040_01_000179: 109.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:15:57,139",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4994 for container-id container_1427088391284_0040_01_000125: 219.1 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:16:00,167",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5031 for container-id container_1427088391284_0040_01_000179: 112.1 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:16:00,260",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4994 for container-id container_1427088391284_0040_01_000125: 219.1 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:16:03,284",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5031 for container-id container_1427088391284_0040_01_000179: 112.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:16:03,377",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4994 for container-id container_1427088391284_0040_01_000125: 219.1 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:16:06,399",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5031 for container-id container_1427088391284_0040_01_000179: 112.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:16:06,455",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4994 for container-id container_1427088391284_0040_01_000125: 219.1 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:16:09,545",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5031 for container-id container_1427088391284_0040_01_000179: 112.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:16:09,554",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4994 for container-id container_1427088391284_0040_01_000125: 219.1 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:16:12,581",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5031 for container-id container_1427088391284_0040_01_000179: 113.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:16:12,619",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4994 for container-id container_1427088391284_0040_01_000125: 219.1 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:16:15,636",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5031 for container-id container_1427088391284_0040_01_000179: 113.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:16:15,717",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4994 for container-id container_1427088391284_0040_01_000125: 219.1 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:16:18,757",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5031 for container-id container_1427088391284_0040_01_000179: 113.2 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:16:18,838",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4994 for container-id container_1427088391284_0040_01_000125: 219.1 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:16:21,871",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5031 for container-id container_1427088391284_0040_01_000179: 113.2 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:16:21,911",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 4994 for container-id container_1427088391284_0040_01_000125: 219.1 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:16:23,583",
        "type": "INFO",
        "app": "SecurityLogger.org.apache.hadoop.ipc.Server",
        "message": " Auth successful for appattempt_1427088391284_0040_000001 (auth:SIMPLE)\n"
    },
    {
        "timestamp": "2015-03-23 08:16:23,585",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Stopping container with container Id: container_1427088391284_0040_01_000125\n"
    },
    {
        "timestamp": "2015-03-23 08:16:23,585",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tIP=172.31.16.214\tOPERATION=Stop Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0040\tCONTAINERID=container_1427088391284_0040_01_000125\n"
    },
    {
        "timestamp": "2015-03-23 08:16:23,585",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0040_01_000125 transitioned from RUNNING to KILLING\n"
    },
    {
        "timestamp": "2015-03-23 08:16:23,586",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch",
        "message": " Cleaning up container container_1427088391284_0040_01_000125\n"
    },
    {
        "timestamp": "2015-03-23 08:16:23,630",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 08:16:23,640",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 08:16:23,677",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 08:16:23,679",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 08:16:23,681",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 08:16:23,768",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 08:16:23,771",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 08:16:23,776",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 08:16:23,778",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 08:16:23,785",
        "type": "WARN",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Exit code from container container_1427088391284_0040_01_000125 is : 143\n"
    },
    {
        "timestamp": "2015-03-23 08:16:23,811",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 08:16:23,812",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 08:16:23,814",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 08:16:23,825",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 08:16:23,826",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 08:16:23,827",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 08:16:23,829",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 08:16:23,832",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 08:16:23,864",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 08:16:23,866",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 08:16:23,913",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 08:16:23,915",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0040_01_000125 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL\n"
    },
    {
        "timestamp": "2015-03-23 08:16:23,916",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 08:16:23,918",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Deleting absolute path : /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0040/container_1427088391284_0040_01_000125\n"
    },
    {
        "timestamp": "2015-03-23 08:16:23,923",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 08:16:23,925",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tOPERATION=Container Finished - Killed\tTARGET=ContainerImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0040\tCONTAINERID=container_1427088391284_0040_01_000125\n"
    },
    {
        "timestamp": "2015-03-23 08:16:23,925",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0040_01_000125 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE\n"
    },
    {
        "timestamp": "2015-03-23 08:16:23,925",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Removing container_1427088391284_0040_01_000125 from application application_1427088391284_0040\n"
    },
    {
        "timestamp": "2015-03-23 08:16:23,925",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event CONTAINER_STOP for appId application_1427088391284_0040\n"
    },
    {
        "timestamp": "2015-03-23 08:16:23,928",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 08:16:23,930",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 08:16:23,956",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 08:16:23,959",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 08:16:24,005",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 08:16:24,006",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 08:16:24,016",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 08:16:24,017",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 08:16:24,222",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 08:16:24,241",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 08:16:24,308",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 08:16:24,312",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 08:16:24,314",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 08:16:24,316",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 08:16:24,318",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 08:16:24,322",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 08:16:24,334",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 08:16:24,340",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 08:16:24,359",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 08:16:24,444",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 08:16:24,483",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 08:16:24,552",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 08:16:24,555",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 08:16:24,568",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 08:16:24,569",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 08:16:24,574",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 08:16:24,911",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Stopping resource-monitoring for container_1427088391284_0040_01_000125\n"
    },
    {
        "timestamp": "2015-03-23 08:16:24,919",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5031 for container-id container_1427088391284_0040_01_000179: 114.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:16:26,596",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl",
        "message": " Removed completed containers from NM context: [container_1427088391284_0040_01_000125]\n"
    },
    {
        "timestamp": "2015-03-23 08:16:27,928",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5031 for container-id container_1427088391284_0040_01_000179: 114.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:16:30,940",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5031 for container-id container_1427088391284_0040_01_000179: 114.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:16:33,948",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5031 for container-id container_1427088391284_0040_01_000179: 114.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:16:36,957",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5031 for container-id container_1427088391284_0040_01_000179: 114.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:16:39,970",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5031 for container-id container_1427088391284_0040_01_000179: 114.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:16:42,978",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5031 for container-id container_1427088391284_0040_01_000179: 114.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:16:45,987",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5031 for container-id container_1427088391284_0040_01_000179: 114.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:16:48,999",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5031 for container-id container_1427088391284_0040_01_000179: 114.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:16:52,019",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5031 for container-id container_1427088391284_0040_01_000179: 116.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:16:55,027",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5031 for container-id container_1427088391284_0040_01_000179: 116.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:16:58,036",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5031 for container-id container_1427088391284_0040_01_000179: 116.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:17:01,048",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5031 for container-id container_1427088391284_0040_01_000179: 116.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:17:04,058",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5031 for container-id container_1427088391284_0040_01_000179: 116.1 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:17:07,067",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5031 for container-id container_1427088391284_0040_01_000179: 116.1 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:17:10,079",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5031 for container-id container_1427088391284_0040_01_000179: 116.1 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:17:13,088",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5031 for container-id container_1427088391284_0040_01_000179: 116.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:17:16,096",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5031 for container-id container_1427088391284_0040_01_000179: 118.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:17:19,108",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5031 for container-id container_1427088391284_0040_01_000179: 121.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:17:22,118",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5031 for container-id container_1427088391284_0040_01_000179: 121.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:17:25,127",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5031 for container-id container_1427088391284_0040_01_000179: 121.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:17:28,172",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5031 for container-id container_1427088391284_0040_01_000179: 120.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:17:31,185",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5031 for container-id container_1427088391284_0040_01_000179: 128.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:17:34,236",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5031 for container-id container_1427088391284_0040_01_000179: 131.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:17:37,270",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5031 for container-id container_1427088391284_0040_01_000179: 135.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:17:40,297",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5031 for container-id container_1427088391284_0040_01_000179: 144.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:17:43,317",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5031 for container-id container_1427088391284_0040_01_000179: 161.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:17:43,528",
        "type": "INFO",
        "app": "SecurityLogger.org.apache.hadoop.ipc.Server",
        "message": " Auth successful for appattempt_1427088391284_0040_000001 (auth:SIMPLE)\n"
    },
    {
        "timestamp": "2015-03-23 08:17:43,530",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Stopping container with container Id: container_1427088391284_0040_01_000179\n"
    },
    {
        "timestamp": "2015-03-23 08:17:43,530",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tIP=172.31.16.214\tOPERATION=Stop Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0040\tCONTAINERID=container_1427088391284_0040_01_000179\n"
    },
    {
        "timestamp": "2015-03-23 08:17:43,530",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0040_01_000179 transitioned from RUNNING to KILLING\n"
    },
    {
        "timestamp": "2015-03-23 08:17:43,530",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch",
        "message": " Cleaning up container container_1427088391284_0040_01_000179\n"
    },
    {
        "timestamp": "2015-03-23 08:17:43,660",
        "type": "WARN",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Exit code from container container_1427088391284_0040_01_000179 is : 143\n"
    },
    {
        "timestamp": "2015-03-23 08:17:43,671",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0040_01_000179 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL\n"
    },
    {
        "timestamp": "2015-03-23 08:17:43,672",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Deleting absolute path : /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0040/container_1427088391284_0040_01_000179\n"
    },
    {
        "timestamp": "2015-03-23 08:17:43,674",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tOPERATION=Container Finished - Killed\tTARGET=ContainerImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0040\tCONTAINERID=container_1427088391284_0040_01_000179\n"
    },
    {
        "timestamp": "2015-03-23 08:17:43,674",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0040_01_000179 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE\n"
    },
    {
        "timestamp": "2015-03-23 08:17:43,674",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Removing container_1427088391284_0040_01_000179 from application application_1427088391284_0040\n"
    },
    {
        "timestamp": "2015-03-23 08:17:43,674",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event CONTAINER_STOP for appId application_1427088391284_0040\n"
    },
    {
        "timestamp": "2015-03-23 08:17:46,318",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Stopping resource-monitoring for container_1427088391284_0040_01_000179\n"
    },
    {
        "timestamp": "2015-03-23 08:17:47,640",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl",
        "message": " Removed completed containers from NM context: [container_1427088391284_0040_01_000179]\n"
    },
    {
        "timestamp": "2015-03-23 08:17:57,699",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0040 transitioned from RUNNING to APPLICATION_RESOURCES_CLEANINGUP\n"
    },
    {
        "timestamp": "2015-03-23 08:17:57,700",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event APPLICATION_STOP for appId application_1427088391284_0040\n"
    },
    {
        "timestamp": "2015-03-23 08:17:57,701",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0040 transitioned from APPLICATION_RESOURCES_CLEANINGUP to FINISHED\n"
    },
    {
        "timestamp": "2015-03-23 08:17:57,701",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler",
        "message": " Scheduling Log Deletion for application: application_1427088391284_0040, with delay of 172800 seconds\n"
    },
    {
        "timestamp": "2015-03-23 08:17:57,700",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Deleting absolute path : /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0040\n"
    },
    {
        "timestamp": "2015-03-23 08:20:09,027",
        "type": "WARN",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Event EventType: KILL_CONTAINER sent to absent container container_1427088391284_0042_01_000071\n"
    },
    {
        "timestamp": "2015-03-23 08:21:34,223",
        "type": "WARN",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Event EventType: FINISH_APPLICATION sent to absent application application_1427088391284_0042\n"
    },
    {
        "timestamp": "2015-03-23 08:24:11,024",
        "type": "INFO",
        "app": "SecurityLogger.org.apache.hadoop.ipc.Server",
        "message": " Auth successful for appattempt_1427088391284_0043_000001 (auth:SIMPLE)\n"
    },
    {
        "timestamp": "2015-03-23 08:24:11,317",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Start request for container_1427088391284_0043_01_000189 by user ubuntu\n"
    },
    {
        "timestamp": "2015-03-23 08:24:11,317",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Creating a new application reference for app application_1427088391284_0043\n"
    },
    {
        "timestamp": "2015-03-23 08:24:11,318",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0043 transitioned from NEW to INITING\n"
    },
    {
        "timestamp": "2015-03-23 08:24:11,318",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0043 transitioned from INITING to RUNNING\n"
    },
    {
        "timestamp": "2015-03-23 08:24:11,318",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Adding container_1427088391284_0043_01_000189 to application application_1427088391284_0043\n"
    },
    {
        "timestamp": "2015-03-23 08:24:11,319",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0043_01_000189 transitioned from NEW to LOCALIZING\n"
    },
    {
        "timestamp": "2015-03-23 08:24:11,319",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event CONTAINER_INIT for appId application_1427088391284_0043\n"
    },
    {
        "timestamp": "2015-03-23 08:24:11,319",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event APPLICATION_INIT for appId application_1427088391284_0043\n"
    },
    {
        "timestamp": "2015-03-23 08:24:11,319",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got APPLICATION_INIT for service mapreduce_shuffle\n"
    },
    {
        "timestamp": "2015-03-23 08:24:11,319",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Added token for job_1427088391284_0043\n"
    },
    {
        "timestamp": "2015-03-23 08:24:11,319",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/eac88314-d5a2-48cc-b0f0-c70bfc4a4bf0/hive_2015-03-23_08-22-26_205_3353145891180710084-1/-mr-10003/97e1a2be-9e43-475c-a59e-d92fec6ee4d0/map.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 08:24:11,319",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/eac88314-d5a2-48cc-b0f0-c70bfc4a4bf0/hive_2015-03-23_08-22-26_205_3353145891180710084-1/-mr-10003/97e1a2be-9e43-475c-a59e-d92fec6ee4d0/reduce.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 08:24:11,320",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0043/job.jar transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 08:24:11,320",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0043/job.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 08:24:11,320",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService",
        "message": " Created localizer for container_1427088391284_0043_01_000189\n"
    },
    {
        "timestamp": "2015-03-23 08:24:11,320",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tIP=172.31.16.214\tOPERATION=Start Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0043\tCONTAINERID=container_1427088391284_0043_01_000189\n"
    },
    {
        "timestamp": "2015-03-23 08:24:11,325",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService",
        "message": " Writing credentials to the nmPrivate file /tmp/hadoop-ubuntu/nm-local-dir/nmPrivate/container_1427088391284_0043_01_000189.tokens. Credentials list: \n"
    },
    {
        "timestamp": "2015-03-23 08:24:11,345",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Initializing user ubuntu\n"
    },
    {
        "timestamp": "2015-03-23 08:24:11,348",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Copying from /tmp/hadoop-ubuntu/nm-local-dir/nmPrivate/container_1427088391284_0043_01_000189.tokens to /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0043/container_1427088391284_0043_01_000189.tokens\n"
    },
    {
        "timestamp": "2015-03-23 08:24:11,348",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Localizer CWD set to /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0043 = file:/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0043\n"
    },
    {
        "timestamp": "2015-03-23 08:24:11,564",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/eac88314-d5a2-48cc-b0f0-c70bfc4a4bf0/hive_2015-03-23_08-22-26_205_3353145891180710084-1/-mr-10003/97e1a2be-9e43-475c-a59e-d92fec6ee4d0/map.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/filecache/46/map.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 08:24:11,630",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/eac88314-d5a2-48cc-b0f0-c70bfc4a4bf0/hive_2015-03-23_08-22-26_205_3353145891180710084-1/-mr-10003/97e1a2be-9e43-475c-a59e-d92fec6ee4d0/reduce.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/filecache/47/reduce.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 08:24:12,093",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0043/job.jar(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0043/filecache/10/job.jar) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 08:24:12,147",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0043/job.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0043/filecache/11/job.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 08:24:12,148",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0043_01_000189 transitioned from LOCALIZING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 08:24:12,205",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0043_01_000189 transitioned from LOCALIZED to RUNNING\n"
    },
    {
        "timestamp": "2015-03-23 08:24:12,212",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " launchContainer: [bash, /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0043/container_1427088391284_0043_01_000189/default_container_executor.sh]\n"
    },
    {
        "timestamp": "2015-03-23 08:24:13,343",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Starting resource-monitoring for container_1427088391284_0043_01_000189\n"
    },
    {
        "timestamp": "2015-03-23 08:24:13,359",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5192 for container-id container_1427088391284_0043_01_000189: 40.0 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:24:16,389",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5192 for container-id container_1427088391284_0043_01_000189: 54.4 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:24:19,406",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5192 for container-id container_1427088391284_0043_01_000189: 72.5 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:24:22,427",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5192 for container-id container_1427088391284_0043_01_000189: 81.0 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:24:25,453",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5192 for container-id container_1427088391284_0043_01_000189: 93.9 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:24:28,466",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5192 for container-id container_1427088391284_0043_01_000189: 98.4 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:24:31,475",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5192 for container-id container_1427088391284_0043_01_000189: 112.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:24:34,487",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5192 for container-id container_1427088391284_0043_01_000189: 113.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:24:37,495",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5192 for container-id container_1427088391284_0043_01_000189: 121.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:24:40,504",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5192 for container-id container_1427088391284_0043_01_000189: 121.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:24:43,518",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5192 for container-id container_1427088391284_0043_01_000189: 121.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:24:46,527",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5192 for container-id container_1427088391284_0043_01_000189: 129.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:24:49,537",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5192 for container-id container_1427088391284_0043_01_000189: 129.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:24:52,547",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5192 for container-id container_1427088391284_0043_01_000189: 129.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:24:55,559",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5192 for container-id container_1427088391284_0043_01_000189: 129.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:24:58,570",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5192 for container-id container_1427088391284_0043_01_000189: 129.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:25:01,580",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5192 for container-id container_1427088391284_0043_01_000189: 132.1 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:25:04,595",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5192 for container-id container_1427088391284_0043_01_000189: 132.1 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:25:07,604",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5192 for container-id container_1427088391284_0043_01_000189: 132.1 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:25:10,616",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5192 for container-id container_1427088391284_0043_01_000189: 131.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:25:13,628",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5192 for container-id container_1427088391284_0043_01_000189: 131.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:25:16,637",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5192 for container-id container_1427088391284_0043_01_000189: 132.1 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:25:19,646",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5192 for container-id container_1427088391284_0043_01_000189: 134.2 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:25:22,658",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5192 for container-id container_1427088391284_0043_01_000189: 136.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:25:25,667",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5192 for container-id container_1427088391284_0043_01_000189: 140.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:25:28,676",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5192 for container-id container_1427088391284_0043_01_000189: 140.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:25:31,751",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5192 for container-id container_1427088391284_0043_01_000189: 141.2 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:25:34,788",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5192 for container-id container_1427088391284_0043_01_000189: 152.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:25:37,824",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5192 for container-id container_1427088391284_0043_01_000189: 157.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:25:40,837",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5192 for container-id container_1427088391284_0043_01_000189: 171.2 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:25:43,853",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5192 for container-id container_1427088391284_0043_01_000189: 164.2 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:25:46,891",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5192 for container-id container_1427088391284_0043_01_000189: 164.2 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:25:50,084",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5192 for container-id container_1427088391284_0043_01_000189: 159.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:25:53,124",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5192 for container-id container_1427088391284_0043_01_000189: 159.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:25:56,154",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5192 for container-id container_1427088391284_0043_01_000189: 159.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:25:59,183",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5192 for container-id container_1427088391284_0043_01_000189: 159.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:26:02,223",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5192 for container-id container_1427088391284_0043_01_000189: 159.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:26:05,244",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5192 for container-id container_1427088391284_0043_01_000189: 159.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:26:08,277",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5192 for container-id container_1427088391284_0043_01_000189: 159.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:26:11,389",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5192 for container-id container_1427088391284_0043_01_000189: 159.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:26:14,425",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5192 for container-id container_1427088391284_0043_01_000189: 159.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:26:17,437",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5192 for container-id container_1427088391284_0043_01_000189: 159.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:26:20,474",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5192 for container-id container_1427088391284_0043_01_000189: 159.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:26:23,532",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5192 for container-id container_1427088391284_0043_01_000189: 159.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:26:26,655",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5192 for container-id container_1427088391284_0043_01_000189: 159.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:26:29,742",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5192 for container-id container_1427088391284_0043_01_000189: 159.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:26:30,456",
        "type": "INFO",
        "app": "SecurityLogger.org.apache.hadoop.ipc.Server",
        "message": " Auth successful for appattempt_1427088391284_0043_000001 (auth:SIMPLE)\n"
    },
    {
        "timestamp": "2015-03-23 08:26:30,458",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Stopping container with container Id: container_1427088391284_0043_01_000189\n"
    },
    {
        "timestamp": "2015-03-23 08:26:30,459",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tIP=172.31.16.214\tOPERATION=Stop Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0043\tCONTAINERID=container_1427088391284_0043_01_000189\n"
    },
    {
        "timestamp": "2015-03-23 08:26:30,459",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0043_01_000189 transitioned from RUNNING to KILLING\n"
    },
    {
        "timestamp": "2015-03-23 08:26:30,459",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch",
        "message": " Cleaning up container container_1427088391284_0043_01_000189\n"
    },
    {
        "timestamp": "2015-03-23 08:26:30,549",
        "type": "WARN",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Exit code from container container_1427088391284_0043_01_000189 is : 143\n"
    },
    {
        "timestamp": "2015-03-23 08:26:30,594",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0043_01_000189 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL\n"
    },
    {
        "timestamp": "2015-03-23 08:26:30,595",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Deleting absolute path : /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0043/container_1427088391284_0043_01_000189\n"
    },
    {
        "timestamp": "2015-03-23 08:26:30,597",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tOPERATION=Container Finished - Killed\tTARGET=ContainerImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0043\tCONTAINERID=container_1427088391284_0043_01_000189\n"
    },
    {
        "timestamp": "2015-03-23 08:26:30,597",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0043_01_000189 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE\n"
    },
    {
        "timestamp": "2015-03-23 08:26:30,597",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Removing container_1427088391284_0043_01_000189 from application application_1427088391284_0043\n"
    },
    {
        "timestamp": "2015-03-23 08:26:30,597",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event CONTAINER_STOP for appId application_1427088391284_0043\n"
    },
    {
        "timestamp": "2015-03-23 08:26:32,742",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Stopping resource-monitoring for container_1427088391284_0043_01_000189\n"
    },
    {
        "timestamp": "2015-03-23 08:26:33,467",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl",
        "message": " Removed completed containers from NM context: [container_1427088391284_0043_01_000189]\n"
    },
    {
        "timestamp": "2015-03-23 08:26:48,530",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0043 transitioned from RUNNING to APPLICATION_RESOURCES_CLEANINGUP\n"
    },
    {
        "timestamp": "2015-03-23 08:26:48,531",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event APPLICATION_STOP for appId application_1427088391284_0043\n"
    },
    {
        "timestamp": "2015-03-23 08:26:48,531",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0043 transitioned from APPLICATION_RESOURCES_CLEANINGUP to FINISHED\n"
    },
    {
        "timestamp": "2015-03-23 08:26:48,532",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler",
        "message": " Scheduling Log Deletion for application: application_1427088391284_0043, with delay of 172800 seconds\n"
    },
    {
        "timestamp": "2015-03-23 08:26:48,532",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Deleting absolute path : /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0043\n"
    },
    {
        "timestamp": "2015-03-23 08:48:52,791",
        "type": "INFO",
        "app": "SecurityLogger.org.apache.hadoop.ipc.Server",
        "message": " Auth successful for appattempt_1427088391284_0050_000001 (auth:SIMPLE)\n"
    },
    {
        "timestamp": "2015-03-23 08:48:53,168",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Start request for container_1427088391284_0050_01_000038 by user ubuntu\n"
    },
    {
        "timestamp": "2015-03-23 08:48:53,168",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Creating a new application reference for app application_1427088391284_0050\n"
    },
    {
        "timestamp": "2015-03-23 08:48:53,169",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0050 transitioned from NEW to INITING\n"
    },
    {
        "timestamp": "2015-03-23 08:48:53,169",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0050 transitioned from INITING to RUNNING\n"
    },
    {
        "timestamp": "2015-03-23 08:48:53,169",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Adding container_1427088391284_0050_01_000038 to application application_1427088391284_0050\n"
    },
    {
        "timestamp": "2015-03-23 08:48:53,170",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0050_01_000038 transitioned from NEW to LOCALIZING\n"
    },
    {
        "timestamp": "2015-03-23 08:48:53,170",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event CONTAINER_INIT for appId application_1427088391284_0050\n"
    },
    {
        "timestamp": "2015-03-23 08:48:53,170",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event APPLICATION_INIT for appId application_1427088391284_0050\n"
    },
    {
        "timestamp": "2015-03-23 08:48:53,170",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got APPLICATION_INIT for service mapreduce_shuffle\n"
    },
    {
        "timestamp": "2015-03-23 08:48:53,170",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Added token for job_1427088391284_0050\n"
    },
    {
        "timestamp": "2015-03-23 08:48:53,170",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/3d5c8399-7cc6-40bf-b564-f4a90a8c3b81/hive_2015-03-23_08-42-19_034_1362371151685462856-1/-mr-10009/d9815b8e-19b4-491c-95cf-9245c0cddcd7/map.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 08:48:53,171",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/3d5c8399-7cc6-40bf-b564-f4a90a8c3b81/hive_2015-03-23_08-42-19_034_1362371151685462856-1/-mr-10009/d9815b8e-19b4-491c-95cf-9245c0cddcd7/reduce.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 08:48:53,171",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0050/job.jar transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 08:48:53,171",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0050/job.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 08:48:53,171",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService",
        "message": " Created localizer for container_1427088391284_0050_01_000038\n"
    },
    {
        "timestamp": "2015-03-23 08:48:53,171",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tIP=172.31.16.229\tOPERATION=Start Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0050\tCONTAINERID=container_1427088391284_0050_01_000038\n"
    },
    {
        "timestamp": "2015-03-23 08:48:53,176",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService",
        "message": " Writing credentials to the nmPrivate file /tmp/hadoop-ubuntu/nm-local-dir/nmPrivate/container_1427088391284_0050_01_000038.tokens. Credentials list: \n"
    },
    {
        "timestamp": "2015-03-23 08:48:53,198",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Initializing user ubuntu\n"
    },
    {
        "timestamp": "2015-03-23 08:48:53,225",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Copying from /tmp/hadoop-ubuntu/nm-local-dir/nmPrivate/container_1427088391284_0050_01_000038.tokens to /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0050/container_1427088391284_0050_01_000038.tokens\n"
    },
    {
        "timestamp": "2015-03-23 08:48:53,225",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Localizer CWD set to /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0050 = file:/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0050\n"
    },
    {
        "timestamp": "2015-03-23 08:48:53,350",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/3d5c8399-7cc6-40bf-b564-f4a90a8c3b81/hive_2015-03-23_08-42-19_034_1362371151685462856-1/-mr-10009/d9815b8e-19b4-491c-95cf-9245c0cddcd7/map.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/filecache/48/map.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 08:48:53,420",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/3d5c8399-7cc6-40bf-b564-f4a90a8c3b81/hive_2015-03-23_08-42-19_034_1362371151685462856-1/-mr-10009/d9815b8e-19b4-491c-95cf-9245c0cddcd7/reduce.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/filecache/49/reduce.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 08:48:54,140",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0050/job.jar(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0050/filecache/10/job.jar) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 08:48:54,198",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0050/job.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0050/filecache/11/job.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 08:48:54,199",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0050_01_000038 transitioned from LOCALIZING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 08:48:54,281",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0050_01_000038 transitioned from LOCALIZED to RUNNING\n"
    },
    {
        "timestamp": "2015-03-23 08:48:54,287",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " launchContainer: [bash, /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0050/container_1427088391284_0050_01_000038/default_container_executor.sh]\n"
    },
    {
        "timestamp": "2015-03-23 08:48:56,797",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Starting resource-monitoring for container_1427088391284_0050_01_000038\n"
    },
    {
        "timestamp": "2015-03-23 08:48:56,878",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5345 for container-id container_1427088391284_0050_01_000038: 47.8 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:48:59,911",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5345 for container-id container_1427088391284_0050_01_000038: 59.1 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:49:02,961",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5345 for container-id container_1427088391284_0050_01_000038: 74.9 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:49:05,974",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5345 for container-id container_1427088391284_0050_01_000038: 86.2 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:49:09,010",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5345 for container-id container_1427088391284_0050_01_000038: 96.7 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:49:12,040",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5345 for container-id container_1427088391284_0050_01_000038: 107.7 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:49:15,063",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5345 for container-id container_1427088391284_0050_01_000038: 211.7 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:49:18,100",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5345 for container-id container_1427088391284_0050_01_000038: 212.4 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:49:21,131",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5345 for container-id container_1427088391284_0050_01_000038: 213.0 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:49:21,860",
        "type": "INFO",
        "app": "SecurityLogger.org.apache.hadoop.ipc.Server",
        "message": " Auth successful for appattempt_1427088391284_0050_000001 (auth:SIMPLE)\n"
    },
    {
        "timestamp": "2015-03-23 08:49:21,947",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Stopping container with container Id: container_1427088391284_0050_01_000038\n"
    },
    {
        "timestamp": "2015-03-23 08:49:21,948",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tIP=172.31.16.229\tOPERATION=Stop Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0050\tCONTAINERID=container_1427088391284_0050_01_000038\n"
    },
    {
        "timestamp": "2015-03-23 08:49:21,948",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0050_01_000038 transitioned from RUNNING to KILLING\n"
    },
    {
        "timestamp": "2015-03-23 08:49:21,948",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch",
        "message": " Cleaning up container container_1427088391284_0050_01_000038\n"
    },
    {
        "timestamp": "2015-03-23 08:49:21,969",
        "type": "WARN",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Exit code from container container_1427088391284_0050_01_000038 is : 143\n"
    },
    {
        "timestamp": "2015-03-23 08:49:22,016",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0050_01_000038 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL\n"
    },
    {
        "timestamp": "2015-03-23 08:49:22,017",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Deleting absolute path : /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0050/container_1427088391284_0050_01_000038\n"
    },
    {
        "timestamp": "2015-03-23 08:49:22,019",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tOPERATION=Container Finished - Killed\tTARGET=ContainerImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0050\tCONTAINERID=container_1427088391284_0050_01_000038\n"
    },
    {
        "timestamp": "2015-03-23 08:49:22,019",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0050_01_000038 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE\n"
    },
    {
        "timestamp": "2015-03-23 08:49:22,019",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Removing container_1427088391284_0050_01_000038 from application application_1427088391284_0050\n"
    },
    {
        "timestamp": "2015-03-23 08:49:22,019",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event CONTAINER_STOP for appId application_1427088391284_0050\n"
    },
    {
        "timestamp": "2015-03-23 08:49:24,131",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Stopping resource-monitoring for container_1427088391284_0050_01_000038\n"
    },
    {
        "timestamp": "2015-03-23 08:49:24,955",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl",
        "message": " Removed completed containers from NM context: [container_1427088391284_0050_01_000038]\n"
    },
    {
        "timestamp": "2015-03-23 08:49:42,071",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 08:50:09,110",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0050 transitioned from RUNNING to APPLICATION_RESOURCES_CLEANINGUP\n"
    },
    {
        "timestamp": "2015-03-23 08:50:09,111",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event APPLICATION_STOP for appId application_1427088391284_0050\n"
    },
    {
        "timestamp": "2015-03-23 08:50:09,111",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0050 transitioned from APPLICATION_RESOURCES_CLEANINGUP to FINISHED\n"
    },
    {
        "timestamp": "2015-03-23 08:50:09,111",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler",
        "message": " Scheduling Log Deletion for application: application_1427088391284_0050, with delay of 172800 seconds\n"
    },
    {
        "timestamp": "2015-03-23 08:50:09,111",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Deleting absolute path : /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0050\n"
    },
    {
        "timestamp": "2015-03-23 08:52:41,520",
        "type": "INFO",
        "app": "SecurityLogger.org.apache.hadoop.ipc.Server",
        "message": " Auth successful for appattempt_1427088391284_0051_000001 (auth:SIMPLE)\n"
    },
    {
        "timestamp": "2015-03-23 08:52:41,742",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Start request for container_1427088391284_0051_01_000209 by user ubuntu\n"
    },
    {
        "timestamp": "2015-03-23 08:52:41,742",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Creating a new application reference for app application_1427088391284_0051\n"
    },
    {
        "timestamp": "2015-03-23 08:52:41,743",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0051 transitioned from NEW to INITING\n"
    },
    {
        "timestamp": "2015-03-23 08:52:41,743",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0051 transitioned from INITING to RUNNING\n"
    },
    {
        "timestamp": "2015-03-23 08:52:41,743",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Adding container_1427088391284_0051_01_000209 to application application_1427088391284_0051\n"
    },
    {
        "timestamp": "2015-03-23 08:52:41,743",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0051_01_000209 transitioned from NEW to LOCALIZING\n"
    },
    {
        "timestamp": "2015-03-23 08:52:41,744",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event CONTAINER_INIT for appId application_1427088391284_0051\n"
    },
    {
        "timestamp": "2015-03-23 08:52:41,744",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event APPLICATION_INIT for appId application_1427088391284_0051\n"
    },
    {
        "timestamp": "2015-03-23 08:52:41,744",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got APPLICATION_INIT for service mapreduce_shuffle\n"
    },
    {
        "timestamp": "2015-03-23 08:52:41,744",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Added token for job_1427088391284_0051\n"
    },
    {
        "timestamp": "2015-03-23 08:52:41,744",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/0dc49793-c241-48d3-a3fb-a06ec3f716e3/hive_2015-03-23_08-51-00_211_2753574595718298987-1/-mr-10003/d7bac429-1bb4-4c0d-81d2-0a21c0036c58/map.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 08:52:41,744",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/0dc49793-c241-48d3-a3fb-a06ec3f716e3/hive_2015-03-23_08-51-00_211_2753574595718298987-1/-mr-10003/d7bac429-1bb4-4c0d-81d2-0a21c0036c58/reduce.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 08:52:41,744",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0051/job.jar transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 08:52:41,744",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0051/job.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 08:52:41,744",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService",
        "message": " Created localizer for container_1427088391284_0051_01_000209\n"
    },
    {
        "timestamp": "2015-03-23 08:52:41,745",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tIP=172.31.16.215\tOPERATION=Start Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0051\tCONTAINERID=container_1427088391284_0051_01_000209\n"
    },
    {
        "timestamp": "2015-03-23 08:52:41,748",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService",
        "message": " Writing credentials to the nmPrivate file /tmp/hadoop-ubuntu/nm-local-dir/nmPrivate/container_1427088391284_0051_01_000209.tokens. Credentials list: \n"
    },
    {
        "timestamp": "2015-03-23 08:52:41,769",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Initializing user ubuntu\n"
    },
    {
        "timestamp": "2015-03-23 08:52:41,796",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Copying from /tmp/hadoop-ubuntu/nm-local-dir/nmPrivate/container_1427088391284_0051_01_000209.tokens to /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0051/container_1427088391284_0051_01_000209.tokens\n"
    },
    {
        "timestamp": "2015-03-23 08:52:41,796",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Localizer CWD set to /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0051 = file:/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0051\n"
    },
    {
        "timestamp": "2015-03-23 08:52:41,912",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/0dc49793-c241-48d3-a3fb-a06ec3f716e3/hive_2015-03-23_08-51-00_211_2753574595718298987-1/-mr-10003/d7bac429-1bb4-4c0d-81d2-0a21c0036c58/map.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/filecache/50/map.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 08:52:41,962",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/0dc49793-c241-48d3-a3fb-a06ec3f716e3/hive_2015-03-23_08-51-00_211_2753574595718298987-1/-mr-10003/d7bac429-1bb4-4c0d-81d2-0a21c0036c58/reduce.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/filecache/51/reduce.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 08:52:42,423",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0051/job.jar(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0051/filecache/10/job.jar) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 08:52:42,544",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0051/job.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0051/filecache/11/job.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 08:52:42,545",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0051_01_000209 transitioned from LOCALIZING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 08:52:42,599",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0051_01_000209 transitioned from LOCALIZED to RUNNING\n"
    },
    {
        "timestamp": "2015-03-23 08:52:42,605",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " launchContainer: [bash, /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0051/container_1427088391284_0051_01_000209/default_container_executor.sh]\n"
    },
    {
        "timestamp": "2015-03-23 08:52:45,180",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Starting resource-monitoring for container_1427088391284_0051_01_000209\n"
    },
    {
        "timestamp": "2015-03-23 08:52:45,277",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5448 for container-id container_1427088391284_0051_01_000209: 48.9 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:52:48,313",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5448 for container-id container_1427088391284_0051_01_000209: 61.0 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:52:51,399",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5448 for container-id container_1427088391284_0051_01_000209: 78.2 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:52:54,444",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5448 for container-id container_1427088391284_0051_01_000209: 87.2 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:52:57,664",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5448 for container-id container_1427088391284_0051_01_000209: 102.7 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:53:00,673",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5448 for container-id container_1427088391284_0051_01_000209: 116.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:53:03,683",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5448 for container-id container_1427088391284_0051_01_000209: 111.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:53:06,696",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5448 for container-id container_1427088391284_0051_01_000209: 112.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:53:09,705",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5448 for container-id container_1427088391284_0051_01_000209: 118.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:53:12,714",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5448 for container-id container_1427088391284_0051_01_000209: 118.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:53:15,726",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5448 for container-id container_1427088391284_0051_01_000209: 127.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:53:18,759",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5448 for container-id container_1427088391284_0051_01_000209: 127.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:53:21,768",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5448 for container-id container_1427088391284_0051_01_000209: 127.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:53:24,787",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5448 for container-id container_1427088391284_0051_01_000209: 127.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:53:27,796",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5448 for container-id container_1427088391284_0051_01_000209: 127.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:53:30,804",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5448 for container-id container_1427088391284_0051_01_000209: 130.1 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:53:33,817",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5448 for container-id container_1427088391284_0051_01_000209: 130.1 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:53:36,825",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5448 for container-id container_1427088391284_0051_01_000209: 130.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:53:39,834",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5448 for container-id container_1427088391284_0051_01_000209: 132.1 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:53:42,843",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5448 for container-id container_1427088391284_0051_01_000209: 134.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:53:45,855",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5448 for container-id container_1427088391284_0051_01_000209: 136.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:53:48,864",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5448 for container-id container_1427088391284_0051_01_000209: 144.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:53:51,873",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5448 for container-id container_1427088391284_0051_01_000209: 144.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:53:54,885",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5448 for container-id container_1427088391284_0051_01_000209: 144.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:53:57,894",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5448 for container-id container_1427088391284_0051_01_000209: 144.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:54:00,904",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5448 for container-id container_1427088391284_0051_01_000209: 144.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:54:03,918",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5448 for container-id container_1427088391284_0051_01_000209: 144.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:54:06,927",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5448 for container-id container_1427088391284_0051_01_000209: 144.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:54:09,936",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5448 for container-id container_1427088391284_0051_01_000209: 144.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:54:12,948",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5448 for container-id container_1427088391284_0051_01_000209: 150.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:54:15,959",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5448 for container-id container_1427088391284_0051_01_000209: 150.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:54:18,967",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5448 for container-id container_1427088391284_0051_01_000209: 150.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:54:21,977",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5448 for container-id container_1427088391284_0051_01_000209: 150.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:54:25,015",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5448 for container-id container_1427088391284_0051_01_000209: 150.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:54:28,025",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5448 for container-id container_1427088391284_0051_01_000209: 150.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:54:31,034",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5448 for container-id container_1427088391284_0051_01_000209: 150.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:54:34,046",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5448 for container-id container_1427088391284_0051_01_000209: 150.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:54:37,055",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5448 for container-id container_1427088391284_0051_01_000209: 150.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:54:40,064",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5448 for container-id container_1427088391284_0051_01_000209: 150.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:54:43,076",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5448 for container-id container_1427088391284_0051_01_000209: 151.1 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:54:46,085",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5448 for container-id container_1427088391284_0051_01_000209: 151.1 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:54:49,094",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5448 for container-id container_1427088391284_0051_01_000209: 151.1 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:54:52,106",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5448 for container-id container_1427088391284_0051_01_000209: 151.1 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:54:55,121",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5448 for container-id container_1427088391284_0051_01_000209: 151.7 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:54:58,133",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5448 for container-id container_1427088391284_0051_01_000209: 153.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:55:01,176",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5448 for container-id container_1427088391284_0051_01_000209: 161.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:55:04,264",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5448 for container-id container_1427088391284_0051_01_000209: 164.7 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:55:07,294",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5448 for container-id container_1427088391284_0051_01_000209: 180.1 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:55:10,380",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5448 for container-id container_1427088391284_0051_01_000209: 175.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:55:13,436",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5448 for container-id container_1427088391284_0051_01_000209: 166.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:55:16,448",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5448 for container-id container_1427088391284_0051_01_000209: 166.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:55:19,465",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5448 for container-id container_1427088391284_0051_01_000209: 166.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:55:22,591",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5448 for container-id container_1427088391284_0051_01_000209: 166.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:55:25,618",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5448 for container-id container_1427088391284_0051_01_000209: 166.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:55:28,634",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5448 for container-id container_1427088391284_0051_01_000209: 166.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:55:31,693",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5448 for container-id container_1427088391284_0051_01_000209: 166.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:55:34,722",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5448 for container-id container_1427088391284_0051_01_000209: 166.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:55:37,757",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5448 for container-id container_1427088391284_0051_01_000209: 166.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:55:40,781",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5448 for container-id container_1427088391284_0051_01_000209: 166.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:55:43,811",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5448 for container-id container_1427088391284_0051_01_000209: 166.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:55:46,830",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5448 for container-id container_1427088391284_0051_01_000209: 166.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:55:49,861",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5448 for container-id container_1427088391284_0051_01_000209: 166.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:55:52,906",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5448 for container-id container_1427088391284_0051_01_000209: 166.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:55:56,034",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5448 for container-id container_1427088391284_0051_01_000209: 166.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:55:59,071",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5448 for container-id container_1427088391284_0051_01_000209: 166.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:56:01,037",
        "type": "INFO",
        "app": "SecurityLogger.org.apache.hadoop.ipc.Server",
        "message": " Auth successful for appattempt_1427088391284_0051_000001 (auth:SIMPLE)\n"
    },
    {
        "timestamp": "2015-03-23 08:56:01,041",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Stopping container with container Id: container_1427088391284_0051_01_000209\n"
    },
    {
        "timestamp": "2015-03-23 08:56:01,041",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tIP=172.31.16.215\tOPERATION=Stop Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0051\tCONTAINERID=container_1427088391284_0051_01_000209\n"
    },
    {
        "timestamp": "2015-03-23 08:56:01,041",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0051_01_000209 transitioned from RUNNING to KILLING\n"
    },
    {
        "timestamp": "2015-03-23 08:56:01,041",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch",
        "message": " Cleaning up container container_1427088391284_0051_01_000209\n"
    },
    {
        "timestamp": "2015-03-23 08:56:01,166",
        "type": "WARN",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Exit code from container container_1427088391284_0051_01_000209 is : 143\n"
    },
    {
        "timestamp": "2015-03-23 08:56:01,188",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0051_01_000209 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL\n"
    },
    {
        "timestamp": "2015-03-23 08:56:01,189",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Deleting absolute path : /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0051/container_1427088391284_0051_01_000209\n"
    },
    {
        "timestamp": "2015-03-23 08:56:01,215",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tOPERATION=Container Finished - Killed\tTARGET=ContainerImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0051\tCONTAINERID=container_1427088391284_0051_01_000209\n"
    },
    {
        "timestamp": "2015-03-23 08:56:01,215",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0051_01_000209 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE\n"
    },
    {
        "timestamp": "2015-03-23 08:56:01,215",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Removing container_1427088391284_0051_01_000209 from application application_1427088391284_0051\n"
    },
    {
        "timestamp": "2015-03-23 08:56:01,215",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event CONTAINER_STOP for appId application_1427088391284_0051\n"
    },
    {
        "timestamp": "2015-03-23 08:56:02,072",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Stopping resource-monitoring for container_1427088391284_0051_01_000209\n"
    },
    {
        "timestamp": "2015-03-23 08:56:04,051",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl",
        "message": " Removed completed containers from NM context: [container_1427088391284_0051_01_000209]\n"
    },
    {
        "timestamp": "2015-03-23 08:56:16,100",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0051 transitioned from RUNNING to APPLICATION_RESOURCES_CLEANINGUP\n"
    },
    {
        "timestamp": "2015-03-23 08:56:16,101",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event APPLICATION_STOP for appId application_1427088391284_0051\n"
    },
    {
        "timestamp": "2015-03-23 08:56:16,101",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0051 transitioned from APPLICATION_RESOURCES_CLEANINGUP to FINISHED\n"
    },
    {
        "timestamp": "2015-03-23 08:56:16,101",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler",
        "message": " Scheduling Log Deletion for application: application_1427088391284_0051, with delay of 172800 seconds\n"
    },
    {
        "timestamp": "2015-03-23 08:56:16,102",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Deleting absolute path : /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0051\n"
    },
    {
        "timestamp": "2015-03-23 08:58:34,507",
        "type": "INFO",
        "app": "SecurityLogger.org.apache.hadoop.ipc.Server",
        "message": " Auth successful for appattempt_1427088391284_0052_000001 (auth:SIMPLE)\n"
    },
    {
        "timestamp": "2015-03-23 08:58:34,601",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Start request for container_1427088391284_0052_01_000163 by user ubuntu\n"
    },
    {
        "timestamp": "2015-03-23 08:58:34,601",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Creating a new application reference for app application_1427088391284_0052\n"
    },
    {
        "timestamp": "2015-03-23 08:58:34,602",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0052 transitioned from NEW to INITING\n"
    },
    {
        "timestamp": "2015-03-23 08:58:34,602",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0052 transitioned from INITING to RUNNING\n"
    },
    {
        "timestamp": "2015-03-23 08:58:34,602",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Adding container_1427088391284_0052_01_000163 to application application_1427088391284_0052\n"
    },
    {
        "timestamp": "2015-03-23 08:58:34,603",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0052_01_000163 transitioned from NEW to LOCALIZING\n"
    },
    {
        "timestamp": "2015-03-23 08:58:34,603",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event CONTAINER_INIT for appId application_1427088391284_0052\n"
    },
    {
        "timestamp": "2015-03-23 08:58:34,603",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event APPLICATION_INIT for appId application_1427088391284_0052\n"
    },
    {
        "timestamp": "2015-03-23 08:58:34,603",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got APPLICATION_INIT for service mapreduce_shuffle\n"
    },
    {
        "timestamp": "2015-03-23 08:58:34,603",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Added token for job_1427088391284_0052\n"
    },
    {
        "timestamp": "2015-03-23 08:58:34,603",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/9651067d-ee17-43df-8e0d-e3bdcab96948/hive_2015-03-23_08-57-10_275_1325170387488477996-1/-mr-10005/64436c38-fb20-4139-a064-b3838fbd4053/map.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 08:58:34,604",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/9651067d-ee17-43df-8e0d-e3bdcab96948/hive_2015-03-23_08-57-10_275_1325170387488477996-1/-mr-10005/64436c38-fb20-4139-a064-b3838fbd4053/reduce.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 08:58:34,604",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0052/job.jar transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 08:58:34,604",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0052/job.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 08:58:34,604",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService",
        "message": " Created localizer for container_1427088391284_0052_01_000163\n"
    },
    {
        "timestamp": "2015-03-23 08:58:34,604",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tIP=172.31.17.71\tOPERATION=Start Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0052\tCONTAINERID=container_1427088391284_0052_01_000163\n"
    },
    {
        "timestamp": "2015-03-23 08:58:34,609",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService",
        "message": " Writing credentials to the nmPrivate file /tmp/hadoop-ubuntu/nm-local-dir/nmPrivate/container_1427088391284_0052_01_000163.tokens. Credentials list: \n"
    },
    {
        "timestamp": "2015-03-23 08:58:34,630",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Initializing user ubuntu\n"
    },
    {
        "timestamp": "2015-03-23 08:58:34,658",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Copying from /tmp/hadoop-ubuntu/nm-local-dir/nmPrivate/container_1427088391284_0052_01_000163.tokens to /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0052/container_1427088391284_0052_01_000163.tokens\n"
    },
    {
        "timestamp": "2015-03-23 08:58:34,658",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Localizer CWD set to /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0052 = file:/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0052\n"
    },
    {
        "timestamp": "2015-03-23 08:58:34,780",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/9651067d-ee17-43df-8e0d-e3bdcab96948/hive_2015-03-23_08-57-10_275_1325170387488477996-1/-mr-10005/64436c38-fb20-4139-a064-b3838fbd4053/map.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/filecache/52/map.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 08:58:34,919",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/9651067d-ee17-43df-8e0d-e3bdcab96948/hive_2015-03-23_08-57-10_275_1325170387488477996-1/-mr-10005/64436c38-fb20-4139-a064-b3838fbd4053/reduce.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/filecache/53/reduce.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 08:58:35,447",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0052/job.jar(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0052/filecache/10/job.jar) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 08:58:35,505",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0052/job.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0052/filecache/11/job.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 08:58:35,505",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0052_01_000163 transitioned from LOCALIZING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 08:58:35,586",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0052_01_000163 transitioned from LOCALIZED to RUNNING\n"
    },
    {
        "timestamp": "2015-03-23 08:58:35,592",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " launchContainer: [bash, /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0052/container_1427088391284_0052_01_000163/default_container_executor.sh]\n"
    },
    {
        "timestamp": "2015-03-23 08:58:38,087",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Starting resource-monitoring for container_1427088391284_0052_01_000163\n"
    },
    {
        "timestamp": "2015-03-23 08:58:38,125",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5571 for container-id container_1427088391284_0052_01_000163: 48.3 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:58:41,142",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5571 for container-id container_1427088391284_0052_01_000163: 59.5 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:58:44,226",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5571 for container-id container_1427088391284_0052_01_000163: 77.6 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:58:47,311",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5571 for container-id container_1427088391284_0052_01_000163: 84.9 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:58:50,338",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5571 for container-id container_1427088391284_0052_01_000163: 98.7 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:58:53,347",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5571 for container-id container_1427088391284_0052_01_000163: 112.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:58:56,356",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5571 for container-id container_1427088391284_0052_01_000163: 112.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:58:59,368",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5571 for container-id container_1427088391284_0052_01_000163: 112.7 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:59:02,378",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5571 for container-id container_1427088391284_0052_01_000163: 114.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:59:05,386",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5571 for container-id container_1427088391284_0052_01_000163: 118.2 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:59:08,395",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5571 for container-id container_1427088391284_0052_01_000163: 119.7 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:59:11,408",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5571 for container-id container_1427088391284_0052_01_000163: 124.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:59:14,416",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5571 for container-id container_1427088391284_0052_01_000163: 124.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:59:17,425",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5571 for container-id container_1427088391284_0052_01_000163: 124.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:59:20,437",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5571 for container-id container_1427088391284_0052_01_000163: 128.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:59:23,446",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5571 for container-id container_1427088391284_0052_01_000163: 128.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:59:26,455",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5571 for container-id container_1427088391284_0052_01_000163: 128.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:59:29,467",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5571 for container-id container_1427088391284_0052_01_000163: 128.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:59:32,475",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5571 for container-id container_1427088391284_0052_01_000163: 129.7 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:59:35,484",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5571 for container-id container_1427088391284_0052_01_000163: 129.7 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:59:38,496",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5571 for container-id container_1427088391284_0052_01_000163: 129.7 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:59:41,505",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5571 for container-id container_1427088391284_0052_01_000163: 129.7 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:59:44,514",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5571 for container-id container_1427088391284_0052_01_000163: 129.7 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:59:47,526",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5571 for container-id container_1427088391284_0052_01_000163: 130.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:59:50,534",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5571 for container-id container_1427088391284_0052_01_000163: 130.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:59:53,543",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5571 for container-id container_1427088391284_0052_01_000163: 130.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:59:56,552",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5571 for container-id container_1427088391284_0052_01_000163: 130.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 08:59:59,564",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5571 for container-id container_1427088391284_0052_01_000163: 131.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:00:02,573",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5571 for container-id container_1427088391284_0052_01_000163: 131.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:00:05,582",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5571 for container-id container_1427088391284_0052_01_000163: 131.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:00:08,594",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5571 for container-id container_1427088391284_0052_01_000163: 131.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:00:11,603",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5571 for container-id container_1427088391284_0052_01_000163: 131.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:00:14,613",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5571 for container-id container_1427088391284_0052_01_000163: 132.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:00:17,627",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5571 for container-id container_1427088391284_0052_01_000163: 132.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:00:20,636",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5571 for container-id container_1427088391284_0052_01_000163: 132.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:00:23,646",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5571 for container-id container_1427088391284_0052_01_000163: 132.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:00:26,658",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5571 for container-id container_1427088391284_0052_01_000163: 132.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:00:29,669",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5571 for container-id container_1427088391284_0052_01_000163: 132.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:00:32,681",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5571 for container-id container_1427088391284_0052_01_000163: 132.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:00:35,691",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5571 for container-id container_1427088391284_0052_01_000163: 132.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:00:38,703",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5571 for container-id container_1427088391284_0052_01_000163: 132.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:00:41,713",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5571 for container-id container_1427088391284_0052_01_000163: 132.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:00:44,722",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5571 for container-id container_1427088391284_0052_01_000163: 132.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:00:47,736",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5571 for container-id container_1427088391284_0052_01_000163: 132.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:00:50,745",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5571 for container-id container_1427088391284_0052_01_000163: 132.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:00:53,753",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5571 for container-id container_1427088391284_0052_01_000163: 132.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:00:56,774",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5571 for container-id container_1427088391284_0052_01_000163: 136.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:00:59,792",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5571 for container-id container_1427088391284_0052_01_000163: 141.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:01:02,828",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5571 for container-id container_1427088391284_0052_01_000163: 142.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:01:05,884",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5571 for container-id container_1427088391284_0052_01_000163: 143.7 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:01:08,897",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5571 for container-id container_1427088391284_0052_01_000163: 146.1 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:01:09,719",
        "type": "INFO",
        "app": "SecurityLogger.org.apache.hadoop.ipc.Server",
        "message": " Auth successful for appattempt_1427088391284_0052_000001 (auth:SIMPLE)\n"
    },
    {
        "timestamp": "2015-03-23 09:01:09,786",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Stopping container with container Id: container_1427088391284_0052_01_000163\n"
    },
    {
        "timestamp": "2015-03-23 09:01:09,787",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tIP=172.31.17.71\tOPERATION=Stop Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0052\tCONTAINERID=container_1427088391284_0052_01_000163\n"
    },
    {
        "timestamp": "2015-03-23 09:01:09,787",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0052_01_000163 transitioned from RUNNING to KILLING\n"
    },
    {
        "timestamp": "2015-03-23 09:01:09,787",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch",
        "message": " Cleaning up container container_1427088391284_0052_01_000163\n"
    },
    {
        "timestamp": "2015-03-23 09:01:10,131",
        "type": "WARN",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Exit code from container container_1427088391284_0052_01_000163 is : 143\n"
    },
    {
        "timestamp": "2015-03-23 09:01:10,229",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0052_01_000163 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL\n"
    },
    {
        "timestamp": "2015-03-23 09:01:10,256",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Deleting absolute path : /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0052/container_1427088391284_0052_01_000163\n"
    },
    {
        "timestamp": "2015-03-23 09:01:10,258",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tOPERATION=Container Finished - Killed\tTARGET=ContainerImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0052\tCONTAINERID=container_1427088391284_0052_01_000163\n"
    },
    {
        "timestamp": "2015-03-23 09:01:10,258",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0052_01_000163 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE\n"
    },
    {
        "timestamp": "2015-03-23 09:01:10,258",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Removing container_1427088391284_0052_01_000163 from application application_1427088391284_0052\n"
    },
    {
        "timestamp": "2015-03-23 09:01:10,258",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event CONTAINER_STOP for appId application_1427088391284_0052\n"
    },
    {
        "timestamp": "2015-03-23 09:01:11,897",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Stopping resource-monitoring for container_1427088391284_0052_01_000163\n"
    },
    {
        "timestamp": "2015-03-23 09:01:19,861",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl",
        "message": " Removed completed containers from NM context: [container_1427088391284_0052_01_000163]\n"
    },
    {
        "timestamp": "2015-03-23 09:01:19,861",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0052 transitioned from RUNNING to APPLICATION_RESOURCES_CLEANINGUP\n"
    },
    {
        "timestamp": "2015-03-23 09:01:19,862",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event APPLICATION_STOP for appId application_1427088391284_0052\n"
    },
    {
        "timestamp": "2015-03-23 09:01:19,862",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0052 transitioned from APPLICATION_RESOURCES_CLEANINGUP to FINISHED\n"
    },
    {
        "timestamp": "2015-03-23 09:01:19,862",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler",
        "message": " Scheduling Log Deletion for application: application_1427088391284_0052, with delay of 172800 seconds\n"
    },
    {
        "timestamp": "2015-03-23 09:01:19,862",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Deleting absolute path : /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0052\n"
    },
    {
        "timestamp": "2015-03-23 09:03:36,131",
        "type": "INFO",
        "app": "SecurityLogger.org.apache.hadoop.ipc.Server",
        "message": " Auth successful for appattempt_1427088391284_0054_000001 (auth:SIMPLE)\n"
    },
    {
        "timestamp": "2015-03-23 09:03:36,741",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Start request for container_1427088391284_0054_01_000013 by user ubuntu\n"
    },
    {
        "timestamp": "2015-03-23 09:03:36,741",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Creating a new application reference for app application_1427088391284_0054\n"
    },
    {
        "timestamp": "2015-03-23 09:03:36,741",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0054 transitioned from NEW to INITING\n"
    },
    {
        "timestamp": "2015-03-23 09:03:36,742",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0054 transitioned from INITING to RUNNING\n"
    },
    {
        "timestamp": "2015-03-23 09:03:36,742",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Adding container_1427088391284_0054_01_000013 to application application_1427088391284_0054\n"
    },
    {
        "timestamp": "2015-03-23 09:03:36,742",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0054_01_000013 transitioned from NEW to LOCALIZING\n"
    },
    {
        "timestamp": "2015-03-23 09:03:36,742",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event CONTAINER_INIT for appId application_1427088391284_0054\n"
    },
    {
        "timestamp": "2015-03-23 09:03:36,742",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event APPLICATION_INIT for appId application_1427088391284_0054\n"
    },
    {
        "timestamp": "2015-03-23 09:03:36,742",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got APPLICATION_INIT for service mapreduce_shuffle\n"
    },
    {
        "timestamp": "2015-03-23 09:03:36,743",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Added token for job_1427088391284_0054\n"
    },
    {
        "timestamp": "2015-03-23 09:03:36,743",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/9651067d-ee17-43df-8e0d-e3bdcab96948/hive_2015-03-23_08-57-10_275_1325170387488477996-1/-mr-10009/fb1937bc-2b71-49a8-9908-7c7e78248f7c/map.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 09:03:36,743",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/9651067d-ee17-43df-8e0d-e3bdcab96948/hive_2015-03-23_08-57-10_275_1325170387488477996-1/-mr-10009/fb1937bc-2b71-49a8-9908-7c7e78248f7c/reduce.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 09:03:36,743",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0054/job.jar transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 09:03:36,743",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0054/job.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 09:03:36,743",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService",
        "message": " Created localizer for container_1427088391284_0054_01_000013\n"
    },
    {
        "timestamp": "2015-03-23 09:03:36,744",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tIP=172.31.16.234\tOPERATION=Start Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0054\tCONTAINERID=container_1427088391284_0054_01_000013\n"
    },
    {
        "timestamp": "2015-03-23 09:03:36,748",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService",
        "message": " Writing credentials to the nmPrivate file /tmp/hadoop-ubuntu/nm-local-dir/nmPrivate/container_1427088391284_0054_01_000013.tokens. Credentials list: \n"
    },
    {
        "timestamp": "2015-03-23 09:03:36,860",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Initializing user ubuntu\n"
    },
    {
        "timestamp": "2015-03-23 09:03:36,863",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Copying from /tmp/hadoop-ubuntu/nm-local-dir/nmPrivate/container_1427088391284_0054_01_000013.tokens to /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0054/container_1427088391284_0054_01_000013.tokens\n"
    },
    {
        "timestamp": "2015-03-23 09:03:36,863",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Localizer CWD set to /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0054 = file:/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0054\n"
    },
    {
        "timestamp": "2015-03-23 09:03:36,980",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/9651067d-ee17-43df-8e0d-e3bdcab96948/hive_2015-03-23_08-57-10_275_1325170387488477996-1/-mr-10009/fb1937bc-2b71-49a8-9908-7c7e78248f7c/map.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/filecache/54/map.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 09:03:37,031",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/9651067d-ee17-43df-8e0d-e3bdcab96948/hive_2015-03-23_08-57-10_275_1325170387488477996-1/-mr-10009/fb1937bc-2b71-49a8-9908-7c7e78248f7c/reduce.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/filecache/55/reduce.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 09:03:37,539",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0054/job.jar(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0054/filecache/10/job.jar) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 09:03:37,572",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0054/job.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0054/filecache/11/job.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 09:03:37,572",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0054_01_000013 transitioned from LOCALIZING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 09:03:37,651",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0054_01_000013 transitioned from LOCALIZED to RUNNING\n"
    },
    {
        "timestamp": "2015-03-23 09:03:37,661",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " launchContainer: [bash, /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0054/container_1427088391284_0054_01_000013/default_container_executor.sh]\n"
    },
    {
        "timestamp": "2015-03-23 09:03:38,909",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Starting resource-monitoring for container_1427088391284_0054_01_000013\n"
    },
    {
        "timestamp": "2015-03-23 09:03:38,923",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5686 for container-id container_1427088391284_0054_01_000013: 41.3 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:03:41,946",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5686 for container-id container_1427088391284_0054_01_000013: 54.4 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:03:45,043",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5686 for container-id container_1427088391284_0054_01_000013: 73.1 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:03:48,069",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5686 for container-id container_1427088391284_0054_01_000013: 82.5 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:03:51,092",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5686 for container-id container_1427088391284_0054_01_000013: 88.9 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:03:54,105",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5686 for container-id container_1427088391284_0054_01_000013: 95.3 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:03:57,213",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5686 for container-id container_1427088391284_0054_01_000013: 197.0 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:04:00,229",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5686 for container-id container_1427088391284_0054_01_000013: 197.6 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:04:02,731",
        "type": "INFO",
        "app": "SecurityLogger.org.apache.hadoop.ipc.Server",
        "message": " Auth successful for appattempt_1427088391284_0054_000001 (auth:SIMPLE)\n"
    },
    {
        "timestamp": "2015-03-23 09:04:02,772",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Stopping container with container Id: container_1427088391284_0054_01_000013\n"
    },
    {
        "timestamp": "2015-03-23 09:04:02,773",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tIP=172.31.16.234\tOPERATION=Stop Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0054\tCONTAINERID=container_1427088391284_0054_01_000013\n"
    },
    {
        "timestamp": "2015-03-23 09:04:02,773",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0054_01_000013 transitioned from RUNNING to KILLING\n"
    },
    {
        "timestamp": "2015-03-23 09:04:02,773",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch",
        "message": " Cleaning up container container_1427088391284_0054_01_000013\n"
    },
    {
        "timestamp": "2015-03-23 09:04:02,793",
        "type": "WARN",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Exit code from container container_1427088391284_0054_01_000013 is : 143\n"
    },
    {
        "timestamp": "2015-03-23 09:04:02,847",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0054_01_000013 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL\n"
    },
    {
        "timestamp": "2015-03-23 09:04:02,848",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Deleting absolute path : /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0054/container_1427088391284_0054_01_000013\n"
    },
    {
        "timestamp": "2015-03-23 09:04:02,850",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tOPERATION=Container Finished - Killed\tTARGET=ContainerImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0054\tCONTAINERID=container_1427088391284_0054_01_000013\n"
    },
    {
        "timestamp": "2015-03-23 09:04:02,851",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0054_01_000013 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE\n"
    },
    {
        "timestamp": "2015-03-23 09:04:02,851",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Removing container_1427088391284_0054_01_000013 from application application_1427088391284_0054\n"
    },
    {
        "timestamp": "2015-03-23 09:04:02,851",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event CONTAINER_STOP for appId application_1427088391284_0054\n"
    },
    {
        "timestamp": "2015-03-23 09:04:03,229",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Stopping resource-monitoring for container_1427088391284_0054_01_000013\n"
    },
    {
        "timestamp": "2015-03-23 09:04:06,783",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl",
        "message": " Removed completed containers from NM context: [container_1427088391284_0054_01_000013]\n"
    },
    {
        "timestamp": "2015-03-23 09:04:24,593",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:05:02,027",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0054 transitioned from RUNNING to APPLICATION_RESOURCES_CLEANINGUP\n"
    },
    {
        "timestamp": "2015-03-23 09:05:02,028",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event APPLICATION_STOP for appId application_1427088391284_0054\n"
    },
    {
        "timestamp": "2015-03-23 09:05:02,028",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0054 transitioned from APPLICATION_RESOURCES_CLEANINGUP to FINISHED\n"
    },
    {
        "timestamp": "2015-03-23 09:05:02,028",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler",
        "message": " Scheduling Log Deletion for application: application_1427088391284_0054, with delay of 172800 seconds\n"
    },
    {
        "timestamp": "2015-03-23 09:05:02,029",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Deleting absolute path : /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0054\n"
    },
    {
        "timestamp": "2015-03-23 09:07:33,924",
        "type": "INFO",
        "app": "SecurityLogger.org.apache.hadoop.ipc.Server",
        "message": " Auth successful for appattempt_1427088391284_0055_000001 (auth:SIMPLE)\n"
    },
    {
        "timestamp": "2015-03-23 09:07:34,244",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Start request for container_1427088391284_0055_01_000109 by user ubuntu\n"
    },
    {
        "timestamp": "2015-03-23 09:07:34,244",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Creating a new application reference for app application_1427088391284_0055\n"
    },
    {
        "timestamp": "2015-03-23 09:07:34,244",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0055 transitioned from NEW to INITING\n"
    },
    {
        "timestamp": "2015-03-23 09:07:34,244",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0055 transitioned from INITING to RUNNING\n"
    },
    {
        "timestamp": "2015-03-23 09:07:34,245",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Adding container_1427088391284_0055_01_000109 to application application_1427088391284_0055\n"
    },
    {
        "timestamp": "2015-03-23 09:07:34,245",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0055_01_000109 transitioned from NEW to LOCALIZING\n"
    },
    {
        "timestamp": "2015-03-23 09:07:34,245",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event CONTAINER_INIT for appId application_1427088391284_0055\n"
    },
    {
        "timestamp": "2015-03-23 09:07:34,245",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event APPLICATION_INIT for appId application_1427088391284_0055\n"
    },
    {
        "timestamp": "2015-03-23 09:07:34,245",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got APPLICATION_INIT for service mapreduce_shuffle\n"
    },
    {
        "timestamp": "2015-03-23 09:07:34,245",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Added token for job_1427088391284_0055\n"
    },
    {
        "timestamp": "2015-03-23 09:07:34,246",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/e451a376-f7ba-466e-9cf8-be6530bb8869/hive_2015-03-23_09-05-54_427_4640719055865576469-1/-mr-10003/2ccb56af-fdaa-4a56-b14c-e1a6624adf74/map.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 09:07:34,246",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/e451a376-f7ba-466e-9cf8-be6530bb8869/hive_2015-03-23_09-05-54_427_4640719055865576469-1/-mr-10003/2ccb56af-fdaa-4a56-b14c-e1a6624adf74/reduce.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 09:07:34,246",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0055/job.jar transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 09:07:34,246",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0055/job.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 09:07:34,246",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService",
        "message": " Created localizer for container_1427088391284_0055_01_000109\n"
    },
    {
        "timestamp": "2015-03-23 09:07:34,246",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tIP=172.31.17.108\tOPERATION=Start Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0055\tCONTAINERID=container_1427088391284_0055_01_000109\n"
    },
    {
        "timestamp": "2015-03-23 09:07:34,251",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService",
        "message": " Writing credentials to the nmPrivate file /tmp/hadoop-ubuntu/nm-local-dir/nmPrivate/container_1427088391284_0055_01_000109.tokens. Credentials list: \n"
    },
    {
        "timestamp": "2015-03-23 09:07:34,296",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Initializing user ubuntu\n"
    },
    {
        "timestamp": "2015-03-23 09:07:34,299",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Copying from /tmp/hadoop-ubuntu/nm-local-dir/nmPrivate/container_1427088391284_0055_01_000109.tokens to /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0055/container_1427088391284_0055_01_000109.tokens\n"
    },
    {
        "timestamp": "2015-03-23 09:07:34,299",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Localizer CWD set to /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0055 = file:/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0055\n"
    },
    {
        "timestamp": "2015-03-23 09:07:34,418",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/e451a376-f7ba-466e-9cf8-be6530bb8869/hive_2015-03-23_09-05-54_427_4640719055865576469-1/-mr-10003/2ccb56af-fdaa-4a56-b14c-e1a6624adf74/map.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/filecache/56/map.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 09:07:34,471",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/e451a376-f7ba-466e-9cf8-be6530bb8869/hive_2015-03-23_09-05-54_427_4640719055865576469-1/-mr-10003/2ccb56af-fdaa-4a56-b14c-e1a6624adf74/reduce.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/filecache/57/reduce.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 09:07:34,938",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0055/job.jar(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0055/filecache/10/job.jar) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 09:07:34,994",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0055/job.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0055/filecache/11/job.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 09:07:34,995",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0055_01_000109 transitioned from LOCALIZING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 09:07:35,081",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0055_01_000109 transitioned from LOCALIZED to RUNNING\n"
    },
    {
        "timestamp": "2015-03-23 09:07:35,087",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " launchContainer: [bash, /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0055/container_1427088391284_0055_01_000109/default_container_executor.sh]\n"
    },
    {
        "timestamp": "2015-03-23 09:07:36,237",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Starting resource-monitoring for container_1427088391284_0055_01_000109\n"
    },
    {
        "timestamp": "2015-03-23 09:07:36,277",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5776 for container-id container_1427088391284_0055_01_000109: 38.1 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:07:39,290",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5776 for container-id container_1427088391284_0055_01_000109: 55.4 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:07:42,375",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5776 for container-id container_1427088391284_0055_01_000109: 72.2 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:07:45,460",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5776 for container-id container_1427088391284_0055_01_000109: 81.4 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:07:48,542",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5776 for container-id container_1427088391284_0055_01_000109: 94.0 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:07:51,579",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5776 for container-id container_1427088391284_0055_01_000109: 103.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:07:54,589",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5776 for container-id container_1427088391284_0055_01_000109: 117.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:07:57,598",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5776 for container-id container_1427088391284_0055_01_000109: 118.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:08:00,620",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5776 for container-id container_1427088391284_0055_01_000109: 124.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:08:03,630",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5776 for container-id container_1427088391284_0055_01_000109: 124.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:08:06,638",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5776 for container-id container_1427088391284_0055_01_000109: 134.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:08:09,651",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5776 for container-id container_1427088391284_0055_01_000109: 134.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:08:12,659",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5776 for container-id container_1427088391284_0055_01_000109: 134.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:08:15,667",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5776 for container-id container_1427088391284_0055_01_000109: 134.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:08:18,675",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5776 for container-id container_1427088391284_0055_01_000109: 134.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:08:21,685",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5776 for container-id container_1427088391284_0055_01_000109: 134.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:08:24,697",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5776 for container-id container_1427088391284_0055_01_000109: 136.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:08:27,706",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5776 for container-id container_1427088391284_0055_01_000109: 138.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:08:30,718",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5776 for container-id container_1427088391284_0055_01_000109: 145.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:08:33,727",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5776 for container-id container_1427088391284_0055_01_000109: 145.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:08:36,735",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5776 for container-id container_1427088391284_0055_01_000109: 145.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:08:39,748",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5776 for container-id container_1427088391284_0055_01_000109: 145.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:08:42,757",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5776 for container-id container_1427088391284_0055_01_000109: 145.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:08:45,766",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5776 for container-id container_1427088391284_0055_01_000109: 145.7 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:08:48,779",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5776 for container-id container_1427088391284_0055_01_000109: 145.7 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:08:51,788",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5776 for container-id container_1427088391284_0055_01_000109: 145.7 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:08:54,797",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5776 for container-id container_1427088391284_0055_01_000109: 151.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:08:57,809",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5776 for container-id container_1427088391284_0055_01_000109: 151.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:09:00,818",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5776 for container-id container_1427088391284_0055_01_000109: 151.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:09:03,827",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5776 for container-id container_1427088391284_0055_01_000109: 151.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:09:06,836",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5776 for container-id container_1427088391284_0055_01_000109: 151.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:09:09,848",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5776 for container-id container_1427088391284_0055_01_000109: 151.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:09:12,857",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5776 for container-id container_1427088391284_0055_01_000109: 151.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:09:15,865",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5776 for container-id container_1427088391284_0055_01_000109: 151.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:09:18,879",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5776 for container-id container_1427088391284_0055_01_000109: 154.2 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:09:21,912",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5776 for container-id container_1427088391284_0055_01_000109: 154.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:09:24,926",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5776 for container-id container_1427088391284_0055_01_000109: 154.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:09:27,946",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5776 for container-id container_1427088391284_0055_01_000109: 165.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:09:30,968",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5776 for container-id container_1427088391284_0055_01_000109: 167.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:09:34,001",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5776 for container-id container_1427088391284_0055_01_000109: 180.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:09:37,036",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5776 for container-id container_1427088391284_0055_01_000109: 171.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:09:40,124",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5776 for container-id container_1427088391284_0055_01_000109: 171.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:09:43,142",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5776 for container-id container_1427088391284_0055_01_000109: 171.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:09:46,176",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5776 for container-id container_1427088391284_0055_01_000109: 170.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:09:49,206",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5776 for container-id container_1427088391284_0055_01_000109: 170.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:09:52,240",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5776 for container-id container_1427088391284_0055_01_000109: 170.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:09:55,253",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5776 for container-id container_1427088391284_0055_01_000109: 170.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:09:58,312",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5776 for container-id container_1427088391284_0055_01_000109: 170.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:10:01,350",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5776 for container-id container_1427088391284_0055_01_000109: 170.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:10:04,374",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5776 for container-id container_1427088391284_0055_01_000109: 170.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:10:07,428",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5776 for container-id container_1427088391284_0055_01_000109: 170.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:10:10,457",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5776 for container-id container_1427088391284_0055_01_000109: 170.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:10:13,494",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5776 for container-id container_1427088391284_0055_01_000109: 170.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:10:16,521",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5776 for container-id container_1427088391284_0055_01_000109: 170.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:10:19,570",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5776 for container-id container_1427088391284_0055_01_000109: 170.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:10:22,585",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5776 for container-id container_1427088391284_0055_01_000109: 170.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:10:25,604",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5776 for container-id container_1427088391284_0055_01_000109: 170.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:10:28,625",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5776 for container-id container_1427088391284_0055_01_000109: 170.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:10:29,716",
        "type": "INFO",
        "app": "SecurityLogger.org.apache.hadoop.ipc.Server",
        "message": " Auth successful for appattempt_1427088391284_0055_000001 (auth:SIMPLE)\n"
    },
    {
        "timestamp": "2015-03-23 09:10:29,718",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Stopping container with container Id: container_1427088391284_0055_01_000109\n"
    },
    {
        "timestamp": "2015-03-23 09:10:29,718",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tIP=172.31.17.108\tOPERATION=Stop Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0055\tCONTAINERID=container_1427088391284_0055_01_000109\n"
    },
    {
        "timestamp": "2015-03-23 09:10:29,718",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0055_01_000109 transitioned from RUNNING to KILLING\n"
    },
    {
        "timestamp": "2015-03-23 09:10:29,718",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch",
        "message": " Cleaning up container container_1427088391284_0055_01_000109\n"
    },
    {
        "timestamp": "2015-03-23 09:10:29,810",
        "type": "WARN",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Exit code from container container_1427088391284_0055_01_000109 is : 143\n"
    },
    {
        "timestamp": "2015-03-23 09:10:29,854",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0055_01_000109 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL\n"
    },
    {
        "timestamp": "2015-03-23 09:10:29,854",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Deleting absolute path : /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0055/container_1427088391284_0055_01_000109\n"
    },
    {
        "timestamp": "2015-03-23 09:10:29,857",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tOPERATION=Container Finished - Killed\tTARGET=ContainerImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0055\tCONTAINERID=container_1427088391284_0055_01_000109\n"
    },
    {
        "timestamp": "2015-03-23 09:10:29,857",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0055_01_000109 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE\n"
    },
    {
        "timestamp": "2015-03-23 09:10:29,857",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Removing container_1427088391284_0055_01_000109 from application application_1427088391284_0055\n"
    },
    {
        "timestamp": "2015-03-23 09:10:29,857",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event CONTAINER_STOP for appId application_1427088391284_0055\n"
    },
    {
        "timestamp": "2015-03-23 09:10:31,626",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Stopping resource-monitoring for container_1427088391284_0055_01_000109\n"
    },
    {
        "timestamp": "2015-03-23 09:10:32,804",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl",
        "message": " Removed completed containers from NM context: [container_1427088391284_0055_01_000109]\n"
    },
    {
        "timestamp": "2015-03-23 09:13:53,002",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0055 transitioned from RUNNING to APPLICATION_RESOURCES_CLEANINGUP\n"
    },
    {
        "timestamp": "2015-03-23 09:13:53,003",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event APPLICATION_STOP for appId application_1427088391284_0055\n"
    },
    {
        "timestamp": "2015-03-23 09:13:53,003",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0055 transitioned from APPLICATION_RESOURCES_CLEANINGUP to FINISHED\n"
    },
    {
        "timestamp": "2015-03-23 09:13:53,003",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler",
        "message": " Scheduling Log Deletion for application: application_1427088391284_0055, with delay of 172800 seconds\n"
    },
    {
        "timestamp": "2015-03-23 09:13:53,003",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Deleting absolute path : /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0055\n"
    },
    {
        "timestamp": "2015-03-23 09:15:39,723",
        "type": "INFO",
        "app": "SecurityLogger.org.apache.hadoop.ipc.Server",
        "message": " Auth successful for appattempt_1427088391284_0056_000001 (auth:SIMPLE)\n"
    },
    {
        "timestamp": "2015-03-23 09:15:39,926",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Start request for container_1427088391284_0056_01_000142 by user ubuntu\n"
    },
    {
        "timestamp": "2015-03-23 09:15:39,926",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Creating a new application reference for app application_1427088391284_0056\n"
    },
    {
        "timestamp": "2015-03-23 09:15:39,927",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0056 transitioned from NEW to INITING\n"
    },
    {
        "timestamp": "2015-03-23 09:15:39,927",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0056 transitioned from INITING to RUNNING\n"
    },
    {
        "timestamp": "2015-03-23 09:15:39,927",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Adding container_1427088391284_0056_01_000142 to application application_1427088391284_0056\n"
    },
    {
        "timestamp": "2015-03-23 09:15:39,928",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0056_01_000142 transitioned from NEW to LOCALIZING\n"
    },
    {
        "timestamp": "2015-03-23 09:15:39,928",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event CONTAINER_INIT for appId application_1427088391284_0056\n"
    },
    {
        "timestamp": "2015-03-23 09:15:39,928",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event APPLICATION_INIT for appId application_1427088391284_0056\n"
    },
    {
        "timestamp": "2015-03-23 09:15:39,928",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got APPLICATION_INIT for service mapreduce_shuffle\n"
    },
    {
        "timestamp": "2015-03-23 09:15:39,928",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Added token for job_1427088391284_0056\n"
    },
    {
        "timestamp": "2015-03-23 09:15:39,928",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/0a2ca13f-a0e7-4431-b746-1aaf8a06af93/hive_2015-03-23_09-14-46_354_2434748962565824460-1/-mr-10005/fbb5eea1-167c-4839-a64b-419110c1b4dc/map.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 09:15:39,928",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/0a2ca13f-a0e7-4431-b746-1aaf8a06af93/hive_2015-03-23_09-14-46_354_2434748962565824460-1/-mr-10005/fbb5eea1-167c-4839-a64b-419110c1b4dc/reduce.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 09:15:39,929",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0056/job.jar transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 09:15:39,929",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0056/job.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 09:15:39,929",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService",
        "message": " Created localizer for container_1427088391284_0056_01_000142\n"
    },
    {
        "timestamp": "2015-03-23 09:15:39,929",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tIP=172.31.17.42\tOPERATION=Start Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0056\tCONTAINERID=container_1427088391284_0056_01_000142\n"
    },
    {
        "timestamp": "2015-03-23 09:15:39,934",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService",
        "message": " Writing credentials to the nmPrivate file /tmp/hadoop-ubuntu/nm-local-dir/nmPrivate/container_1427088391284_0056_01_000142.tokens. Credentials list: \n"
    },
    {
        "timestamp": "2015-03-23 09:15:39,955",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Initializing user ubuntu\n"
    },
    {
        "timestamp": "2015-03-23 09:15:39,959",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Copying from /tmp/hadoop-ubuntu/nm-local-dir/nmPrivate/container_1427088391284_0056_01_000142.tokens to /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0056/container_1427088391284_0056_01_000142.tokens\n"
    },
    {
        "timestamp": "2015-03-23 09:15:39,959",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Localizer CWD set to /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0056 = file:/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0056\n"
    },
    {
        "timestamp": "2015-03-23 09:15:40,152",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/0a2ca13f-a0e7-4431-b746-1aaf8a06af93/hive_2015-03-23_09-14-46_354_2434748962565824460-1/-mr-10005/fbb5eea1-167c-4839-a64b-419110c1b4dc/map.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/filecache/58/map.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 09:15:40,284",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/0a2ca13f-a0e7-4431-b746-1aaf8a06af93/hive_2015-03-23_09-14-46_354_2434748962565824460-1/-mr-10005/fbb5eea1-167c-4839-a64b-419110c1b4dc/reduce.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/filecache/59/reduce.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 09:15:40,751",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0056/job.jar(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0056/filecache/10/job.jar) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 09:15:40,835",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0056/job.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0056/filecache/11/job.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 09:15:40,836",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0056_01_000142 transitioned from LOCALIZING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 09:15:40,904",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0056_01_000142 transitioned from LOCALIZED to RUNNING\n"
    },
    {
        "timestamp": "2015-03-23 09:15:40,939",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " launchContainer: [bash, /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0056/container_1427088391284_0056_01_000142/default_container_executor.sh]\n"
    },
    {
        "timestamp": "2015-03-23 09:15:43,638",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Starting resource-monitoring for container_1427088391284_0056_01_000142\n"
    },
    {
        "timestamp": "2015-03-23 09:15:43,737",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5908 for container-id container_1427088391284_0056_01_000142: 48.2 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:15:46,770",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5908 for container-id container_1427088391284_0056_01_000142: 60.3 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:15:49,795",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5908 for container-id container_1427088391284_0056_01_000142: 78.0 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:15:52,811",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5908 for container-id container_1427088391284_0056_01_000142: 85.4 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:15:56,117",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5908 for container-id container_1427088391284_0056_01_000142: 102.0 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:15:59,202",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5908 for container-id container_1427088391284_0056_01_000142: 110.1 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:16:02,255",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5908 for container-id container_1427088391284_0056_01_000142: 216.5 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:16:05,295",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5908 for container-id container_1427088391284_0056_01_000142: 217.6 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:16:08,319",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 5908 for container-id container_1427088391284_0056_01_000142: 217.9 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:16:10,508",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch",
        "message": " Container container_1427088391284_0056_01_000142 succeeded \n"
    },
    {
        "timestamp": "2015-03-23 09:16:10,508",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0056_01_000142 transitioned from RUNNING to EXITED_WITH_SUCCESS\n"
    },
    {
        "timestamp": "2015-03-23 09:16:10,509",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch",
        "message": " Cleaning up container container_1427088391284_0056_01_000142\n"
    },
    {
        "timestamp": "2015-03-23 09:16:10,565",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Deleting absolute path : /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0056/container_1427088391284_0056_01_000142\n"
    },
    {
        "timestamp": "2015-03-23 09:16:10,567",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tOPERATION=Container Finished - Succeeded\tTARGET=ContainerImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0056\tCONTAINERID=container_1427088391284_0056_01_000142\n"
    },
    {
        "timestamp": "2015-03-23 09:16:10,567",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0056_01_000142 transitioned from EXITED_WITH_SUCCESS to DONE\n"
    },
    {
        "timestamp": "2015-03-23 09:16:10,568",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Removing container_1427088391284_0056_01_000142 from application application_1427088391284_0056\n"
    },
    {
        "timestamp": "2015-03-23 09:16:10,568",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event CONTAINER_STOP for appId application_1427088391284_0056\n"
    },
    {
        "timestamp": "2015-03-23 09:16:10,785",
        "type": "INFO",
        "app": "SecurityLogger.org.apache.hadoop.ipc.Server",
        "message": " Auth successful for appattempt_1427088391284_0056_000001 (auth:SIMPLE)\n"
    },
    {
        "timestamp": "2015-03-23 09:16:10,872",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Stopping container with container Id: container_1427088391284_0056_01_000142\n"
    },
    {
        "timestamp": "2015-03-23 09:16:10,872",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tIP=172.31.17.42\tOPERATION=Stop Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0056\tCONTAINERID=container_1427088391284_0056_01_000142\n"
    },
    {
        "timestamp": "2015-03-23 09:16:11,320",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Stopping resource-monitoring for container_1427088391284_0056_01_000142\n"
    },
    {
        "timestamp": "2015-03-23 09:16:13,881",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl",
        "message": " Removed completed containers from NM context: [container_1427088391284_0056_01_000142]\n"
    },
    {
        "timestamp": "2015-03-23 09:16:28,752",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:16:29,241",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:16:30,813",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:16:31,010",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:16:31,117",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:16:31,350",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:16:31,358",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:16:31,627",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:16:31,641",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:16:31,704",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:16:31,803",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:16:31,851",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:16:31,858",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:16:31,943",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:16:32,026",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:16:32,260",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:16:32,409",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:16:32,506",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:16:32,532",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:16:32,583",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:16:32,622",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:16:33,262",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:16:33,275",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:16:33,416",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:16:33,484",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:16:33,674",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:16:33,743",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:16:33,852",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:16:33,886",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:16:33,900",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:16:33,919",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:16:33,933",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:16:34,075",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:16:34,142",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:16:34,172",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:16:34,221",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:16:34,507",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:16:47,531",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:16:48,814",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:16:49,249",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:16:49,725",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:16:49,954",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:16:50,515",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:16:51,097",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:16:51,712",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:16:51,919",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:16:52,527",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:16:54,497",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:19:11,676",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0056 transitioned from RUNNING to APPLICATION_RESOURCES_CLEANINGUP\n"
    },
    {
        "timestamp": "2015-03-23 09:19:11,677",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event APPLICATION_STOP for appId application_1427088391284_0056\n"
    },
    {
        "timestamp": "2015-03-23 09:19:11,677",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0056 transitioned from APPLICATION_RESOURCES_CLEANINGUP to FINISHED\n"
    },
    {
        "timestamp": "2015-03-23 09:19:11,677",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler",
        "message": " Scheduling Log Deletion for application: application_1427088391284_0056, with delay of 172800 seconds\n"
    },
    {
        "timestamp": "2015-03-23 09:19:11,678",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Deleting absolute path : /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0056\n"
    },
    {
        "timestamp": "2015-03-23 09:19:37,446",
        "type": "INFO",
        "app": "SecurityLogger.org.apache.hadoop.ipc.Server",
        "message": " Auth successful for appattempt_1427088391284_0057_000001 (auth:SIMPLE)\n"
    },
    {
        "timestamp": "2015-03-23 09:19:38,292",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Start request for container_1427088391284_0057_01_000010 by user ubuntu\n"
    },
    {
        "timestamp": "2015-03-23 09:19:38,292",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Creating a new application reference for app application_1427088391284_0057\n"
    },
    {
        "timestamp": "2015-03-23 09:19:38,292",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0057 transitioned from NEW to INITING\n"
    },
    {
        "timestamp": "2015-03-23 09:19:38,293",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0057 transitioned from INITING to RUNNING\n"
    },
    {
        "timestamp": "2015-03-23 09:19:38,293",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Adding container_1427088391284_0057_01_000010 to application application_1427088391284_0057\n"
    },
    {
        "timestamp": "2015-03-23 09:19:38,293",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0057_01_000010 transitioned from NEW to LOCALIZING\n"
    },
    {
        "timestamp": "2015-03-23 09:19:38,293",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event CONTAINER_INIT for appId application_1427088391284_0057\n"
    },
    {
        "timestamp": "2015-03-23 09:19:38,293",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event APPLICATION_INIT for appId application_1427088391284_0057\n"
    },
    {
        "timestamp": "2015-03-23 09:19:38,293",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got APPLICATION_INIT for service mapreduce_shuffle\n"
    },
    {
        "timestamp": "2015-03-23 09:19:38,294",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Added token for job_1427088391284_0057\n"
    },
    {
        "timestamp": "2015-03-23 09:19:38,294",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/0a2ca13f-a0e7-4431-b746-1aaf8a06af93/hive_2015-03-23_09-14-46_354_2434748962565824460-1/-mr-10007/08acf87f-5dad-48a8-a062-8e58cebf01ab/map.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 09:19:38,294",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/0a2ca13f-a0e7-4431-b746-1aaf8a06af93/hive_2015-03-23_09-14-46_354_2434748962565824460-1/-mr-10007/08acf87f-5dad-48a8-a062-8e58cebf01ab/reduce.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 09:19:38,294",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0057/job.jar transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 09:19:38,294",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0057/job.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 09:19:38,294",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService",
        "message": " Created localizer for container_1427088391284_0057_01_000010\n"
    },
    {
        "timestamp": "2015-03-23 09:19:38,295",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tIP=172.31.17.138\tOPERATION=Start Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0057\tCONTAINERID=container_1427088391284_0057_01_000010\n"
    },
    {
        "timestamp": "2015-03-23 09:19:38,299",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService",
        "message": " Writing credentials to the nmPrivate file /tmp/hadoop-ubuntu/nm-local-dir/nmPrivate/container_1427088391284_0057_01_000010.tokens. Credentials list: \n"
    },
    {
        "timestamp": "2015-03-23 09:19:38,344",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Initializing user ubuntu\n"
    },
    {
        "timestamp": "2015-03-23 09:19:38,347",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Copying from /tmp/hadoop-ubuntu/nm-local-dir/nmPrivate/container_1427088391284_0057_01_000010.tokens to /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0057/container_1427088391284_0057_01_000010.tokens\n"
    },
    {
        "timestamp": "2015-03-23 09:19:38,347",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Localizer CWD set to /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0057 = file:/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0057\n"
    },
    {
        "timestamp": "2015-03-23 09:19:38,524",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/0a2ca13f-a0e7-4431-b746-1aaf8a06af93/hive_2015-03-23_09-14-46_354_2434748962565824460-1/-mr-10007/08acf87f-5dad-48a8-a062-8e58cebf01ab/map.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/filecache/60/map.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 09:19:38,582",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/0a2ca13f-a0e7-4431-b746-1aaf8a06af93/hive_2015-03-23_09-14-46_354_2434748962565824460-1/-mr-10007/08acf87f-5dad-48a8-a062-8e58cebf01ab/reduce.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/filecache/61/reduce.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 09:19:39,158",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0057/job.jar(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0057/filecache/10/job.jar) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 09:19:39,228",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0057/job.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0057/filecache/11/job.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 09:19:39,229",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0057_01_000010 transitioned from LOCALIZING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 09:19:39,293",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0057_01_000010 transitioned from LOCALIZED to RUNNING\n"
    },
    {
        "timestamp": "2015-03-23 09:19:39,324",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " launchContainer: [bash, /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0057/container_1427088391284_0057_01_000010/default_container_executor.sh]\n"
    },
    {
        "timestamp": "2015-03-23 09:19:41,336",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Starting resource-monitoring for container_1427088391284_0057_01_000010\n"
    },
    {
        "timestamp": "2015-03-23 09:19:41,464",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6000 for container-id container_1427088391284_0057_01_000010: 47.3 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:19:44,493",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6000 for container-id container_1427088391284_0057_01_000010: 56.8 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:19:47,539",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6000 for container-id container_1427088391284_0057_01_000010: 76.3 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:19:50,559",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6000 for container-id container_1427088391284_0057_01_000010: 82.1 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:19:53,583",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6000 for container-id container_1427088391284_0057_01_000010: 93.5 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:19:56,613",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6000 for container-id container_1427088391284_0057_01_000010: 102.5 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:19:59,625",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6000 for container-id container_1427088391284_0057_01_000010: 204.6 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:20:02,647",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6000 for container-id container_1427088391284_0057_01_000010: 205.7 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:20:05,728",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6000 for container-id container_1427088391284_0057_01_000010: 206.0 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:20:08,740",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6000 for container-id container_1427088391284_0057_01_000010: 206.8 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:20:08,971",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch",
        "message": " Container container_1427088391284_0057_01_000010 succeeded \n"
    },
    {
        "timestamp": "2015-03-23 09:20:08,971",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0057_01_000010 transitioned from RUNNING to EXITED_WITH_SUCCESS\n"
    },
    {
        "timestamp": "2015-03-23 09:20:08,971",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch",
        "message": " Cleaning up container container_1427088391284_0057_01_000010\n"
    },
    {
        "timestamp": "2015-03-23 09:20:09,070",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Deleting absolute path : /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0057/container_1427088391284_0057_01_000010\n"
    },
    {
        "timestamp": "2015-03-23 09:20:09,073",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tOPERATION=Container Finished - Succeeded\tTARGET=ContainerImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0057\tCONTAINERID=container_1427088391284_0057_01_000010\n"
    },
    {
        "timestamp": "2015-03-23 09:20:09,073",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0057_01_000010 transitioned from EXITED_WITH_SUCCESS to DONE\n"
    },
    {
        "timestamp": "2015-03-23 09:20:09,073",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Removing container_1427088391284_0057_01_000010 from application application_1427088391284_0057\n"
    },
    {
        "timestamp": "2015-03-23 09:20:09,073",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event CONTAINER_STOP for appId application_1427088391284_0057\n"
    },
    {
        "timestamp": "2015-03-23 09:20:09,226",
        "type": "INFO",
        "app": "SecurityLogger.org.apache.hadoop.ipc.Server",
        "message": " Auth successful for appattempt_1427088391284_0057_000001 (auth:SIMPLE)\n"
    },
    {
        "timestamp": "2015-03-23 09:20:09,506",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Stopping container with container Id: container_1427088391284_0057_01_000010\n"
    },
    {
        "timestamp": "2015-03-23 09:20:09,506",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tIP=172.31.17.138\tOPERATION=Stop Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0057\tCONTAINERID=container_1427088391284_0057_01_000010\n"
    },
    {
        "timestamp": "2015-03-23 09:20:11,741",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Stopping resource-monitoring for container_1427088391284_0057_01_000010\n"
    },
    {
        "timestamp": "2015-03-23 09:20:13,516",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl",
        "message": " Removed completed containers from NM context: [container_1427088391284_0057_01_000010]\n"
    },
    {
        "timestamp": "2015-03-23 09:20:14,367",
        "type": "INFO",
        "app": "SecurityLogger.org.apache.hadoop.ipc.Server",
        "message": " Auth successful for appattempt_1427088391284_0057_000001 (auth:SIMPLE)\n"
    },
    {
        "timestamp": "2015-03-23 09:20:14,521",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Start request for container_1427088391284_0057_01_000090 by user ubuntu\n"
    },
    {
        "timestamp": "2015-03-23 09:20:14,522",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Adding container_1427088391284_0057_01_000090 to application application_1427088391284_0057\n"
    },
    {
        "timestamp": "2015-03-23 09:20:14,522",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0057_01_000090 transitioned from NEW to LOCALIZING\n"
    },
    {
        "timestamp": "2015-03-23 09:20:14,522",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event CONTAINER_INIT for appId application_1427088391284_0057\n"
    },
    {
        "timestamp": "2015-03-23 09:20:14,522",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event APPLICATION_INIT for appId application_1427088391284_0057\n"
    },
    {
        "timestamp": "2015-03-23 09:20:14,522",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got APPLICATION_INIT for service mapreduce_shuffle\n"
    },
    {
        "timestamp": "2015-03-23 09:20:14,522",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Added token for job_1427088391284_0057\n"
    },
    {
        "timestamp": "2015-03-23 09:20:14,523",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0057_01_000090 transitioned from LOCALIZING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 09:20:14,528",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tIP=172.31.17.138\tOPERATION=Start Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0057\tCONTAINERID=container_1427088391284_0057_01_000090\n"
    },
    {
        "timestamp": "2015-03-23 09:20:14,584",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0057_01_000090 transitioned from LOCALIZED to RUNNING\n"
    },
    {
        "timestamp": "2015-03-23 09:20:14,591",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " launchContainer: [bash, /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0057/container_1427088391284_0057_01_000090/default_container_executor.sh]\n"
    },
    {
        "timestamp": "2015-03-23 09:20:14,764",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Starting resource-monitoring for container_1427088391284_0057_01_000090\n"
    },
    {
        "timestamp": "2015-03-23 09:20:14,787",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6042 for container-id container_1427088391284_0057_01_000090: 11.8 MB of 4 GB physical memory used; 6.3 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:20:17,802",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6042 for container-id container_1427088391284_0057_01_000090: 49.0 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:20:20,890",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6042 for container-id container_1427088391284_0057_01_000090: 63.3 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:20:23,907",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6042 for container-id container_1427088391284_0057_01_000090: 78.5 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:20:26,944",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6042 for container-id container_1427088391284_0057_01_000090: 93.8 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:20:27,856",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:20:29,037",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:20:29,241",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:20:29,461",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:20:29,508",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:20:29,602",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:20:29,653",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:20:29,671",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:20:29,725",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:20:29,749",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:20:29,796",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:20:29,854",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:20:30,037",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6042 for container-id container_1427088391284_0057_01_000090: 101.6 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:20:30,086",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:20:30,092",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:20:30,289",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:20:30,718",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:20:30,828",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:20:30,915",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:20:30,924",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:20:31,068",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:20:31,095",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:20:31,144",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:20:31,282",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:20:31,419",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:20:31,516",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:20:31,568",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:20:31,825",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:20:31,846",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:20:31,897",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:20:31,898",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:20:31,918",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:20:31,945",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:20:31,993",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:20:31,995",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:20:32,065",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:20:32,072",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:20:32,259",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:20:32,381",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:20:32,406",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:20:32,512",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:20:32,518",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:20:32,567",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:20:32,700",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:20:32,715",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:20:32,737",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:20:32,852",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:20:32,970",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:20:33,049",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6042 for container-id container_1427088391284_0057_01_000090: 101.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:20:33,793",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 09:20:36,062",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6042 for container-id container_1427088391284_0057_01_000090: 99.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:20:39,085",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6042 for container-id container_1427088391284_0057_01_000090: 107.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:20:42,130",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6042 for container-id container_1427088391284_0057_01_000090: 111.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:20:45,146",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6042 for container-id container_1427088391284_0057_01_000090: 123.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:20:47,408",
        "type": "INFO",
        "app": "SecurityLogger.org.apache.hadoop.ipc.Server",
        "message": " Auth successful for appattempt_1427088391284_0057_000001 (auth:SIMPLE)\n"
    },
    {
        "timestamp": "2015-03-23 09:20:47,420",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch",
        "message": " Container container_1427088391284_0057_01_000090 succeeded \n"
    },
    {
        "timestamp": "2015-03-23 09:20:47,420",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0057_01_000090 transitioned from RUNNING to EXITED_WITH_SUCCESS\n"
    },
    {
        "timestamp": "2015-03-23 09:20:47,420",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch",
        "message": " Cleaning up container container_1427088391284_0057_01_000090\n"
    },
    {
        "timestamp": "2015-03-23 09:20:47,471",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Stopping container with container Id: container_1427088391284_0057_01_000090\n"
    },
    {
        "timestamp": "2015-03-23 09:20:47,471",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tIP=172.31.17.138\tOPERATION=Stop Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0057\tCONTAINERID=container_1427088391284_0057_01_000090\n"
    },
    {
        "timestamp": "2015-03-23 09:20:47,547",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Deleting absolute path : /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0057/container_1427088391284_0057_01_000090\n"
    },
    {
        "timestamp": "2015-03-23 09:20:47,550",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tOPERATION=Container Finished - Succeeded\tTARGET=ContainerImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0057\tCONTAINERID=container_1427088391284_0057_01_000090\n"
    },
    {
        "timestamp": "2015-03-23 09:20:47,550",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0057_01_000090 transitioned from EXITED_WITH_SUCCESS to DONE\n"
    },
    {
        "timestamp": "2015-03-23 09:20:47,550",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Removing container_1427088391284_0057_01_000090 from application application_1427088391284_0057\n"
    },
    {
        "timestamp": "2015-03-23 09:20:47,550",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event CONTAINER_STOP for appId application_1427088391284_0057\n"
    },
    {
        "timestamp": "2015-03-23 09:20:48,146",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Stopping resource-monitoring for container_1427088391284_0057_01_000090\n"
    },
    {
        "timestamp": "2015-03-23 09:20:56,574",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl",
        "message": " Removed completed containers from NM context: [container_1427088391284_0057_01_000090]\n"
    },
    {
        "timestamp": "2015-03-23 09:20:56,574",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0057 transitioned from RUNNING to APPLICATION_RESOURCES_CLEANINGUP\n"
    },
    {
        "timestamp": "2015-03-23 09:20:56,575",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event APPLICATION_STOP for appId application_1427088391284_0057\n"
    },
    {
        "timestamp": "2015-03-23 09:20:56,575",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0057 transitioned from APPLICATION_RESOURCES_CLEANINGUP to FINISHED\n"
    },
    {
        "timestamp": "2015-03-23 09:20:56,575",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler",
        "message": " Scheduling Log Deletion for application: application_1427088391284_0057, with delay of 172800 seconds\n"
    },
    {
        "timestamp": "2015-03-23 09:20:56,576",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Deleting absolute path : /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0057\n"
    },
    {
        "timestamp": "2015-03-23 09:24:20,914",
        "type": "WARN",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Event EventType: KILL_CONTAINER sent to absent container container_1427088391284_0059_01_000090\n"
    },
    {
        "timestamp": "2015-03-23 09:32:04,187",
        "type": "WARN",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Event EventType: FINISH_APPLICATION sent to absent application application_1427088391284_0059\n"
    },
    {
        "timestamp": "2015-03-23 09:43:22,784",
        "type": "INFO",
        "app": "SecurityLogger.org.apache.hadoop.ipc.Server",
        "message": " Auth successful for appattempt_1427088391284_0063_000001 (auth:SIMPLE)\n"
    },
    {
        "timestamp": "2015-03-23 09:43:22,969",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Start request for container_1427088391284_0063_01_000087 by user ubuntu\n"
    },
    {
        "timestamp": "2015-03-23 09:43:22,970",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Creating a new application reference for app application_1427088391284_0063\n"
    },
    {
        "timestamp": "2015-03-23 09:43:22,970",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0063 transitioned from NEW to INITING\n"
    },
    {
        "timestamp": "2015-03-23 09:43:22,970",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0063 transitioned from INITING to RUNNING\n"
    },
    {
        "timestamp": "2015-03-23 09:43:22,970",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Adding container_1427088391284_0063_01_000087 to application application_1427088391284_0063\n"
    },
    {
        "timestamp": "2015-03-23 09:43:22,971",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0063_01_000087 transitioned from NEW to LOCALIZING\n"
    },
    {
        "timestamp": "2015-03-23 09:43:22,971",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event CONTAINER_INIT for appId application_1427088391284_0063\n"
    },
    {
        "timestamp": "2015-03-23 09:43:22,971",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event APPLICATION_INIT for appId application_1427088391284_0063\n"
    },
    {
        "timestamp": "2015-03-23 09:43:22,971",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got APPLICATION_INIT for service mapreduce_shuffle\n"
    },
    {
        "timestamp": "2015-03-23 09:43:22,971",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Added token for job_1427088391284_0063\n"
    },
    {
        "timestamp": "2015-03-23 09:43:22,972",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/8723662d-1d85-4661-856e-51234ded753a/hive_2015-03-23_09-41-43_214_3830095574455686628-1/-mr-10003/a6f8bf2a-4359-4528-a21b-374282f4fcc7/map.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 09:43:22,972",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/8723662d-1d85-4661-856e-51234ded753a/hive_2015-03-23_09-41-43_214_3830095574455686628-1/-mr-10003/a6f8bf2a-4359-4528-a21b-374282f4fcc7/reduce.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 09:43:22,972",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0063/job.jar transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 09:43:22,972",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0063/job.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 09:43:22,972",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService",
        "message": " Created localizer for container_1427088391284_0063_01_000087\n"
    },
    {
        "timestamp": "2015-03-23 09:43:22,972",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tIP=172.31.17.2\tOPERATION=Start Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0063\tCONTAINERID=container_1427088391284_0063_01_000087\n"
    },
    {
        "timestamp": "2015-03-23 09:43:22,975",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService",
        "message": " Writing credentials to the nmPrivate file /tmp/hadoop-ubuntu/nm-local-dir/nmPrivate/container_1427088391284_0063_01_000087.tokens. Credentials list: \n"
    },
    {
        "timestamp": "2015-03-23 09:43:22,999",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Initializing user ubuntu\n"
    },
    {
        "timestamp": "2015-03-23 09:43:23,002",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Copying from /tmp/hadoop-ubuntu/nm-local-dir/nmPrivate/container_1427088391284_0063_01_000087.tokens to /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0063/container_1427088391284_0063_01_000087.tokens\n"
    },
    {
        "timestamp": "2015-03-23 09:43:23,003",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Localizer CWD set to /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0063 = file:/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0063\n"
    },
    {
        "timestamp": "2015-03-23 09:43:23,195",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/8723662d-1d85-4661-856e-51234ded753a/hive_2015-03-23_09-41-43_214_3830095574455686628-1/-mr-10003/a6f8bf2a-4359-4528-a21b-374282f4fcc7/map.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/filecache/62/map.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 09:43:23,324",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/8723662d-1d85-4661-856e-51234ded753a/hive_2015-03-23_09-41-43_214_3830095574455686628-1/-mr-10003/a6f8bf2a-4359-4528-a21b-374282f4fcc7/reduce.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/filecache/63/reduce.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 09:43:24,336",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0063/job.jar(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0063/filecache/10/job.jar) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 09:43:24,437",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0063/job.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0063/filecache/11/job.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 09:43:24,438",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0063_01_000087 transitioned from LOCALIZING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 09:43:24,490",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0063_01_000087 transitioned from LOCALIZED to RUNNING\n"
    },
    {
        "timestamp": "2015-03-23 09:43:24,497",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " launchContainer: [bash, /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0063/container_1427088391284_0063_01_000087/default_container_executor.sh]\n"
    },
    {
        "timestamp": "2015-03-23 09:43:27,230",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Starting resource-monitoring for container_1427088391284_0063_01_000087\n"
    },
    {
        "timestamp": "2015-03-23 09:43:27,272",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6182 for container-id container_1427088391284_0063_01_000087: 48.3 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:43:30,285",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6182 for container-id container_1427088391284_0063_01_000087: 60.3 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:43:33,318",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6182 for container-id container_1427088391284_0063_01_000087: 77.0 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:43:36,379",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6182 for container-id container_1427088391284_0063_01_000087: 90.3 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:43:39,396",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6182 for container-id container_1427088391284_0063_01_000087: 98.8 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:43:42,405",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6182 for container-id container_1427088391284_0063_01_000087: 111.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:43:45,414",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6182 for container-id container_1427088391284_0063_01_000087: 111.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:43:48,426",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6182 for container-id container_1427088391284_0063_01_000087: 111.2 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:43:50,446",
        "type": "INFO",
        "app": "SecurityLogger.org.apache.hadoop.ipc.Server",
        "message": " Auth successful for appattempt_1427088391284_0063_000001 (auth:SIMPLE)\n"
    },
    {
        "timestamp": "2015-03-23 09:43:50,450",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Start request for container_1427088391284_0063_01_000168 by user ubuntu\n"
    },
    {
        "timestamp": "2015-03-23 09:43:50,451",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Adding container_1427088391284_0063_01_000168 to application application_1427088391284_0063\n"
    },
    {
        "timestamp": "2015-03-23 09:43:50,451",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0063_01_000168 transitioned from NEW to LOCALIZING\n"
    },
    {
        "timestamp": "2015-03-23 09:43:50,451",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event CONTAINER_INIT for appId application_1427088391284_0063\n"
    },
    {
        "timestamp": "2015-03-23 09:43:50,451",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event APPLICATION_INIT for appId application_1427088391284_0063\n"
    },
    {
        "timestamp": "2015-03-23 09:43:50,451",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got APPLICATION_INIT for service mapreduce_shuffle\n"
    },
    {
        "timestamp": "2015-03-23 09:43:50,452",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Added token for job_1427088391284_0063\n"
    },
    {
        "timestamp": "2015-03-23 09:43:50,452",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0063_01_000168 transitioned from LOCALIZING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 09:43:50,453",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tIP=172.31.17.2\tOPERATION=Start Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0063\tCONTAINERID=container_1427088391284_0063_01_000168\n"
    },
    {
        "timestamp": "2015-03-23 09:43:50,513",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0063_01_000168 transitioned from LOCALIZED to RUNNING\n"
    },
    {
        "timestamp": "2015-03-23 09:43:50,523",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " launchContainer: [bash, /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0063/container_1427088391284_0063_01_000168/default_container_executor.sh]\n"
    },
    {
        "timestamp": "2015-03-23 09:43:51,440",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Starting resource-monitoring for container_1427088391284_0063_01_000168\n"
    },
    {
        "timestamp": "2015-03-23 09:43:51,535",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6182 for container-id container_1427088391284_0063_01_000087: 113.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:43:51,544",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6226 for container-id container_1427088391284_0063_01_000168: 33.7 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:43:54,635",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6182 for container-id container_1427088391284_0063_01_000087: 117.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:43:54,644",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6226 for container-id container_1427088391284_0063_01_000168: 52.8 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:43:57,657",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6182 for container-id container_1427088391284_0063_01_000087: 117.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:43:57,696",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6226 for container-id container_1427088391284_0063_01_000168: 69.7 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:44:00,738",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6182 for container-id container_1427088391284_0063_01_000087: 117.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:44:00,821",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6226 for container-id container_1427088391284_0063_01_000168: 80.4 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:44:03,855",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6182 for container-id container_1427088391284_0063_01_000087: 122.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:44:03,944",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6226 for container-id container_1427088391284_0063_01_000168: 94.3 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:44:06,957",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6182 for container-id container_1427088391284_0063_01_000087: 122.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:44:06,992",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6226 for container-id container_1427088391284_0063_01_000168: 101.8 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:44:10,030",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6182 for container-id container_1427088391284_0063_01_000087: 122.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:44:10,038",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6226 for container-id container_1427088391284_0063_01_000168: 209.1 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:44:10,915",
        "type": "INFO",
        "app": "SecurityLogger.org.apache.hadoop.ipc.Server",
        "message": " Auth successful for appattempt_1427088391284_0063_000001 (auth:SIMPLE)\n"
    },
    {
        "timestamp": "2015-03-23 09:44:10,918",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Stopping container with container Id: container_1427088391284_0063_01_000168\n"
    },
    {
        "timestamp": "2015-03-23 09:44:10,918",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tIP=172.31.17.2\tOPERATION=Stop Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0063\tCONTAINERID=container_1427088391284_0063_01_000168\n"
    },
    {
        "timestamp": "2015-03-23 09:44:10,918",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0063_01_000168 transitioned from RUNNING to KILLING\n"
    },
    {
        "timestamp": "2015-03-23 09:44:10,918",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch",
        "message": " Cleaning up container container_1427088391284_0063_01_000168\n"
    },
    {
        "timestamp": "2015-03-23 09:44:11,062",
        "type": "WARN",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Exit code from container container_1427088391284_0063_01_000168 is : 143\n"
    },
    {
        "timestamp": "2015-03-23 09:44:11,138",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0063_01_000168 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL\n"
    },
    {
        "timestamp": "2015-03-23 09:44:11,138",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Deleting absolute path : /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0063/container_1427088391284_0063_01_000168\n"
    },
    {
        "timestamp": "2015-03-23 09:44:11,140",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tOPERATION=Container Finished - Killed\tTARGET=ContainerImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0063\tCONTAINERID=container_1427088391284_0063_01_000168\n"
    },
    {
        "timestamp": "2015-03-23 09:44:11,141",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0063_01_000168 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE\n"
    },
    {
        "timestamp": "2015-03-23 09:44:11,141",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Removing container_1427088391284_0063_01_000168 from application application_1427088391284_0063\n"
    },
    {
        "timestamp": "2015-03-23 09:44:11,141",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event CONTAINER_STOP for appId application_1427088391284_0063\n"
    },
    {
        "timestamp": "2015-03-23 09:44:13,039",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Stopping resource-monitoring for container_1427088391284_0063_01_000168\n"
    },
    {
        "timestamp": "2015-03-23 09:44:13,048",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6182 for container-id container_1427088391284_0063_01_000087: 125.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:44:13,967",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl",
        "message": " Removed completed containers from NM context: [container_1427088391284_0063_01_000168]\n"
    },
    {
        "timestamp": "2015-03-23 09:44:16,056",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6182 for container-id container_1427088391284_0063_01_000087: 125.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:44:19,068",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6182 for container-id container_1427088391284_0063_01_000087: 125.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:44:22,077",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6182 for container-id container_1427088391284_0063_01_000087: 132.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:44:25,085",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6182 for container-id container_1427088391284_0063_01_000087: 132.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:44:28,097",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6182 for container-id container_1427088391284_0063_01_000087: 132.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:44:31,106",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6182 for container-id container_1427088391284_0063_01_000087: 132.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:44:34,115",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6182 for container-id container_1427088391284_0063_01_000087: 132.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:44:37,124",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6182 for container-id container_1427088391284_0063_01_000087: 132.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:44:40,133",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6182 for container-id container_1427088391284_0063_01_000087: 135.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:44:43,142",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6182 for container-id container_1427088391284_0063_01_000087: 137.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:44:46,151",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6182 for container-id container_1427088391284_0063_01_000087: 144.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:44:49,163",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6182 for container-id container_1427088391284_0063_01_000087: 144.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:44:52,173",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6182 for container-id container_1427088391284_0063_01_000087: 144.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:44:55,182",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6182 for container-id container_1427088391284_0063_01_000087: 144.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:44:58,194",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6182 for container-id container_1427088391284_0063_01_000087: 144.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:45:01,204",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6182 for container-id container_1427088391284_0063_01_000087: 144.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:45:04,213",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6182 for container-id container_1427088391284_0063_01_000087: 144.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:45:07,226",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6182 for container-id container_1427088391284_0063_01_000087: 144.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:45:10,245",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6182 for container-id container_1427088391284_0063_01_000087: 145.1 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:45:13,275",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6182 for container-id container_1427088391284_0063_01_000087: 149.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:45:16,314",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6182 for container-id container_1427088391284_0063_01_000087: 156.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:45:19,347",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6182 for container-id container_1427088391284_0063_01_000087: 163.1 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:45:22,380",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6182 for container-id container_1427088391284_0063_01_000087: 176.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:45:25,405",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6182 for container-id container_1427088391284_0063_01_000087: 168.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:45:28,437",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6182 for container-id container_1427088391284_0063_01_000087: 168.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:45:31,482",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6182 for container-id container_1427088391284_0063_01_000087: 163.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:45:34,518",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6182 for container-id container_1427088391284_0063_01_000087: 163.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:45:37,550",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6182 for container-id container_1427088391284_0063_01_000087: 163.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:45:40,563",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6182 for container-id container_1427088391284_0063_01_000087: 163.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:45:43,576",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6182 for container-id container_1427088391284_0063_01_000087: 163.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:45:46,609",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6182 for container-id container_1427088391284_0063_01_000087: 163.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:45:49,617",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6182 for container-id container_1427088391284_0063_01_000087: 163.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:45:52,657",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6182 for container-id container_1427088391284_0063_01_000087: 163.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:45:55,749",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6182 for container-id container_1427088391284_0063_01_000087: 163.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:45:58,789",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6182 for container-id container_1427088391284_0063_01_000087: 163.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:46:01,816",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6182 for container-id container_1427088391284_0063_01_000087: 163.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:46:04,852",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6182 for container-id container_1427088391284_0063_01_000087: 163.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:46:07,884",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6182 for container-id container_1427088391284_0063_01_000087: 163.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:46:10,551",
        "type": "INFO",
        "app": "SecurityLogger.org.apache.hadoop.ipc.Server",
        "message": " Auth successful for appattempt_1427088391284_0063_000001 (auth:SIMPLE)\n"
    },
    {
        "timestamp": "2015-03-23 09:46:10,553",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Stopping container with container Id: container_1427088391284_0063_01_000087\n"
    },
    {
        "timestamp": "2015-03-23 09:46:10,553",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tIP=172.31.17.2\tOPERATION=Stop Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0063\tCONTAINERID=container_1427088391284_0063_01_000087\n"
    },
    {
        "timestamp": "2015-03-23 09:46:10,554",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0063_01_000087 transitioned from RUNNING to KILLING\n"
    },
    {
        "timestamp": "2015-03-23 09:46:10,554",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch",
        "message": " Cleaning up container container_1427088391284_0063_01_000087\n"
    },
    {
        "timestamp": "2015-03-23 09:46:10,655",
        "type": "WARN",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Exit code from container container_1427088391284_0063_01_000087 is : 143\n"
    },
    {
        "timestamp": "2015-03-23 09:46:10,665",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0063_01_000087 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL\n"
    },
    {
        "timestamp": "2015-03-23 09:46:10,665",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Deleting absolute path : /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0063/container_1427088391284_0063_01_000087\n"
    },
    {
        "timestamp": "2015-03-23 09:46:10,668",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tOPERATION=Container Finished - Killed\tTARGET=ContainerImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0063\tCONTAINERID=container_1427088391284_0063_01_000087\n"
    },
    {
        "timestamp": "2015-03-23 09:46:10,668",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0063_01_000087 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE\n"
    },
    {
        "timestamp": "2015-03-23 09:46:10,668",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Removing container_1427088391284_0063_01_000087 from application application_1427088391284_0063\n"
    },
    {
        "timestamp": "2015-03-23 09:46:10,668",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event CONTAINER_STOP for appId application_1427088391284_0063\n"
    },
    {
        "timestamp": "2015-03-23 09:46:10,885",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Stopping resource-monitoring for container_1427088391284_0063_01_000087\n"
    },
    {
        "timestamp": "2015-03-23 09:46:13,563",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl",
        "message": " Removed completed containers from NM context: [container_1427088391284_0063_01_000087]\n"
    },
    {
        "timestamp": "2015-03-23 09:46:28,647",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0063 transitioned from RUNNING to APPLICATION_RESOURCES_CLEANINGUP\n"
    },
    {
        "timestamp": "2015-03-23 09:46:28,648",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event APPLICATION_STOP for appId application_1427088391284_0063\n"
    },
    {
        "timestamp": "2015-03-23 09:46:28,648",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0063 transitioned from APPLICATION_RESOURCES_CLEANINGUP to FINISHED\n"
    },
    {
        "timestamp": "2015-03-23 09:46:28,648",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler",
        "message": " Scheduling Log Deletion for application: application_1427088391284_0063, with delay of 172800 seconds\n"
    },
    {
        "timestamp": "2015-03-23 09:46:28,648",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Deleting absolute path : /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0063\n"
    },
    {
        "timestamp": "2015-03-23 09:57:52,825",
        "type": "INFO",
        "app": "SecurityLogger.org.apache.hadoop.ipc.Server",
        "message": " Auth successful for appattempt_1427088391284_0067_000001 (auth:SIMPLE)\n"
    },
    {
        "timestamp": "2015-03-23 09:57:52,925",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Start request for container_1427088391284_0067_01_000163 by user ubuntu\n"
    },
    {
        "timestamp": "2015-03-23 09:57:52,925",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Creating a new application reference for app application_1427088391284_0067\n"
    },
    {
        "timestamp": "2015-03-23 09:57:52,926",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0067 transitioned from NEW to INITING\n"
    },
    {
        "timestamp": "2015-03-23 09:57:52,926",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0067 transitioned from INITING to RUNNING\n"
    },
    {
        "timestamp": "2015-03-23 09:57:52,926",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Adding container_1427088391284_0067_01_000163 to application application_1427088391284_0067\n"
    },
    {
        "timestamp": "2015-03-23 09:57:52,926",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0067_01_000163 transitioned from NEW to LOCALIZING\n"
    },
    {
        "timestamp": "2015-03-23 09:57:52,927",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event CONTAINER_INIT for appId application_1427088391284_0067\n"
    },
    {
        "timestamp": "2015-03-23 09:57:52,927",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event APPLICATION_INIT for appId application_1427088391284_0067\n"
    },
    {
        "timestamp": "2015-03-23 09:57:52,927",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got APPLICATION_INIT for service mapreduce_shuffle\n"
    },
    {
        "timestamp": "2015-03-23 09:57:52,927",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Added token for job_1427088391284_0067\n"
    },
    {
        "timestamp": "2015-03-23 09:57:52,927",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/72463537-116c-44a6-b71e-62bcaa31c505/hive_2015-03-23_09-56-14_086_7715079455331298756-1/-mr-10003/38b3b377-3832-4865-a44a-9e686c95677f/map.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 09:57:52,927",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/72463537-116c-44a6-b71e-62bcaa31c505/hive_2015-03-23_09-56-14_086_7715079455331298756-1/-mr-10003/38b3b377-3832-4865-a44a-9e686c95677f/reduce.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 09:57:52,927",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0067/job.jar transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 09:57:52,927",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0067/job.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 09:57:52,928",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService",
        "message": " Created localizer for container_1427088391284_0067_01_000163\n"
    },
    {
        "timestamp": "2015-03-23 09:57:52,928",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tIP=172.31.17.108\tOPERATION=Start Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0067\tCONTAINERID=container_1427088391284_0067_01_000163\n"
    },
    {
        "timestamp": "2015-03-23 09:57:52,933",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService",
        "message": " Writing credentials to the nmPrivate file /tmp/hadoop-ubuntu/nm-local-dir/nmPrivate/container_1427088391284_0067_01_000163.tokens. Credentials list: \n"
    },
    {
        "timestamp": "2015-03-23 09:57:52,953",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Initializing user ubuntu\n"
    },
    {
        "timestamp": "2015-03-23 09:57:52,995",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Copying from /tmp/hadoop-ubuntu/nm-local-dir/nmPrivate/container_1427088391284_0067_01_000163.tokens to /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0067/container_1427088391284_0067_01_000163.tokens\n"
    },
    {
        "timestamp": "2015-03-23 09:57:52,996",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Localizer CWD set to /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0067 = file:/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0067\n"
    },
    {
        "timestamp": "2015-03-23 09:57:53,161",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/72463537-116c-44a6-b71e-62bcaa31c505/hive_2015-03-23_09-56-14_086_7715079455331298756-1/-mr-10003/38b3b377-3832-4865-a44a-9e686c95677f/map.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/filecache/64/map.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 09:57:53,238",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/72463537-116c-44a6-b71e-62bcaa31c505/hive_2015-03-23_09-56-14_086_7715079455331298756-1/-mr-10003/38b3b377-3832-4865-a44a-9e686c95677f/reduce.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/filecache/65/reduce.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 09:57:53,704",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0067/job.jar(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0067/filecache/10/job.jar) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 09:57:53,753",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0067/job.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0067/filecache/11/job.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 09:57:53,753",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0067_01_000163 transitioned from LOCALIZING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 09:57:53,849",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0067_01_000163 transitioned from LOCALIZED to RUNNING\n"
    },
    {
        "timestamp": "2015-03-23 09:57:53,856",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " launchContainer: [bash, /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0067/container_1427088391284_0067_01_000163/default_container_executor.sh]\n"
    },
    {
        "timestamp": "2015-03-23 09:57:55,947",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Starting resource-monitoring for container_1427088391284_0067_01_000163\n"
    },
    {
        "timestamp": "2015-03-23 09:57:56,092",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6372 for container-id container_1427088391284_0067_01_000163: 46.7 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:57:59,121",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6372 for container-id container_1427088391284_0067_01_000163: 59.7 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:58:02,160",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6372 for container-id container_1427088391284_0067_01_000163: 78.1 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:58:05,181",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6372 for container-id container_1427088391284_0067_01_000163: 83.0 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:58:08,213",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6372 for container-id container_1427088391284_0067_01_000163: 94.7 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:58:11,227",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6372 for container-id container_1427088391284_0067_01_000163: 110.1 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:58:14,236",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6372 for container-id container_1427088391284_0067_01_000163: 115.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:58:17,248",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6372 for container-id container_1427088391284_0067_01_000163: 115.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:58:20,257",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6372 for container-id container_1427088391284_0067_01_000163: 116.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:58:23,266",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6372 for container-id container_1427088391284_0067_01_000163: 122.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:58:26,279",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6372 for container-id container_1427088391284_0067_01_000163: 122.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:58:29,287",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6372 for container-id container_1427088391284_0067_01_000163: 129.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:58:32,297",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6372 for container-id container_1427088391284_0067_01_000163: 129.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:58:35,309",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6372 for container-id container_1427088391284_0067_01_000163: 129.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:58:38,318",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6372 for container-id container_1427088391284_0067_01_000163: 129.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:58:41,328",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6372 for container-id container_1427088391284_0067_01_000163: 129.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:58:44,337",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6372 for container-id container_1427088391284_0067_01_000163: 131.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:58:47,349",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6372 for container-id container_1427088391284_0067_01_000163: 137.2 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:58:50,357",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6372 for container-id container_1427088391284_0067_01_000163: 137.2 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:58:53,366",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6372 for container-id container_1427088391284_0067_01_000163: 137.2 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:58:56,378",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6372 for container-id container_1427088391284_0067_01_000163: 137.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:58:59,387",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6372 for container-id container_1427088391284_0067_01_000163: 137.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:59:02,396",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6372 for container-id container_1427088391284_0067_01_000163: 137.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:59:05,409",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6372 for container-id container_1427088391284_0067_01_000163: 139.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:59:08,417",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6372 for container-id container_1427088391284_0067_01_000163: 141.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:59:11,426",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6372 for container-id container_1427088391284_0067_01_000163: 144.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:59:14,438",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6372 for container-id container_1427088391284_0067_01_000163: 149.1 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:59:17,447",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6372 for container-id container_1427088391284_0067_01_000163: 149.1 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:59:20,456",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6372 for container-id container_1427088391284_0067_01_000163: 149.1 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:59:23,465",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6372 for container-id container_1427088391284_0067_01_000163: 149.1 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:59:26,477",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6372 for container-id container_1427088391284_0067_01_000163: 149.1 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:59:29,485",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6372 for container-id container_1427088391284_0067_01_000163: 149.1 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:59:32,494",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6372 for container-id container_1427088391284_0067_01_000163: 149.1 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:59:35,506",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6372 for container-id container_1427088391284_0067_01_000163: 149.1 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:59:38,525",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6372 for container-id container_1427088391284_0067_01_000163: 155.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:59:41,564",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6372 for container-id container_1427088391284_0067_01_000163: 161.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:59:44,610",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6372 for container-id container_1427088391284_0067_01_000163: 166.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:59:47,765",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6372 for container-id container_1427088391284_0067_01_000163: 175.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:59:50,781",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6372 for container-id container_1427088391284_0067_01_000163: 170.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:59:53,866",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6372 for container-id container_1427088391284_0067_01_000163: 170.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:59:56,896",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6372 for container-id container_1427088391284_0067_01_000163: 170.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 09:59:59,921",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6372 for container-id container_1427088391284_0067_01_000163: 170.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:00:02,960",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6372 for container-id container_1427088391284_0067_01_000163: 170.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:00:05,984",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6372 for container-id container_1427088391284_0067_01_000163: 170.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:00:09,018",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6372 for container-id container_1427088391284_0067_01_000163: 170.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:00:12,106",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6372 for container-id container_1427088391284_0067_01_000163: 170.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:00:15,145",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6372 for container-id container_1427088391284_0067_01_000163: 170.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:00:18,275",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6372 for container-id container_1427088391284_0067_01_000163: 170.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:00:21,310",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6372 for container-id container_1427088391284_0067_01_000163: 170.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:00:24,843",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6372 for container-id container_1427088391284_0067_01_000163: 170.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:00:27,937",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6372 for container-id container_1427088391284_0067_01_000163: 170.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:00:30,950",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6372 for container-id container_1427088391284_0067_01_000163: 170.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:00:34,044",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6372 for container-id container_1427088391284_0067_01_000163: 170.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:00:36,698",
        "type": "INFO",
        "app": "SecurityLogger.org.apache.hadoop.ipc.Server",
        "message": " Auth successful for appattempt_1427088391284_0067_000001 (auth:SIMPLE)\n"
    },
    {
        "timestamp": "2015-03-23 10:00:36,700",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Stopping container with container Id: container_1427088391284_0067_01_000163\n"
    },
    {
        "timestamp": "2015-03-23 10:00:36,700",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tIP=172.31.17.108\tOPERATION=Stop Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0067\tCONTAINERID=container_1427088391284_0067_01_000163\n"
    },
    {
        "timestamp": "2015-03-23 10:00:36,701",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0067_01_000163 transitioned from RUNNING to KILLING\n"
    },
    {
        "timestamp": "2015-03-23 10:00:36,701",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch",
        "message": " Cleaning up container container_1427088391284_0067_01_000163\n"
    },
    {
        "timestamp": "2015-03-23 10:00:36,733",
        "type": "WARN",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Exit code from container container_1427088391284_0067_01_000163 is : 143\n"
    },
    {
        "timestamp": "2015-03-23 10:00:36,785",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0067_01_000163 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL\n"
    },
    {
        "timestamp": "2015-03-23 10:00:36,786",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Deleting absolute path : /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0067/container_1427088391284_0067_01_000163\n"
    },
    {
        "timestamp": "2015-03-23 10:00:36,788",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tOPERATION=Container Finished - Killed\tTARGET=ContainerImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0067\tCONTAINERID=container_1427088391284_0067_01_000163\n"
    },
    {
        "timestamp": "2015-03-23 10:00:36,788",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0067_01_000163 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE\n"
    },
    {
        "timestamp": "2015-03-23 10:00:36,788",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Removing container_1427088391284_0067_01_000163 from application application_1427088391284_0067\n"
    },
    {
        "timestamp": "2015-03-23 10:00:36,788",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event CONTAINER_STOP for appId application_1427088391284_0067\n"
    },
    {
        "timestamp": "2015-03-23 10:00:37,045",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Stopping resource-monitoring for container_1427088391284_0067_01_000163\n"
    },
    {
        "timestamp": "2015-03-23 10:00:40,766",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl",
        "message": " Removed completed containers from NM context: [container_1427088391284_0067_01_000163]\n"
    },
    {
        "timestamp": "2015-03-23 10:01:54,334",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0067 transitioned from RUNNING to APPLICATION_RESOURCES_CLEANINGUP\n"
    },
    {
        "timestamp": "2015-03-23 10:01:54,335",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event APPLICATION_STOP for appId application_1427088391284_0067\n"
    },
    {
        "timestamp": "2015-03-23 10:01:54,335",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0067 transitioned from APPLICATION_RESOURCES_CLEANINGUP to FINISHED\n"
    },
    {
        "timestamp": "2015-03-23 10:01:54,335",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler",
        "message": " Scheduling Log Deletion for application: application_1427088391284_0067, with delay of 172800 seconds\n"
    },
    {
        "timestamp": "2015-03-23 10:01:54,335",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Deleting absolute path : /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0067\n"
    },
    {
        "timestamp": "2015-03-23 10:04:23,120",
        "type": "INFO",
        "app": "SecurityLogger.org.apache.hadoop.ipc.Server",
        "message": " Auth successful for appattempt_1427088391284_0068_000001 (auth:SIMPLE)\n"
    },
    {
        "timestamp": "2015-03-23 10:04:23,269",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Start request for container_1427088391284_0068_01_000171 by user ubuntu\n"
    },
    {
        "timestamp": "2015-03-23 10:04:23,270",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Creating a new application reference for app application_1427088391284_0068\n"
    },
    {
        "timestamp": "2015-03-23 10:04:23,270",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0068 transitioned from NEW to INITING\n"
    },
    {
        "timestamp": "2015-03-23 10:04:23,270",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0068 transitioned from INITING to RUNNING\n"
    },
    {
        "timestamp": "2015-03-23 10:04:23,271",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Adding container_1427088391284_0068_01_000171 to application application_1427088391284_0068\n"
    },
    {
        "timestamp": "2015-03-23 10:04:23,271",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0068_01_000171 transitioned from NEW to LOCALIZING\n"
    },
    {
        "timestamp": "2015-03-23 10:04:23,271",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event CONTAINER_INIT for appId application_1427088391284_0068\n"
    },
    {
        "timestamp": "2015-03-23 10:04:23,271",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event APPLICATION_INIT for appId application_1427088391284_0068\n"
    },
    {
        "timestamp": "2015-03-23 10:04:23,271",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got APPLICATION_INIT for service mapreduce_shuffle\n"
    },
    {
        "timestamp": "2015-03-23 10:04:23,271",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Added token for job_1427088391284_0068\n"
    },
    {
        "timestamp": "2015-03-23 10:04:23,272",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/e481a1ab-471f-4e6b-8faf-c8539b2ce09d/hive_2015-03-23_10-02-49_711_8979275617120589633-1/-mr-10005/ac55d807-f7aa-43e0-a913-06cc0fafd75d/map.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 10:04:23,272",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/e481a1ab-471f-4e6b-8faf-c8539b2ce09d/hive_2015-03-23_10-02-49_711_8979275617120589633-1/-mr-10005/ac55d807-f7aa-43e0-a913-06cc0fafd75d/reduce.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 10:04:23,272",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0068/job.jar transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 10:04:23,272",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0068/job.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 10:04:23,272",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService",
        "message": " Created localizer for container_1427088391284_0068_01_000171\n"
    },
    {
        "timestamp": "2015-03-23 10:04:23,272",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tIP=172.31.16.233\tOPERATION=Start Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0068\tCONTAINERID=container_1427088391284_0068_01_000171\n"
    },
    {
        "timestamp": "2015-03-23 10:04:23,277",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService",
        "message": " Writing credentials to the nmPrivate file /tmp/hadoop-ubuntu/nm-local-dir/nmPrivate/container_1427088391284_0068_01_000171.tokens. Credentials list: \n"
    },
    {
        "timestamp": "2015-03-23 10:04:23,299",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Initializing user ubuntu\n"
    },
    {
        "timestamp": "2015-03-23 10:04:23,302",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Copying from /tmp/hadoop-ubuntu/nm-local-dir/nmPrivate/container_1427088391284_0068_01_000171.tokens to /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0068/container_1427088391284_0068_01_000171.tokens\n"
    },
    {
        "timestamp": "2015-03-23 10:04:23,302",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Localizer CWD set to /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0068 = file:/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0068\n"
    },
    {
        "timestamp": "2015-03-23 10:04:23,466",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/e481a1ab-471f-4e6b-8faf-c8539b2ce09d/hive_2015-03-23_10-02-49_711_8979275617120589633-1/-mr-10005/ac55d807-f7aa-43e0-a913-06cc0fafd75d/map.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/filecache/66/map.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 10:04:23,516",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/e481a1ab-471f-4e6b-8faf-c8539b2ce09d/hive_2015-03-23_10-02-49_711_8979275617120589633-1/-mr-10005/ac55d807-f7aa-43e0-a913-06cc0fafd75d/reduce.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/filecache/67/reduce.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 10:04:24,142",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0068/job.jar(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0068/filecache/10/job.jar) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 10:04:24,231",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0068/job.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0068/filecache/11/job.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 10:04:24,231",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0068_01_000171 transitioned from LOCALIZING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 10:04:24,261",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0068_01_000171 transitioned from LOCALIZED to RUNNING\n"
    },
    {
        "timestamp": "2015-03-23 10:04:24,292",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " launchContainer: [bash, /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0068/container_1427088391284_0068_01_000171/default_container_executor.sh]\n"
    },
    {
        "timestamp": "2015-03-23 10:04:25,056",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Starting resource-monitoring for container_1427088391284_0068_01_000171\n"
    },
    {
        "timestamp": "2015-03-23 10:04:25,106",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6495 for container-id container_1427088391284_0068_01_000171: 28.4 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:04:28,146",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6495 for container-id container_1427088391284_0068_01_000171: 54.0 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:04:31,172",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6495 for container-id container_1427088391284_0068_01_000171: 70.4 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:04:34,219",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6495 for container-id container_1427088391284_0068_01_000171: 82.1 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:04:37,399",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6495 for container-id container_1427088391284_0068_01_000171: 92.4 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:04:40,433",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6495 for container-id container_1427088391284_0068_01_000171: 102.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:04:43,445",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6495 for container-id container_1427088391284_0068_01_000171: 110.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:04:46,454",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6495 for container-id container_1427088391284_0068_01_000171: 113.2 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:04:49,463",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6495 for container-id container_1427088391284_0068_01_000171: 118.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:04:52,472",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6495 for container-id container_1427088391284_0068_01_000171: 118.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:04:55,484",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6495 for container-id container_1427088391284_0068_01_000171: 119.2 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:04:58,493",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6495 for container-id container_1427088391284_0068_01_000171: 124.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:05:01,525",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6495 for container-id container_1427088391284_0068_01_000171: 124.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:05:04,546",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6495 for container-id container_1427088391284_0068_01_000171: 124.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:05:07,556",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6495 for container-id container_1427088391284_0068_01_000171: 124.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:05:10,565",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6495 for container-id container_1427088391284_0068_01_000171: 124.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:05:13,578",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6495 for container-id container_1427088391284_0068_01_000171: 125.7 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:05:16,587",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6495 for container-id container_1427088391284_0068_01_000171: 125.7 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:05:19,596",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6495 for container-id container_1427088391284_0068_01_000171: 125.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:05:22,633",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6495 for container-id container_1427088391284_0068_01_000171: 125.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:05:25,643",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6495 for container-id container_1427088391284_0068_01_000171: 126.7 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:05:28,676",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6495 for container-id container_1427088391284_0068_01_000171: 126.7 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:05:31,685",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6495 for container-id container_1427088391284_0068_01_000171: 126.7 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:05:34,699",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6495 for container-id container_1427088391284_0068_01_000171: 126.7 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:05:37,708",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6495 for container-id container_1427088391284_0068_01_000171: 126.7 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:05:40,717",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6495 for container-id container_1427088391284_0068_01_000171: 128.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:05:43,730",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6495 for container-id container_1427088391284_0068_01_000171: 128.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:05:46,739",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6495 for container-id container_1427088391284_0068_01_000171: 128.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:05:49,748",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6495 for container-id container_1427088391284_0068_01_000171: 128.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:05:52,761",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6495 for container-id container_1427088391284_0068_01_000171: 128.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:05:55,770",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6495 for container-id container_1427088391284_0068_01_000171: 128.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:05:58,779",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6495 for container-id container_1427088391284_0068_01_000171: 128.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:06:01,793",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6495 for container-id container_1427088391284_0068_01_000171: 128.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:06:04,804",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6495 for container-id container_1427088391284_0068_01_000171: 128.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:06:07,813",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6495 for container-id container_1427088391284_0068_01_000171: 129.7 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:06:10,825",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6495 for container-id container_1427088391284_0068_01_000171: 129.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:06:13,876",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6495 for container-id container_1427088391284_0068_01_000171: 129.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:06:16,885",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6495 for container-id container_1427088391284_0068_01_000171: 129.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:06:19,895",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6495 for container-id container_1427088391284_0068_01_000171: 129.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:06:22,908",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6495 for container-id container_1427088391284_0068_01_000171: 129.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:06:25,917",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6495 for container-id container_1427088391284_0068_01_000171: 130.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:06:28,926",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6495 for container-id container_1427088391284_0068_01_000171: 132.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:06:31,939",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6495 for container-id container_1427088391284_0068_01_000171: 133.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:06:34,948",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6495 for container-id container_1427088391284_0068_01_000171: 133.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:06:37,957",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6495 for container-id container_1427088391284_0068_01_000171: 133.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:06:40,995",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6495 for container-id container_1427088391284_0068_01_000171: 133.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:06:44,024",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6495 for container-id container_1427088391284_0068_01_000171: 140.7 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:06:47,043",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6495 for container-id container_1427088391284_0068_01_000171: 142.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:06:50,095",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6495 for container-id container_1427088391284_0068_01_000171: 149.7 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:06:53,138",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6495 for container-id container_1427088391284_0068_01_000171: 156.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:06:55,582",
        "type": "INFO",
        "app": "SecurityLogger.org.apache.hadoop.ipc.Server",
        "message": " Auth successful for appattempt_1427088391284_0068_000001 (auth:SIMPLE)\n"
    },
    {
        "timestamp": "2015-03-23 10:06:55,587",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Stopping container with container Id: container_1427088391284_0068_01_000171\n"
    },
    {
        "timestamp": "2015-03-23 10:06:55,587",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tIP=172.31.16.233\tOPERATION=Stop Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0068\tCONTAINERID=container_1427088391284_0068_01_000171\n"
    },
    {
        "timestamp": "2015-03-23 10:06:55,588",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0068_01_000171 transitioned from RUNNING to KILLING\n"
    },
    {
        "timestamp": "2015-03-23 10:06:55,588",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch",
        "message": " Cleaning up container container_1427088391284_0068_01_000171\n"
    },
    {
        "timestamp": "2015-03-23 10:06:55,926",
        "type": "WARN",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Exit code from container container_1427088391284_0068_01_000171 is : 143\n"
    },
    {
        "timestamp": "2015-03-23 10:06:55,928",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0068_01_000171 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL\n"
    },
    {
        "timestamp": "2015-03-23 10:06:55,929",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Deleting absolute path : /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0068/container_1427088391284_0068_01_000171\n"
    },
    {
        "timestamp": "2015-03-23 10:06:55,931",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tOPERATION=Container Finished - Killed\tTARGET=ContainerImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0068\tCONTAINERID=container_1427088391284_0068_01_000171\n"
    },
    {
        "timestamp": "2015-03-23 10:06:55,931",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0068_01_000171 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE\n"
    },
    {
        "timestamp": "2015-03-23 10:06:55,931",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Removing container_1427088391284_0068_01_000171 from application application_1427088391284_0068\n"
    },
    {
        "timestamp": "2015-03-23 10:06:55,931",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event CONTAINER_STOP for appId application_1427088391284_0068\n"
    },
    {
        "timestamp": "2015-03-23 10:06:56,139",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Stopping resource-monitoring for container_1427088391284_0068_01_000171\n"
    },
    {
        "timestamp": "2015-03-23 10:06:58,822",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl",
        "message": " Removed completed containers from NM context: [container_1427088391284_0068_01_000171]\n"
    },
    {
        "timestamp": "2015-03-23 10:07:20,014",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0068 transitioned from RUNNING to APPLICATION_RESOURCES_CLEANINGUP\n"
    },
    {
        "timestamp": "2015-03-23 10:07:20,015",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event APPLICATION_STOP for appId application_1427088391284_0068\n"
    },
    {
        "timestamp": "2015-03-23 10:07:20,015",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0068 transitioned from APPLICATION_RESOURCES_CLEANINGUP to FINISHED\n"
    },
    {
        "timestamp": "2015-03-23 10:07:20,015",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler",
        "message": " Scheduling Log Deletion for application: application_1427088391284_0068, with delay of 172800 seconds\n"
    },
    {
        "timestamp": "2015-03-23 10:07:20,018",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Deleting absolute path : /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0068\n"
    },
    {
        "timestamp": "2015-03-23 10:19:34,689",
        "type": "INFO",
        "app": "SecurityLogger.org.apache.hadoop.ipc.Server",
        "message": " Auth successful for appattempt_1427088391284_0072_000001 (auth:SIMPLE)\n"
    },
    {
        "timestamp": "2015-03-23 10:19:34,978",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Start request for container_1427088391284_0072_01_000165 by user ubuntu\n"
    },
    {
        "timestamp": "2015-03-23 10:19:34,978",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Creating a new application reference for app application_1427088391284_0072\n"
    },
    {
        "timestamp": "2015-03-23 10:19:34,979",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0072 transitioned from NEW to INITING\n"
    },
    {
        "timestamp": "2015-03-23 10:19:34,979",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0072 transitioned from INITING to RUNNING\n"
    },
    {
        "timestamp": "2015-03-23 10:19:34,979",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Adding container_1427088391284_0072_01_000165 to application application_1427088391284_0072\n"
    },
    {
        "timestamp": "2015-03-23 10:19:34,979",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0072_01_000165 transitioned from NEW to LOCALIZING\n"
    },
    {
        "timestamp": "2015-03-23 10:19:34,980",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event CONTAINER_INIT for appId application_1427088391284_0072\n"
    },
    {
        "timestamp": "2015-03-23 10:19:34,980",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event APPLICATION_INIT for appId application_1427088391284_0072\n"
    },
    {
        "timestamp": "2015-03-23 10:19:34,980",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got APPLICATION_INIT for service mapreduce_shuffle\n"
    },
    {
        "timestamp": "2015-03-23 10:19:34,980",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Added token for job_1427088391284_0072\n"
    },
    {
        "timestamp": "2015-03-23 10:19:34,980",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/46a596ba-ae66-4674-b9ad-20fdf6958c29/hive_2015-03-23_10-18-09_127_6342888489495760377-1/-mr-10005/921a64ca-3db1-45fc-af5e-a981765f1324/map.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 10:19:34,980",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/46a596ba-ae66-4674-b9ad-20fdf6958c29/hive_2015-03-23_10-18-09_127_6342888489495760377-1/-mr-10005/921a64ca-3db1-45fc-af5e-a981765f1324/reduce.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 10:19:34,980",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0072/job.jar transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 10:19:34,980",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0072/job.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 10:19:34,980",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService",
        "message": " Created localizer for container_1427088391284_0072_01_000165\n"
    },
    {
        "timestamp": "2015-03-23 10:19:34,981",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tIP=172.31.17.20\tOPERATION=Start Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0072\tCONTAINERID=container_1427088391284_0072_01_000165\n"
    },
    {
        "timestamp": "2015-03-23 10:19:34,985",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService",
        "message": " Writing credentials to the nmPrivate file /tmp/hadoop-ubuntu/nm-local-dir/nmPrivate/container_1427088391284_0072_01_000165.tokens. Credentials list: \n"
    },
    {
        "timestamp": "2015-03-23 10:19:35,009",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Initializing user ubuntu\n"
    },
    {
        "timestamp": "2015-03-23 10:19:35,012",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Copying from /tmp/hadoop-ubuntu/nm-local-dir/nmPrivate/container_1427088391284_0072_01_000165.tokens to /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0072/container_1427088391284_0072_01_000165.tokens\n"
    },
    {
        "timestamp": "2015-03-23 10:19:35,012",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Localizer CWD set to /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0072 = file:/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0072\n"
    },
    {
        "timestamp": "2015-03-23 10:19:35,145",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/46a596ba-ae66-4674-b9ad-20fdf6958c29/hive_2015-03-23_10-18-09_127_6342888489495760377-1/-mr-10005/921a64ca-3db1-45fc-af5e-a981765f1324/map.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/filecache/68/map.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 10:19:35,238",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/46a596ba-ae66-4674-b9ad-20fdf6958c29/hive_2015-03-23_10-18-09_127_6342888489495760377-1/-mr-10005/921a64ca-3db1-45fc-af5e-a981765f1324/reduce.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/filecache/69/reduce.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 10:19:35,798",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0072/job.jar(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0072/filecache/10/job.jar) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 10:19:35,837",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0072/job.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0072/filecache/11/job.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 10:19:35,838",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0072_01_000165 transitioned from LOCALIZING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 10:19:35,902",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0072_01_000165 transitioned from LOCALIZED to RUNNING\n"
    },
    {
        "timestamp": "2015-03-23 10:19:35,909",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " launchContainer: [bash, /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0072/container_1427088391284_0072_01_000165/default_container_executor.sh]\n"
    },
    {
        "timestamp": "2015-03-23 10:19:38,185",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Starting resource-monitoring for container_1427088391284_0072_01_000165\n"
    },
    {
        "timestamp": "2015-03-23 10:19:38,274",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6625 for container-id container_1427088391284_0072_01_000165: 48.0 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:19:41,311",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6625 for container-id container_1427088391284_0072_01_000165: 58.5 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:19:44,329",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6625 for container-id container_1427088391284_0072_01_000165: 78.6 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:19:47,345",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6625 for container-id container_1427088391284_0072_01_000165: 83.9 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:19:50,385",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6625 for container-id container_1427088391284_0072_01_000165: 98.4 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:19:53,393",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6625 for container-id container_1427088391284_0072_01_000165: 107.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:19:56,402",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6625 for container-id container_1427088391284_0072_01_000165: 107.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:19:59,414",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6625 for container-id container_1427088391284_0072_01_000165: 107.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:20:02,424",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6625 for container-id container_1427088391284_0072_01_000165: 109.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:20:05,435",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6625 for container-id container_1427088391284_0072_01_000165: 113.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:20:08,447",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6625 for container-id container_1427088391284_0072_01_000165: 116 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:20:11,455",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6625 for container-id container_1427088391284_0072_01_000165: 116 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:20:14,464",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6625 for container-id container_1427088391284_0072_01_000165: 116.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:20:17,476",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6625 for container-id container_1427088391284_0072_01_000165: 116.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:20:20,485",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6625 for container-id container_1427088391284_0072_01_000165: 116.1 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:20:23,494",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6625 for container-id container_1427088391284_0072_01_000165: 119.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:20:26,502",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6625 for container-id container_1427088391284_0072_01_000165: 119.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:20:29,515",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6625 for container-id container_1427088391284_0072_01_000165: 119.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:20:32,523",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6625 for container-id container_1427088391284_0072_01_000165: 119.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:20:35,532",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6625 for container-id container_1427088391284_0072_01_000165: 120.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:20:38,544",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6625 for container-id container_1427088391284_0072_01_000165: 120.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:20:41,552",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6625 for container-id container_1427088391284_0072_01_000165: 120.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:20:44,561",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6625 for container-id container_1427088391284_0072_01_000165: 120.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:20:47,573",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6625 for container-id container_1427088391284_0072_01_000165: 120.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:20:50,583",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6625 for container-id container_1427088391284_0072_01_000165: 122.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:20:53,592",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6625 for container-id container_1427088391284_0072_01_000165: 122.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:20:56,605",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6625 for container-id container_1427088391284_0072_01_000165: 122.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:20:59,616",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6625 for container-id container_1427088391284_0072_01_000165: 122.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:21:02,624",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6625 for container-id container_1427088391284_0072_01_000165: 122.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:21:05,633",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6625 for container-id container_1427088391284_0072_01_000165: 122.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:21:08,645",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6625 for container-id container_1427088391284_0072_01_000165: 122.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:21:11,653",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6625 for container-id container_1427088391284_0072_01_000165: 122.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:21:14,663",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6625 for container-id container_1427088391284_0072_01_000165: 122.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:21:17,676",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6625 for container-id container_1427088391284_0072_01_000165: 123.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:21:20,684",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6625 for container-id container_1427088391284_0072_01_000165: 123.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:21:23,693",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6625 for container-id container_1427088391284_0072_01_000165: 123.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:21:26,706",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6625 for container-id container_1427088391284_0072_01_000165: 123.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:21:29,715",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6625 for container-id container_1427088391284_0072_01_000165: 123.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:21:32,724",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6625 for container-id container_1427088391284_0072_01_000165: 123.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:21:35,732",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6625 for container-id container_1427088391284_0072_01_000165: 123.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:21:38,741",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6625 for container-id container_1427088391284_0072_01_000165: 123.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:21:41,750",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6625 for container-id container_1427088391284_0072_01_000165: 123.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:21:44,758",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6625 for container-id container_1427088391284_0072_01_000165: 123.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:21:47,770",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6625 for container-id container_1427088391284_0072_01_000165: 123.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:21:50,779",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6625 for container-id container_1427088391284_0072_01_000165: 123.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:21:53,787",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6625 for container-id container_1427088391284_0072_01_000165: 123.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:21:56,831",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6625 for container-id container_1427088391284_0072_01_000165: 127.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:21:59,844",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6625 for container-id container_1427088391284_0072_01_000165: 133.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:22:02,860",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6625 for container-id container_1427088391284_0072_01_000165: 133.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:22:05,892",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6625 for container-id container_1427088391284_0072_01_000165: 133.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:22:08,911",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6625 for container-id container_1427088391284_0072_01_000165: 137.7 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:22:10,411",
        "type": "INFO",
        "app": "SecurityLogger.org.apache.hadoop.ipc.Server",
        "message": " Auth successful for appattempt_1427088391284_0072_000001 (auth:SIMPLE)\n"
    },
    {
        "timestamp": "2015-03-23 10:22:10,506",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Stopping container with container Id: container_1427088391284_0072_01_000165\n"
    },
    {
        "timestamp": "2015-03-23 10:22:10,507",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tIP=172.31.17.20\tOPERATION=Stop Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0072\tCONTAINERID=container_1427088391284_0072_01_000165\n"
    },
    {
        "timestamp": "2015-03-23 10:22:10,507",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0072_01_000165 transitioned from RUNNING to KILLING\n"
    },
    {
        "timestamp": "2015-03-23 10:22:10,507",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch",
        "message": " Cleaning up container container_1427088391284_0072_01_000165\n"
    },
    {
        "timestamp": "2015-03-23 10:22:10,606",
        "type": "WARN",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Exit code from container container_1427088391284_0072_01_000165 is : 143\n"
    },
    {
        "timestamp": "2015-03-23 10:22:10,660",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0072_01_000165 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL\n"
    },
    {
        "timestamp": "2015-03-23 10:22:10,661",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Deleting absolute path : /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0072/container_1427088391284_0072_01_000165\n"
    },
    {
        "timestamp": "2015-03-23 10:22:10,663",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tOPERATION=Container Finished - Killed\tTARGET=ContainerImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0072\tCONTAINERID=container_1427088391284_0072_01_000165\n"
    },
    {
        "timestamp": "2015-03-23 10:22:10,663",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0072_01_000165 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE\n"
    },
    {
        "timestamp": "2015-03-23 10:22:10,663",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Removing container_1427088391284_0072_01_000165 from application application_1427088391284_0072\n"
    },
    {
        "timestamp": "2015-03-23 10:22:10,663",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event CONTAINER_STOP for appId application_1427088391284_0072\n"
    },
    {
        "timestamp": "2015-03-23 10:22:11,911",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Stopping resource-monitoring for container_1427088391284_0072_01_000165\n"
    },
    {
        "timestamp": "2015-03-23 10:22:13,520",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl",
        "message": " Removed completed containers from NM context: [container_1427088391284_0072_01_000165]\n"
    },
    {
        "timestamp": "2015-03-23 10:22:21,555",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0072 transitioned from RUNNING to APPLICATION_RESOURCES_CLEANINGUP\n"
    },
    {
        "timestamp": "2015-03-23 10:22:21,556",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event APPLICATION_STOP for appId application_1427088391284_0072\n"
    },
    {
        "timestamp": "2015-03-23 10:22:21,556",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0072 transitioned from APPLICATION_RESOURCES_CLEANINGUP to FINISHED\n"
    },
    {
        "timestamp": "2015-03-23 10:22:21,556",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler",
        "message": " Scheduling Log Deletion for application: application_1427088391284_0072, with delay of 172800 seconds\n"
    },
    {
        "timestamp": "2015-03-23 10:22:21,556",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Deleting absolute path : /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0072\n"
    },
    {
        "timestamp": "2015-03-23 10:55:42,932",
        "type": "INFO",
        "app": "SecurityLogger.org.apache.hadoop.ipc.Server",
        "message": " Auth successful for appattempt_1427088391284_0081_000001 (auth:SIMPLE)\n"
    },
    {
        "timestamp": "2015-03-23 10:55:43,265",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Start request for container_1427088391284_0081_01_000018 by user ubuntu\n"
    },
    {
        "timestamp": "2015-03-23 10:55:43,265",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Creating a new application reference for app application_1427088391284_0081\n"
    },
    {
        "timestamp": "2015-03-23 10:55:43,266",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0081 transitioned from NEW to INITING\n"
    },
    {
        "timestamp": "2015-03-23 10:55:43,266",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0081 transitioned from INITING to RUNNING\n"
    },
    {
        "timestamp": "2015-03-23 10:55:43,266",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Adding container_1427088391284_0081_01_000018 to application application_1427088391284_0081\n"
    },
    {
        "timestamp": "2015-03-23 10:55:43,267",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0081_01_000018 transitioned from NEW to LOCALIZING\n"
    },
    {
        "timestamp": "2015-03-23 10:55:43,267",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event CONTAINER_INIT for appId application_1427088391284_0081\n"
    },
    {
        "timestamp": "2015-03-23 10:55:43,267",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event APPLICATION_INIT for appId application_1427088391284_0081\n"
    },
    {
        "timestamp": "2015-03-23 10:55:43,267",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got APPLICATION_INIT for service mapreduce_shuffle\n"
    },
    {
        "timestamp": "2015-03-23 10:55:43,267",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Added token for job_1427088391284_0081\n"
    },
    {
        "timestamp": "2015-03-23 10:55:43,267",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/57789e9d-885c-46fe-99d3-c447b6d9d6ba/hive_2015-03-23_10-50-57_154_6611927580389654886-1/-mr-10007/d84f58a7-8b16-4652-ac33-b7013c00cda7/map.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 10:55:43,267",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/57789e9d-885c-46fe-99d3-c447b6d9d6ba/hive_2015-03-23_10-50-57_154_6611927580389654886-1/-mr-10007/d84f58a7-8b16-4652-ac33-b7013c00cda7/reduce.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 10:55:43,268",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0081/job.jar transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 10:55:43,268",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0081/job.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 10:55:43,268",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService",
        "message": " Created localizer for container_1427088391284_0081_01_000018\n"
    },
    {
        "timestamp": "2015-03-23 10:55:43,268",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tIP=172.31.17.22\tOPERATION=Start Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0081\tCONTAINERID=container_1427088391284_0081_01_000018\n"
    },
    {
        "timestamp": "2015-03-23 10:55:43,273",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService",
        "message": " Writing credentials to the nmPrivate file /tmp/hadoop-ubuntu/nm-local-dir/nmPrivate/container_1427088391284_0081_01_000018.tokens. Credentials list: \n"
    },
    {
        "timestamp": "2015-03-23 10:55:43,293",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Initializing user ubuntu\n"
    },
    {
        "timestamp": "2015-03-23 10:55:43,320",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Copying from /tmp/hadoop-ubuntu/nm-local-dir/nmPrivate/container_1427088391284_0081_01_000018.tokens to /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0081/container_1427088391284_0081_01_000018.tokens\n"
    },
    {
        "timestamp": "2015-03-23 10:55:43,321",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Localizer CWD set to /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0081 = file:/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0081\n"
    },
    {
        "timestamp": "2015-03-23 10:55:43,447",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/57789e9d-885c-46fe-99d3-c447b6d9d6ba/hive_2015-03-23_10-50-57_154_6611927580389654886-1/-mr-10007/d84f58a7-8b16-4652-ac33-b7013c00cda7/map.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/filecache/70/map.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 10:55:43,499",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/57789e9d-885c-46fe-99d3-c447b6d9d6ba/hive_2015-03-23_10-50-57_154_6611927580389654886-1/-mr-10007/d84f58a7-8b16-4652-ac33-b7013c00cda7/reduce.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/filecache/71/reduce.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 10:55:44,424",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0081/job.jar(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0081/filecache/10/job.jar) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 10:55:44,469",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0081/job.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0081/filecache/11/job.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 10:55:44,469",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0081_01_000018 transitioned from LOCALIZING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 10:55:44,549",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0081_01_000018 transitioned from LOCALIZED to RUNNING\n"
    },
    {
        "timestamp": "2015-03-23 10:55:44,555",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " launchContainer: [bash, /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0081/container_1427088391284_0081_01_000018/default_container_executor.sh]\n"
    },
    {
        "timestamp": "2015-03-23 10:55:44,990",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Starting resource-monitoring for container_1427088391284_0081_01_000018\n"
    },
    {
        "timestamp": "2015-03-23 10:55:45,219",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6835 for container-id container_1427088391284_0081_01_000018: 24.3 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:55:48,356",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6835 for container-id container_1427088391284_0081_01_000018: 53.4 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:55:51,370",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6835 for container-id container_1427088391284_0081_01_000018: 71.0 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:55:54,398",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6835 for container-id container_1427088391284_0081_01_000018: 81.1 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:55:57,430",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6835 for container-id container_1427088391284_0081_01_000018: 93.2 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:56:00,450",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6835 for container-id container_1427088391284_0081_01_000018: 97.1 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:56:03,485",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6835 for container-id container_1427088391284_0081_01_000018: 205.1 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:56:06,519",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6835 for container-id container_1427088391284_0081_01_000018: 205.8 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:56:09,559",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6835 for container-id container_1427088391284_0081_01_000018: 206.1 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:56:11,748",
        "type": "INFO",
        "app": "SecurityLogger.org.apache.hadoop.ipc.Server",
        "message": " Auth successful for appattempt_1427088391284_0081_000001 (auth:SIMPLE)\n"
    },
    {
        "timestamp": "2015-03-23 10:56:11,780",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Stopping container with container Id: container_1427088391284_0081_01_000018\n"
    },
    {
        "timestamp": "2015-03-23 10:56:11,780",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tIP=172.31.17.22\tOPERATION=Stop Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0081\tCONTAINERID=container_1427088391284_0081_01_000018\n"
    },
    {
        "timestamp": "2015-03-23 10:56:11,780",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0081_01_000018 transitioned from RUNNING to KILLING\n"
    },
    {
        "timestamp": "2015-03-23 10:56:11,780",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch",
        "message": " Cleaning up container container_1427088391284_0081_01_000018\n"
    },
    {
        "timestamp": "2015-03-23 10:56:11,883",
        "type": "WARN",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Exit code from container container_1427088391284_0081_01_000018 is : 143\n"
    },
    {
        "timestamp": "2015-03-23 10:56:11,898",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0081_01_000018 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL\n"
    },
    {
        "timestamp": "2015-03-23 10:56:11,923",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Deleting absolute path : /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0081/container_1427088391284_0081_01_000018\n"
    },
    {
        "timestamp": "2015-03-23 10:56:11,925",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tOPERATION=Container Finished - Killed\tTARGET=ContainerImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0081\tCONTAINERID=container_1427088391284_0081_01_000018\n"
    },
    {
        "timestamp": "2015-03-23 10:56:11,925",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0081_01_000018 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE\n"
    },
    {
        "timestamp": "2015-03-23 10:56:11,925",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Removing container_1427088391284_0081_01_000018 from application application_1427088391284_0081\n"
    },
    {
        "timestamp": "2015-03-23 10:56:11,925",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event CONTAINER_STOP for appId application_1427088391284_0081\n"
    },
    {
        "timestamp": "2015-03-23 10:56:12,559",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Stopping resource-monitoring for container_1427088391284_0081_01_000018\n"
    },
    {
        "timestamp": "2015-03-23 10:56:15,795",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl",
        "message": " Removed completed containers from NM context: [container_1427088391284_0081_01_000018]\n"
    },
    {
        "timestamp": "2015-03-23 10:56:29,840",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 10:56:30,485",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 10:56:30,734",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 10:56:31,104",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 10:56:31,161",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 10:56:31,346",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 10:56:31,362",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 10:56:31,385",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 10:56:31,559",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 10:56:31,659",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 10:56:31,706",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 10:56:31,733",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 10:56:31,761",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 10:56:31,826",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 10:56:31,851",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 10:56:31,963",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 10:56:32,045",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 10:56:32,051",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 10:56:32,250",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 10:56:32,269",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 10:56:32,559",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 10:56:32,614",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 10:56:32,860",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 10:56:32,884",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 10:56:33,000",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 10:56:33,001",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 10:56:33,022",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 10:56:33,059",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 10:56:33,229",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 10:56:33,262",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 10:56:33,316",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 10:56:33,318",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 10:56:33,323",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 10:56:33,338",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 10:56:33,418",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 10:56:33,540",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 10:56:33,651",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 10:56:33,661",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 10:56:33,681",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 10:56:33,877",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 10:56:33,939",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 10:56:34,059",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 10:56:34,061",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 10:56:34,190",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 10:56:34,350",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 10:56:35,616",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 10:56:37,731",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 10:56:38,626",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 10:57:05,143",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0081 transitioned from RUNNING to APPLICATION_RESOURCES_CLEANINGUP\n"
    },
    {
        "timestamp": "2015-03-23 10:57:05,144",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event APPLICATION_STOP for appId application_1427088391284_0081\n"
    },
    {
        "timestamp": "2015-03-23 10:57:05,144",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0081 transitioned from APPLICATION_RESOURCES_CLEANINGUP to FINISHED\n"
    },
    {
        "timestamp": "2015-03-23 10:57:05,144",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler",
        "message": " Scheduling Log Deletion for application: application_1427088391284_0081, with delay of 172800 seconds\n"
    },
    {
        "timestamp": "2015-03-23 10:57:05,144",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Deleting absolute path : /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0081\n"
    },
    {
        "timestamp": "2015-03-23 10:57:31,904",
        "type": "INFO",
        "app": "SecurityLogger.org.apache.hadoop.ipc.Server",
        "message": " Auth successful for appattempt_1427088391284_0082_000001 (auth:SIMPLE)\n"
    },
    {
        "timestamp": "2015-03-23 10:57:32,139",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Start request for container_1427088391284_0082_01_000017 by user ubuntu\n"
    },
    {
        "timestamp": "2015-03-23 10:57:32,139",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Creating a new application reference for app application_1427088391284_0082\n"
    },
    {
        "timestamp": "2015-03-23 10:57:32,140",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0082 transitioned from NEW to INITING\n"
    },
    {
        "timestamp": "2015-03-23 10:57:32,140",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0082 transitioned from INITING to RUNNING\n"
    },
    {
        "timestamp": "2015-03-23 10:57:32,140",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Adding container_1427088391284_0082_01_000017 to application application_1427088391284_0082\n"
    },
    {
        "timestamp": "2015-03-23 10:57:32,141",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0082_01_000017 transitioned from NEW to LOCALIZING\n"
    },
    {
        "timestamp": "2015-03-23 10:57:32,141",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event CONTAINER_INIT for appId application_1427088391284_0082\n"
    },
    {
        "timestamp": "2015-03-23 10:57:32,141",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event APPLICATION_INIT for appId application_1427088391284_0082\n"
    },
    {
        "timestamp": "2015-03-23 10:57:32,141",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got APPLICATION_INIT for service mapreduce_shuffle\n"
    },
    {
        "timestamp": "2015-03-23 10:57:32,141",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Added token for job_1427088391284_0082\n"
    },
    {
        "timestamp": "2015-03-23 10:57:32,141",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/57789e9d-885c-46fe-99d3-c447b6d9d6ba/hive_2015-03-23_10-50-57_154_6611927580389654886-1/-mr-10009/50a4a425-b1e1-4a9f-95fa-fb21e5953af4/map.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 10:57:32,141",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/57789e9d-885c-46fe-99d3-c447b6d9d6ba/hive_2015-03-23_10-50-57_154_6611927580389654886-1/-mr-10009/50a4a425-b1e1-4a9f-95fa-fb21e5953af4/reduce.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 10:57:32,141",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0082/job.jar transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 10:57:32,142",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0082/job.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 10:57:32,142",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService",
        "message": " Created localizer for container_1427088391284_0082_01_000017\n"
    },
    {
        "timestamp": "2015-03-23 10:57:32,142",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tIP=172.31.17.23\tOPERATION=Start Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0082\tCONTAINERID=container_1427088391284_0082_01_000017\n"
    },
    {
        "timestamp": "2015-03-23 10:57:32,146",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService",
        "message": " Writing credentials to the nmPrivate file /tmp/hadoop-ubuntu/nm-local-dir/nmPrivate/container_1427088391284_0082_01_000017.tokens. Credentials list: \n"
    },
    {
        "timestamp": "2015-03-23 10:57:32,168",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Initializing user ubuntu\n"
    },
    {
        "timestamp": "2015-03-23 10:57:32,171",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Copying from /tmp/hadoop-ubuntu/nm-local-dir/nmPrivate/container_1427088391284_0082_01_000017.tokens to /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0082/container_1427088391284_0082_01_000017.tokens\n"
    },
    {
        "timestamp": "2015-03-23 10:57:32,171",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Localizer CWD set to /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0082 = file:/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0082\n"
    },
    {
        "timestamp": "2015-03-23 10:57:32,315",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/57789e9d-885c-46fe-99d3-c447b6d9d6ba/hive_2015-03-23_10-50-57_154_6611927580389654886-1/-mr-10009/50a4a425-b1e1-4a9f-95fa-fb21e5953af4/map.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/filecache/72/map.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 10:57:32,365",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/57789e9d-885c-46fe-99d3-c447b6d9d6ba/hive_2015-03-23_10-50-57_154_6611927580389654886-1/-mr-10009/50a4a425-b1e1-4a9f-95fa-fb21e5953af4/reduce.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/filecache/73/reduce.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 10:57:32,855",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0082/job.jar(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0082/filecache/10/job.jar) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 10:57:32,908",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0082/job.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0082/filecache/11/job.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 10:57:32,909",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0082_01_000017 transitioned from LOCALIZING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 10:57:32,965",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0082_01_000017 transitioned from LOCALIZED to RUNNING\n"
    },
    {
        "timestamp": "2015-03-23 10:57:32,995",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " launchContainer: [bash, /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0082/container_1427088391284_0082_01_000017/default_container_executor.sh]\n"
    },
    {
        "timestamp": "2015-03-23 10:57:33,568",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Starting resource-monitoring for container_1427088391284_0082_01_000017\n"
    },
    {
        "timestamp": "2015-03-23 10:57:33,583",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6939 for container-id container_1427088391284_0082_01_000017: 23.3 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:57:36,605",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6939 for container-id container_1427088391284_0082_01_000017: 50.5 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:57:39,634",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6939 for container-id container_1427088391284_0082_01_000017: 68.4 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:57:42,654",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6939 for container-id container_1427088391284_0082_01_000017: 79.2 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:57:45,683",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6939 for container-id container_1427088391284_0082_01_000017: 93.4 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:57:48,702",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6939 for container-id container_1427088391284_0082_01_000017: 96.6 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:57:51,715",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6939 for container-id container_1427088391284_0082_01_000017: 204.5 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:57:54,731",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6939 for container-id container_1427088391284_0082_01_000017: 205.7 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:57:57,752",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 6939 for container-id container_1427088391284_0082_01_000017: 205.9 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 10:57:59,442",
        "type": "INFO",
        "app": "SecurityLogger.org.apache.hadoop.ipc.Server",
        "message": " Auth successful for appattempt_1427088391284_0082_000001 (auth:SIMPLE)\n"
    },
    {
        "timestamp": "2015-03-23 10:57:59,478",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Stopping container with container Id: container_1427088391284_0082_01_000017\n"
    },
    {
        "timestamp": "2015-03-23 10:57:59,478",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tIP=172.31.17.23\tOPERATION=Stop Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0082\tCONTAINERID=container_1427088391284_0082_01_000017\n"
    },
    {
        "timestamp": "2015-03-23 10:57:59,478",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0082_01_000017 transitioned from RUNNING to KILLING\n"
    },
    {
        "timestamp": "2015-03-23 10:57:59,478",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch",
        "message": " Cleaning up container container_1427088391284_0082_01_000017\n"
    },
    {
        "timestamp": "2015-03-23 10:57:59,506",
        "type": "WARN",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Exit code from container container_1427088391284_0082_01_000017 is : 143\n"
    },
    {
        "timestamp": "2015-03-23 10:57:59,559",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0082_01_000017 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL\n"
    },
    {
        "timestamp": "2015-03-23 10:57:59,560",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Deleting absolute path : /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0082/container_1427088391284_0082_01_000017\n"
    },
    {
        "timestamp": "2015-03-23 10:57:59,562",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tOPERATION=Container Finished - Killed\tTARGET=ContainerImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0082\tCONTAINERID=container_1427088391284_0082_01_000017\n"
    },
    {
        "timestamp": "2015-03-23 10:57:59,562",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0082_01_000017 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE\n"
    },
    {
        "timestamp": "2015-03-23 10:57:59,562",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Removing container_1427088391284_0082_01_000017 from application application_1427088391284_0082\n"
    },
    {
        "timestamp": "2015-03-23 10:57:59,562",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event CONTAINER_STOP for appId application_1427088391284_0082\n"
    },
    {
        "timestamp": "2015-03-23 10:58:00,753",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Stopping resource-monitoring for container_1427088391284_0082_01_000017\n"
    },
    {
        "timestamp": "2015-03-23 10:58:03,487",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl",
        "message": " Removed completed containers from NM context: [container_1427088391284_0082_01_000017]\n"
    },
    {
        "timestamp": "2015-03-23 10:58:22,124",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 10:58:54,603",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0082 transitioned from RUNNING to APPLICATION_RESOURCES_CLEANINGUP\n"
    },
    {
        "timestamp": "2015-03-23 10:58:54,603",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event APPLICATION_STOP for appId application_1427088391284_0082\n"
    },
    {
        "timestamp": "2015-03-23 10:58:54,604",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0082 transitioned from APPLICATION_RESOURCES_CLEANINGUP to FINISHED\n"
    },
    {
        "timestamp": "2015-03-23 10:58:54,604",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler",
        "message": " Scheduling Log Deletion for application: application_1427088391284_0082, with delay of 172800 seconds\n"
    },
    {
        "timestamp": "2015-03-23 10:58:54,604",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Deleting absolute path : /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0082\n"
    },
    {
        "timestamp": "2015-03-23 11:06:34,312",
        "type": "WARN",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Event EventType: KILL_CONTAINER sent to absent container container_1427088391284_0084_01_000153\n"
    },
    {
        "timestamp": "2015-03-23 11:09:54,916",
        "type": "WARN",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Event EventType: FINISH_APPLICATION sent to absent application application_1427088391284_0084\n"
    },
    {
        "timestamp": "2015-03-23 11:12:11,990",
        "type": "INFO",
        "app": "SecurityLogger.org.apache.hadoop.ipc.Server",
        "message": " Auth successful for appattempt_1427088391284_0086_000001 (auth:SIMPLE)\n"
    },
    {
        "timestamp": "2015-03-23 11:12:12,571",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Start request for container_1427088391284_0086_01_000040 by user ubuntu\n"
    },
    {
        "timestamp": "2015-03-23 11:12:12,572",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Creating a new application reference for app application_1427088391284_0086\n"
    },
    {
        "timestamp": "2015-03-23 11:12:12,572",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0086 transitioned from NEW to INITING\n"
    },
    {
        "timestamp": "2015-03-23 11:12:12,572",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0086 transitioned from INITING to RUNNING\n"
    },
    {
        "timestamp": "2015-03-23 11:12:12,572",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Adding container_1427088391284_0086_01_000040 to application application_1427088391284_0086\n"
    },
    {
        "timestamp": "2015-03-23 11:12:12,573",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0086_01_000040 transitioned from NEW to LOCALIZING\n"
    },
    {
        "timestamp": "2015-03-23 11:12:12,573",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event CONTAINER_INIT for appId application_1427088391284_0086\n"
    },
    {
        "timestamp": "2015-03-23 11:12:12,573",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event APPLICATION_INIT for appId application_1427088391284_0086\n"
    },
    {
        "timestamp": "2015-03-23 11:12:12,573",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got APPLICATION_INIT for service mapreduce_shuffle\n"
    },
    {
        "timestamp": "2015-03-23 11:12:12,573",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Added token for job_1427088391284_0086\n"
    },
    {
        "timestamp": "2015-03-23 11:12:12,573",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/e0f0f814-c488-401c-b756-e5f14ffc79f8/hive_2015-03-23_11-05-40_287_5508142731648152568-1/-mr-10009/e139de4a-7318-4a33-b9bc-9053a08c12a0/map.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 11:12:12,574",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/e0f0f814-c488-401c-b756-e5f14ffc79f8/hive_2015-03-23_11-05-40_287_5508142731648152568-1/-mr-10009/e139de4a-7318-4a33-b9bc-9053a08c12a0/reduce.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 11:12:12,574",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0086/job.jar transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 11:12:12,574",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0086/job.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 11:12:12,574",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService",
        "message": " Created localizer for container_1427088391284_0086_01_000040\n"
    },
    {
        "timestamp": "2015-03-23 11:12:12,574",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tIP=172.31.16.223\tOPERATION=Start Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0086\tCONTAINERID=container_1427088391284_0086_01_000040\n"
    },
    {
        "timestamp": "2015-03-23 11:12:12,579",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService",
        "message": " Writing credentials to the nmPrivate file /tmp/hadoop-ubuntu/nm-local-dir/nmPrivate/container_1427088391284_0086_01_000040.tokens. Credentials list: \n"
    },
    {
        "timestamp": "2015-03-23 11:12:12,636",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Initializing user ubuntu\n"
    },
    {
        "timestamp": "2015-03-23 11:12:12,639",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Copying from /tmp/hadoop-ubuntu/nm-local-dir/nmPrivate/container_1427088391284_0086_01_000040.tokens to /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0086/container_1427088391284_0086_01_000040.tokens\n"
    },
    {
        "timestamp": "2015-03-23 11:12:12,640",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Localizer CWD set to /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0086 = file:/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0086\n"
    },
    {
        "timestamp": "2015-03-23 11:12:12,822",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/e0f0f814-c488-401c-b756-e5f14ffc79f8/hive_2015-03-23_11-05-40_287_5508142731648152568-1/-mr-10009/e139de4a-7318-4a33-b9bc-9053a08c12a0/map.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/filecache/74/map.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 11:12:12,868",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/e0f0f814-c488-401c-b756-e5f14ffc79f8/hive_2015-03-23_11-05-40_287_5508142731648152568-1/-mr-10009/e139de4a-7318-4a33-b9bc-9053a08c12a0/reduce.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/filecache/75/reduce.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 11:12:13,430",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0086/job.jar(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0086/filecache/10/job.jar) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 11:12:13,484",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0086/job.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0086/filecache/11/job.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 11:12:13,485",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0086_01_000040 transitioned from LOCALIZING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 11:12:13,541",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0086_01_000040 transitioned from LOCALIZED to RUNNING\n"
    },
    {
        "timestamp": "2015-03-23 11:12:13,572",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " launchContainer: [bash, /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0086/container_1427088391284_0086_01_000040/default_container_executor.sh]\n"
    },
    {
        "timestamp": "2015-03-23 11:12:15,785",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Starting resource-monitoring for container_1427088391284_0086_01_000040\n"
    },
    {
        "timestamp": "2015-03-23 11:12:15,798",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7051 for container-id container_1427088391284_0086_01_000040: 47.9 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:12:18,851",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7051 for container-id container_1427088391284_0086_01_000040: 58.8 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:12:21,903",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7051 for container-id container_1427088391284_0086_01_000040: 76.8 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:12:24,930",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7051 for container-id container_1427088391284_0086_01_000040: 84.7 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:12:27,961",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7051 for container-id container_1427088391284_0086_01_000040: 93.8 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:12:31,089",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7051 for container-id container_1427088391284_0086_01_000040: 105.0 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:12:34,123",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7051 for container-id container_1427088391284_0086_01_000040: 207.7 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:12:37,162",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7051 for container-id container_1427088391284_0086_01_000040: 208.5 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:12:40,175",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7051 for container-id container_1427088391284_0086_01_000040: 208.9 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:12:40,618",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch",
        "message": " Container container_1427088391284_0086_01_000040 succeeded \n"
    },
    {
        "timestamp": "2015-03-23 11:12:40,618",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0086_01_000040 transitioned from RUNNING to EXITED_WITH_SUCCESS\n"
    },
    {
        "timestamp": "2015-03-23 11:12:40,618",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch",
        "message": " Cleaning up container container_1427088391284_0086_01_000040\n"
    },
    {
        "timestamp": "2015-03-23 11:12:40,690",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Deleting absolute path : /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0086/container_1427088391284_0086_01_000040\n"
    },
    {
        "timestamp": "2015-03-23 11:12:40,692",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tOPERATION=Container Finished - Succeeded\tTARGET=ContainerImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0086\tCONTAINERID=container_1427088391284_0086_01_000040\n"
    },
    {
        "timestamp": "2015-03-23 11:12:40,692",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0086_01_000040 transitioned from EXITED_WITH_SUCCESS to DONE\n"
    },
    {
        "timestamp": "2015-03-23 11:12:40,693",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Removing container_1427088391284_0086_01_000040 from application application_1427088391284_0086\n"
    },
    {
        "timestamp": "2015-03-23 11:12:40,693",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event CONTAINER_STOP for appId application_1427088391284_0086\n"
    },
    {
        "timestamp": "2015-03-23 11:12:40,954",
        "type": "INFO",
        "app": "SecurityLogger.org.apache.hadoop.ipc.Server",
        "message": " Auth successful for appattempt_1427088391284_0086_000001 (auth:SIMPLE)\n"
    },
    {
        "timestamp": "2015-03-23 11:12:41,143",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Stopping container with container Id: container_1427088391284_0086_01_000040\n"
    },
    {
        "timestamp": "2015-03-23 11:12:41,143",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tIP=172.31.16.223\tOPERATION=Stop Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0086\tCONTAINERID=container_1427088391284_0086_01_000040\n"
    },
    {
        "timestamp": "2015-03-23 11:12:43,175",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Stopping resource-monitoring for container_1427088391284_0086_01_000040\n"
    },
    {
        "timestamp": "2015-03-23 11:12:43,176",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl",
        "message": " Removed completed containers from NM context: [container_1427088391284_0086_01_000040]\n"
    },
    {
        "timestamp": "2015-03-23 11:13:08,139",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:13:35,350",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0086 transitioned from RUNNING to APPLICATION_RESOURCES_CLEANINGUP\n"
    },
    {
        "timestamp": "2015-03-23 11:13:35,351",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event APPLICATION_STOP for appId application_1427088391284_0086\n"
    },
    {
        "timestamp": "2015-03-23 11:13:35,352",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0086 transitioned from APPLICATION_RESOURCES_CLEANINGUP to FINISHED\n"
    },
    {
        "timestamp": "2015-03-23 11:13:35,352",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler",
        "message": " Scheduling Log Deletion for application: application_1427088391284_0086, with delay of 172800 seconds\n"
    },
    {
        "timestamp": "2015-03-23 11:13:35,351",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Deleting absolute path : /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0086\n"
    },
    {
        "timestamp": "2015-03-23 11:16:11,167",
        "type": "INFO",
        "app": "SecurityLogger.org.apache.hadoop.ipc.Server",
        "message": " Auth successful for appattempt_1427088391284_0087_000001 (auth:SIMPLE)\n"
    },
    {
        "timestamp": "2015-03-23 11:16:11,260",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Start request for container_1427088391284_0087_01_000144 by user ubuntu\n"
    },
    {
        "timestamp": "2015-03-23 11:16:11,260",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Creating a new application reference for app application_1427088391284_0087\n"
    },
    {
        "timestamp": "2015-03-23 11:16:11,261",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0087 transitioned from NEW to INITING\n"
    },
    {
        "timestamp": "2015-03-23 11:16:11,261",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0087 transitioned from INITING to RUNNING\n"
    },
    {
        "timestamp": "2015-03-23 11:16:11,261",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Adding container_1427088391284_0087_01_000144 to application application_1427088391284_0087\n"
    },
    {
        "timestamp": "2015-03-23 11:16:11,262",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0087_01_000144 transitioned from NEW to LOCALIZING\n"
    },
    {
        "timestamp": "2015-03-23 11:16:11,262",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event CONTAINER_INIT for appId application_1427088391284_0087\n"
    },
    {
        "timestamp": "2015-03-23 11:16:11,262",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event APPLICATION_INIT for appId application_1427088391284_0087\n"
    },
    {
        "timestamp": "2015-03-23 11:16:11,262",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got APPLICATION_INIT for service mapreduce_shuffle\n"
    },
    {
        "timestamp": "2015-03-23 11:16:11,262",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Added token for job_1427088391284_0087\n"
    },
    {
        "timestamp": "2015-03-23 11:16:11,262",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/8399bc40-e945-4fd2-b971-cfeb398a9ff5/hive_2015-03-23_11-14-27_258_7948204101035880663-1/-mr-10003/ceb5d328-e81f-485f-a6a0-209aa03c1fca/map.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 11:16:11,263",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/8399bc40-e945-4fd2-b971-cfeb398a9ff5/hive_2015-03-23_11-14-27_258_7948204101035880663-1/-mr-10003/ceb5d328-e81f-485f-a6a0-209aa03c1fca/reduce.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 11:16:11,263",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0087/job.jar transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 11:16:11,263",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0087/job.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 11:16:11,263",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService",
        "message": " Created localizer for container_1427088391284_0087_01_000144\n"
    },
    {
        "timestamp": "2015-03-23 11:16:11,263",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tIP=172.31.17.124\tOPERATION=Start Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0087\tCONTAINERID=container_1427088391284_0087_01_000144\n"
    },
    {
        "timestamp": "2015-03-23 11:16:11,271",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService",
        "message": " Writing credentials to the nmPrivate file /tmp/hadoop-ubuntu/nm-local-dir/nmPrivate/container_1427088391284_0087_01_000144.tokens. Credentials list: \n"
    },
    {
        "timestamp": "2015-03-23 11:16:11,321",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Initializing user ubuntu\n"
    },
    {
        "timestamp": "2015-03-23 11:16:11,324",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Copying from /tmp/hadoop-ubuntu/nm-local-dir/nmPrivate/container_1427088391284_0087_01_000144.tokens to /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0087/container_1427088391284_0087_01_000144.tokens\n"
    },
    {
        "timestamp": "2015-03-23 11:16:11,325",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Localizer CWD set to /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0087 = file:/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0087\n"
    },
    {
        "timestamp": "2015-03-23 11:16:11,465",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/8399bc40-e945-4fd2-b971-cfeb398a9ff5/hive_2015-03-23_11-14-27_258_7948204101035880663-1/-mr-10003/ceb5d328-e81f-485f-a6a0-209aa03c1fca/map.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/filecache/76/map.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 11:16:11,529",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/8399bc40-e945-4fd2-b971-cfeb398a9ff5/hive_2015-03-23_11-14-27_258_7948204101035880663-1/-mr-10003/ceb5d328-e81f-485f-a6a0-209aa03c1fca/reduce.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/filecache/77/reduce.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 11:16:12,051",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0087/job.jar(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0087/filecache/10/job.jar) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 11:16:12,255",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0087/job.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0087/filecache/11/job.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 11:16:12,255",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0087_01_000144 transitioned from LOCALIZING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 11:16:12,324",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0087_01_000144 transitioned from LOCALIZED to RUNNING\n"
    },
    {
        "timestamp": "2015-03-23 11:16:12,330",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " launchContainer: [bash, /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0087/container_1427088391284_0087_01_000144/default_container_executor.sh]\n"
    },
    {
        "timestamp": "2015-03-23 11:16:13,214",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Starting resource-monitoring for container_1427088391284_0087_01_000144\n"
    },
    {
        "timestamp": "2015-03-23 11:16:13,226",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7147 for container-id container_1427088391284_0087_01_000144: 32.5 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:16:16,436",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7147 for container-id container_1427088391284_0087_01_000144: 54.1 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:16:19,477",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7147 for container-id container_1427088391284_0087_01_000144: 72.0 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:16:22,558",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7147 for container-id container_1427088391284_0087_01_000144: 81.5 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:16:25,594",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7147 for container-id container_1427088391284_0087_01_000144: 92.9 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:16:28,712",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7147 for container-id container_1427088391284_0087_01_000144: 100.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:16:31,721",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7147 for container-id container_1427088391284_0087_01_000144: 114.2 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:16:34,730",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7147 for container-id container_1427088391284_0087_01_000144: 116.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:16:37,739",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7147 for container-id container_1427088391284_0087_01_000144: 123.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:16:40,752",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7147 for container-id container_1427088391284_0087_01_000144: 123.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:16:43,761",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7147 for container-id container_1427088391284_0087_01_000144: 123.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:16:46,770",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7147 for container-id container_1427088391284_0087_01_000144: 128.2 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:16:49,782",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7147 for container-id container_1427088391284_0087_01_000144: 128.2 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:16:52,791",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7147 for container-id container_1427088391284_0087_01_000144: 128.2 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:16:55,800",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7147 for container-id container_1427088391284_0087_01_000144: 128.2 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:16:58,812",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7147 for container-id container_1427088391284_0087_01_000144: 132.1 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:17:01,821",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7147 for container-id container_1427088391284_0087_01_000144: 132.1 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:17:04,830",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7147 for container-id container_1427088391284_0087_01_000144: 132.1 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:17:07,843",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7147 for container-id container_1427088391284_0087_01_000144: 132.7 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:17:10,851",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7147 for container-id container_1427088391284_0087_01_000144: 134.7 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:17:13,860",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7147 for container-id container_1427088391284_0087_01_000144: 136.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:17:16,868",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7147 for container-id container_1427088391284_0087_01_000144: 143.7 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:17:19,880",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7147 for container-id container_1427088391284_0087_01_000144: 143.7 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:17:22,888",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7147 for container-id container_1427088391284_0087_01_000144: 143.7 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:17:25,896",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7147 for container-id container_1427088391284_0087_01_000144: 143.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:17:28,908",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7147 for container-id container_1427088391284_0087_01_000144: 144.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:17:31,916",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7147 for container-id container_1427088391284_0087_01_000144: 144.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:17:34,925",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7147 for container-id container_1427088391284_0087_01_000144: 144.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:17:37,948",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7147 for container-id container_1427088391284_0087_01_000144: 144.2 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:17:40,956",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7147 for container-id container_1427088391284_0087_01_000144: 151.2 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:17:43,965",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7147 for container-id container_1427088391284_0087_01_000144: 151.2 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:17:46,974",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7147 for container-id container_1427088391284_0087_01_000144: 151.2 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:17:50,011",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7147 for container-id container_1427088391284_0087_01_000144: 151.2 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:17:53,058",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7147 for container-id container_1427088391284_0087_01_000144: 151.2 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:17:56,094",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7147 for container-id container_1427088391284_0087_01_000144: 151.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:17:59,136",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7147 for container-id container_1427088391284_0087_01_000144: 162.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:18:02,158",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7147 for container-id container_1427088391284_0087_01_000144: 169.1 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:18:05,179",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7147 for container-id container_1427088391284_0087_01_000144: 182.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:18:08,219",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7147 for container-id container_1427088391284_0087_01_000144: 170.7 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:18:11,239",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7147 for container-id container_1427088391284_0087_01_000144: 170.7 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:18:14,256",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7147 for container-id container_1427088391284_0087_01_000144: 170.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:18:17,317",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7147 for container-id container_1427088391284_0087_01_000144: 170.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:18:20,353",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7147 for container-id container_1427088391284_0087_01_000144: 170.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:18:23,381",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7147 for container-id container_1427088391284_0087_01_000144: 170.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:18:26,408",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7147 for container-id container_1427088391284_0087_01_000144: 170.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:18:29,438",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7147 for container-id container_1427088391284_0087_01_000144: 170.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:18:32,454",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7147 for container-id container_1427088391284_0087_01_000144: 170.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:18:35,470",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7147 for container-id container_1427088391284_0087_01_000144: 170.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:18:38,486",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7147 for container-id container_1427088391284_0087_01_000144: 170.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:18:41,505",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7147 for container-id container_1427088391284_0087_01_000144: 170.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:18:44,530",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7147 for container-id container_1427088391284_0087_01_000144: 170.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:18:47,553",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7147 for container-id container_1427088391284_0087_01_000144: 170.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:18:50,582",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7147 for container-id container_1427088391284_0087_01_000144: 170.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:18:53,607",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7147 for container-id container_1427088391284_0087_01_000144: 171.2 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:18:56,635",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7147 for container-id container_1427088391284_0087_01_000144: 171.2 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:18:57,236",
        "type": "INFO",
        "app": "SecurityLogger.org.apache.hadoop.ipc.Server",
        "message": " Auth successful for appattempt_1427088391284_0087_000001 (auth:SIMPLE)\n"
    },
    {
        "timestamp": "2015-03-23 11:18:57,239",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Stopping container with container Id: container_1427088391284_0087_01_000144\n"
    },
    {
        "timestamp": "2015-03-23 11:18:57,239",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tIP=172.31.17.124\tOPERATION=Stop Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0087\tCONTAINERID=container_1427088391284_0087_01_000144\n"
    },
    {
        "timestamp": "2015-03-23 11:18:57,240",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0087_01_000144 transitioned from RUNNING to KILLING\n"
    },
    {
        "timestamp": "2015-03-23 11:18:57,240",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch",
        "message": " Cleaning up container container_1427088391284_0087_01_000144\n"
    },
    {
        "timestamp": "2015-03-23 11:18:57,300",
        "type": "WARN",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Exit code from container container_1427088391284_0087_01_000144 is : 143\n"
    },
    {
        "timestamp": "2015-03-23 11:18:57,350",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0087_01_000144 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL\n"
    },
    {
        "timestamp": "2015-03-23 11:18:57,351",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Deleting absolute path : /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0087/container_1427088391284_0087_01_000144\n"
    },
    {
        "timestamp": "2015-03-23 11:18:57,353",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tOPERATION=Container Finished - Killed\tTARGET=ContainerImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0087\tCONTAINERID=container_1427088391284_0087_01_000144\n"
    },
    {
        "timestamp": "2015-03-23 11:18:57,353",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0087_01_000144 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE\n"
    },
    {
        "timestamp": "2015-03-23 11:18:57,353",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Removing container_1427088391284_0087_01_000144 from application application_1427088391284_0087\n"
    },
    {
        "timestamp": "2015-03-23 11:18:57,353",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event CONTAINER_STOP for appId application_1427088391284_0087\n"
    },
    {
        "timestamp": "2015-03-23 11:18:59,635",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Stopping resource-monitoring for container_1427088391284_0087_01_000144\n"
    },
    {
        "timestamp": "2015-03-23 11:19:00,250",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl",
        "message": " Removed completed containers from NM context: [container_1427088391284_0087_01_000144]\n"
    },
    {
        "timestamp": "2015-03-23 11:19:10,311",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0087 transitioned from RUNNING to APPLICATION_RESOURCES_CLEANINGUP\n"
    },
    {
        "timestamp": "2015-03-23 11:19:10,311",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event APPLICATION_STOP for appId application_1427088391284_0087\n"
    },
    {
        "timestamp": "2015-03-23 11:19:10,312",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0087 transitioned from APPLICATION_RESOURCES_CLEANINGUP to FINISHED\n"
    },
    {
        "timestamp": "2015-03-23 11:19:10,312",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler",
        "message": " Scheduling Log Deletion for application: application_1427088391284_0087, with delay of 172800 seconds\n"
    },
    {
        "timestamp": "2015-03-23 11:19:10,312",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Deleting absolute path : /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0087\n"
    },
    {
        "timestamp": "2015-03-23 11:21:58,527",
        "type": "INFO",
        "app": "SecurityLogger.org.apache.hadoop.ipc.Server",
        "message": " Auth successful for appattempt_1427088391284_0088_000001 (auth:SIMPLE)\n"
    },
    {
        "timestamp": "2015-03-23 11:21:58,531",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Start request for container_1427088391284_0088_01_000193 by user ubuntu\n"
    },
    {
        "timestamp": "2015-03-23 11:21:58,532",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Creating a new application reference for app application_1427088391284_0088\n"
    },
    {
        "timestamp": "2015-03-23 11:21:58,532",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0088 transitioned from NEW to INITING\n"
    },
    {
        "timestamp": "2015-03-23 11:21:58,532",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0088 transitioned from INITING to RUNNING\n"
    },
    {
        "timestamp": "2015-03-23 11:21:58,533",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Adding container_1427088391284_0088_01_000193 to application application_1427088391284_0088\n"
    },
    {
        "timestamp": "2015-03-23 11:21:58,533",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0088_01_000193 transitioned from NEW to LOCALIZING\n"
    },
    {
        "timestamp": "2015-03-23 11:21:58,533",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event CONTAINER_INIT for appId application_1427088391284_0088\n"
    },
    {
        "timestamp": "2015-03-23 11:21:58,533",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event APPLICATION_INIT for appId application_1427088391284_0088\n"
    },
    {
        "timestamp": "2015-03-23 11:21:58,533",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got APPLICATION_INIT for service mapreduce_shuffle\n"
    },
    {
        "timestamp": "2015-03-23 11:21:58,533",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Added token for job_1427088391284_0088\n"
    },
    {
        "timestamp": "2015-03-23 11:21:58,534",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/a68a0c47-3daa-4d82-93e5-e41babe027f5/hive_2015-03-23_11-20-05_140_8861444585183040507-1/-mr-10005/b3c40d8e-20a8-474d-9f43-7e10d4fa146b/map.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 11:21:58,534",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/a68a0c47-3daa-4d82-93e5-e41babe027f5/hive_2015-03-23_11-20-05_140_8861444585183040507-1/-mr-10005/b3c40d8e-20a8-474d-9f43-7e10d4fa146b/reduce.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 11:21:58,534",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0088/job.jar transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 11:21:58,534",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0088/job.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 11:21:58,534",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService",
        "message": " Created localizer for container_1427088391284_0088_01_000193\n"
    },
    {
        "timestamp": "2015-03-23 11:21:58,534",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tIP=172.31.17.108\tOPERATION=Start Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0088\tCONTAINERID=container_1427088391284_0088_01_000193\n"
    },
    {
        "timestamp": "2015-03-23 11:21:58,544",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService",
        "message": " Writing credentials to the nmPrivate file /tmp/hadoop-ubuntu/nm-local-dir/nmPrivate/container_1427088391284_0088_01_000193.tokens. Credentials list: \n"
    },
    {
        "timestamp": "2015-03-23 11:21:58,592",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Initializing user ubuntu\n"
    },
    {
        "timestamp": "2015-03-23 11:21:58,595",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Copying from /tmp/hadoop-ubuntu/nm-local-dir/nmPrivate/container_1427088391284_0088_01_000193.tokens to /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0088/container_1427088391284_0088_01_000193.tokens\n"
    },
    {
        "timestamp": "2015-03-23 11:21:58,595",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Localizer CWD set to /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0088 = file:/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0088\n"
    },
    {
        "timestamp": "2015-03-23 11:21:58,730",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/a68a0c47-3daa-4d82-93e5-e41babe027f5/hive_2015-03-23_11-20-05_140_8861444585183040507-1/-mr-10005/b3c40d8e-20a8-474d-9f43-7e10d4fa146b/map.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/filecache/78/map.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 11:21:58,777",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/a68a0c47-3daa-4d82-93e5-e41babe027f5/hive_2015-03-23_11-20-05_140_8861444585183040507-1/-mr-10005/b3c40d8e-20a8-474d-9f43-7e10d4fa146b/reduce.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/filecache/79/reduce.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 11:21:59,244",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0088/job.jar(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0088/filecache/10/job.jar) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 11:21:59,302",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0088/job.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0088/filecache/11/job.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 11:21:59,303",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0088_01_000193 transitioned from LOCALIZING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 11:21:59,396",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0088_01_000193 transitioned from LOCALIZED to RUNNING\n"
    },
    {
        "timestamp": "2015-03-23 11:21:59,402",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " launchContainer: [bash, /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0088/container_1427088391284_0088_01_000193/default_container_executor.sh]\n"
    },
    {
        "timestamp": "2015-03-23 11:21:59,658",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Starting resource-monitoring for container_1427088391284_0088_01_000193\n"
    },
    {
        "timestamp": "2015-03-23 11:21:59,680",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7276 for container-id container_1427088391284_0088_01_000193: 14.7 MB of 4 GB physical memory used; 3.5 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:22:02,761",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7276 for container-id container_1427088391284_0088_01_000193: 48.6 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:22:05,787",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7276 for container-id container_1427088391284_0088_01_000193: 64.9 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:22:08,803",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7276 for container-id container_1427088391284_0088_01_000193: 80.2 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:22:11,830",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7276 for container-id container_1427088391284_0088_01_000193: 93.4 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:22:12,436",
        "type": "INFO",
        "app": "SecurityLogger.org.apache.hadoop.ipc.Server",
        "message": " Auth successful for appattempt_1427088391284_0088_000001 (auth:SIMPLE)\n"
    },
    {
        "timestamp": "2015-03-23 11:22:12,439",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Stopping container with container Id: container_1427088391284_0088_01_000193\n"
    },
    {
        "timestamp": "2015-03-23 11:22:12,439",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tIP=172.31.17.108\tOPERATION=Stop Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0088\tCONTAINERID=container_1427088391284_0088_01_000193\n"
    },
    {
        "timestamp": "2015-03-23 11:22:12,439",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0088_01_000193 transitioned from RUNNING to KILLING\n"
    },
    {
        "timestamp": "2015-03-23 11:22:12,439",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch",
        "message": " Cleaning up container container_1427088391284_0088_01_000193\n"
    },
    {
        "timestamp": "2015-03-23 11:22:12,501",
        "type": "WARN",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Exit code from container container_1427088391284_0088_01_000193 is : 143\n"
    },
    {
        "timestamp": "2015-03-23 11:22:12,631",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0088_01_000193 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL\n"
    },
    {
        "timestamp": "2015-03-23 11:22:12,632",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Deleting absolute path : /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0088/container_1427088391284_0088_01_000193\n"
    },
    {
        "timestamp": "2015-03-23 11:22:12,634",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tOPERATION=Container Finished - Killed\tTARGET=ContainerImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0088\tCONTAINERID=container_1427088391284_0088_01_000193\n"
    },
    {
        "timestamp": "2015-03-23 11:22:12,634",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0088_01_000193 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE\n"
    },
    {
        "timestamp": "2015-03-23 11:22:12,634",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Removing container_1427088391284_0088_01_000193 from application application_1427088391284_0088\n"
    },
    {
        "timestamp": "2015-03-23 11:22:12,634",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event CONTAINER_STOP for appId application_1427088391284_0088\n"
    },
    {
        "timestamp": "2015-03-23 11:22:14,830",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Stopping resource-monitoring for container_1427088391284_0088_01_000193\n"
    },
    {
        "timestamp": "2015-03-23 11:22:15,465",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl",
        "message": " Removed completed containers from NM context: [container_1427088391284_0088_01_000193]\n"
    },
    {
        "timestamp": "2015-03-23 11:24:18,797",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0088 transitioned from RUNNING to APPLICATION_RESOURCES_CLEANINGUP\n"
    },
    {
        "timestamp": "2015-03-23 11:24:18,798",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event APPLICATION_STOP for appId application_1427088391284_0088\n"
    },
    {
        "timestamp": "2015-03-23 11:24:18,798",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0088 transitioned from APPLICATION_RESOURCES_CLEANINGUP to FINISHED\n"
    },
    {
        "timestamp": "2015-03-23 11:24:18,798",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler",
        "message": " Scheduling Log Deletion for application: application_1427088391284_0088, with delay of 172800 seconds\n"
    },
    {
        "timestamp": "2015-03-23 11:24:18,799",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Deleting absolute path : /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0088\n"
    },
    {
        "timestamp": "2015-03-23 11:24:44,802",
        "type": "INFO",
        "app": "SecurityLogger.org.apache.hadoop.ipc.Server",
        "message": " Auth successful for appattempt_1427088391284_0089_000001 (auth:SIMPLE)\n"
    },
    {
        "timestamp": "2015-03-23 11:24:44,846",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Start request for container_1427088391284_0089_01_000041 by user ubuntu\n"
    },
    {
        "timestamp": "2015-03-23 11:24:44,846",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Creating a new application reference for app application_1427088391284_0089\n"
    },
    {
        "timestamp": "2015-03-23 11:24:44,847",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0089 transitioned from NEW to INITING\n"
    },
    {
        "timestamp": "2015-03-23 11:24:44,847",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0089 transitioned from INITING to RUNNING\n"
    },
    {
        "timestamp": "2015-03-23 11:24:44,847",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Adding container_1427088391284_0089_01_000041 to application application_1427088391284_0089\n"
    },
    {
        "timestamp": "2015-03-23 11:24:44,848",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0089_01_000041 transitioned from NEW to LOCALIZING\n"
    },
    {
        "timestamp": "2015-03-23 11:24:44,848",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event CONTAINER_INIT for appId application_1427088391284_0089\n"
    },
    {
        "timestamp": "2015-03-23 11:24:44,848",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event APPLICATION_INIT for appId application_1427088391284_0089\n"
    },
    {
        "timestamp": "2015-03-23 11:24:44,848",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got APPLICATION_INIT for service mapreduce_shuffle\n"
    },
    {
        "timestamp": "2015-03-23 11:24:44,848",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Added token for job_1427088391284_0089\n"
    },
    {
        "timestamp": "2015-03-23 11:24:44,848",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/a68a0c47-3daa-4d82-93e5-e41babe027f5/hive_2015-03-23_11-20-05_140_8861444585183040507-1/-mr-10007/475310f7-d508-4d2e-992e-afcbf5468273/map.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 11:24:44,848",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/a68a0c47-3daa-4d82-93e5-e41babe027f5/hive_2015-03-23_11-20-05_140_8861444585183040507-1/-mr-10007/475310f7-d508-4d2e-992e-afcbf5468273/reduce.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 11:24:44,848",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0089/job.jar transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 11:24:44,849",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0089/job.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 11:24:44,849",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService",
        "message": " Created localizer for container_1427088391284_0089_01_000041\n"
    },
    {
        "timestamp": "2015-03-23 11:24:44,849",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tIP=172.31.17.120\tOPERATION=Start Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0089\tCONTAINERID=container_1427088391284_0089_01_000041\n"
    },
    {
        "timestamp": "2015-03-23 11:24:44,853",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService",
        "message": " Writing credentials to the nmPrivate file /tmp/hadoop-ubuntu/nm-local-dir/nmPrivate/container_1427088391284_0089_01_000041.tokens. Credentials list: \n"
    },
    {
        "timestamp": "2015-03-23 11:24:44,874",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Initializing user ubuntu\n"
    },
    {
        "timestamp": "2015-03-23 11:24:44,877",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Copying from /tmp/hadoop-ubuntu/nm-local-dir/nmPrivate/container_1427088391284_0089_01_000041.tokens to /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0089/container_1427088391284_0089_01_000041.tokens\n"
    },
    {
        "timestamp": "2015-03-23 11:24:44,878",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Localizer CWD set to /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0089 = file:/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0089\n"
    },
    {
        "timestamp": "2015-03-23 11:24:45,060",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/a68a0c47-3daa-4d82-93e5-e41babe027f5/hive_2015-03-23_11-20-05_140_8861444585183040507-1/-mr-10007/475310f7-d508-4d2e-992e-afcbf5468273/map.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/filecache/80/map.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 11:24:45,114",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/a68a0c47-3daa-4d82-93e5-e41babe027f5/hive_2015-03-23_11-20-05_140_8861444585183040507-1/-mr-10007/475310f7-d508-4d2e-992e-afcbf5468273/reduce.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/filecache/81/reduce.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 11:24:45,594",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0089/job.jar(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0089/filecache/10/job.jar) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 11:24:45,649",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0089/job.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0089/filecache/11/job.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 11:24:45,650",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0089_01_000041 transitioned from LOCALIZING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 11:24:45,703",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0089_01_000041 transitioned from LOCALIZED to RUNNING\n"
    },
    {
        "timestamp": "2015-03-23 11:24:45,709",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " launchContainer: [bash, /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0089/container_1427088391284_0089_01_000041/default_container_executor.sh]\n"
    },
    {
        "timestamp": "2015-03-23 11:24:47,850",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Starting resource-monitoring for container_1427088391284_0089_01_000041\n"
    },
    {
        "timestamp": "2015-03-23 11:24:47,948",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7360 for container-id container_1427088391284_0089_01_000041: 48.8 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:24:50,985",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7360 for container-id container_1427088391284_0089_01_000041: 57.6 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:24:54,021",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7360 for container-id container_1427088391284_0089_01_000041: 77.8 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:24:57,063",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7360 for container-id container_1427088391284_0089_01_000041: 84.9 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:25:00,078",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7360 for container-id container_1427088391284_0089_01_000041: 94.9 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:25:03,103",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7360 for container-id container_1427088391284_0089_01_000041: 100.6 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:25:06,145",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7360 for container-id container_1427088391284_0089_01_000041: 202.9 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:25:09,160",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7360 for container-id container_1427088391284_0089_01_000041: 203.6 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:25:12,081",
        "type": "INFO",
        "app": "SecurityLogger.org.apache.hadoop.ipc.Server",
        "message": " Auth successful for appattempt_1427088391284_0089_000001 (auth:SIMPLE)\n"
    },
    {
        "timestamp": "2015-03-23 11:25:12,089",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Stopping container with container Id: container_1427088391284_0089_01_000041\n"
    },
    {
        "timestamp": "2015-03-23 11:25:12,089",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tIP=172.31.17.120\tOPERATION=Stop Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0089\tCONTAINERID=container_1427088391284_0089_01_000041\n"
    },
    {
        "timestamp": "2015-03-23 11:25:12,089",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0089_01_000041 transitioned from RUNNING to KILLING\n"
    },
    {
        "timestamp": "2015-03-23 11:25:12,089",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch",
        "message": " Cleaning up container container_1427088391284_0089_01_000041\n"
    },
    {
        "timestamp": "2015-03-23 11:25:12,129",
        "type": "WARN",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Exit code from container container_1427088391284_0089_01_000041 is : 143\n"
    },
    {
        "timestamp": "2015-03-23 11:25:12,176",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7360 for container-id container_1427088391284_0089_01_000041: 0B of 4 GB physical memory used; 0B of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:25:12,182",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0089_01_000041 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL\n"
    },
    {
        "timestamp": "2015-03-23 11:25:12,183",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Deleting absolute path : /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0089/container_1427088391284_0089_01_000041\n"
    },
    {
        "timestamp": "2015-03-23 11:25:12,185",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tOPERATION=Container Finished - Killed\tTARGET=ContainerImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0089\tCONTAINERID=container_1427088391284_0089_01_000041\n"
    },
    {
        "timestamp": "2015-03-23 11:25:12,185",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0089_01_000041 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE\n"
    },
    {
        "timestamp": "2015-03-23 11:25:12,185",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Removing container_1427088391284_0089_01_000041 from application application_1427088391284_0089\n"
    },
    {
        "timestamp": "2015-03-23 11:25:12,185",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event CONTAINER_STOP for appId application_1427088391284_0089\n"
    },
    {
        "timestamp": "2015-03-23 11:25:15,177",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Stopping resource-monitoring for container_1427088391284_0089_01_000041\n"
    },
    {
        "timestamp": "2015-03-23 11:25:16,100",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl",
        "message": " Removed completed containers from NM context: [container_1427088391284_0089_01_000041]\n"
    },
    {
        "timestamp": "2015-03-23 11:25:32,456",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:25:32,830",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:25:33,148",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:25:33,298",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:25:33,565",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:25:33,571",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:25:33,587",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:25:33,627",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:25:33,963",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:25:33,974",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:25:33,988",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:25:34,029",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:25:34,036",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:25:34,037",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:25:34,070",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:25:34,094",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:25:34,143",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:25:34,226",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:25:34,325",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:25:34,327",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:25:34,380",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:25:34,422",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:25:34,475",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:25:34,532",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:25:34,539",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:25:34,541",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:25:34,546",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:25:34,548",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:25:34,602",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:25:34,623",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:25:34,634",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:25:34,759",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:25:34,769",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:25:34,845",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:25:34,860",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:25:34,894",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:25:34,982",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:25:35,008",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:25:35,031",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:25:35,034",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:25:35,125",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:25:35,241",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:25:35,272",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:25:35,404",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:25:35,734",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:25:35,759",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:25:36,295",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:25:36,339",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:26:06,286",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0089 transitioned from RUNNING to APPLICATION_RESOURCES_CLEANINGUP\n"
    },
    {
        "timestamp": "2015-03-23 11:26:06,287",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event APPLICATION_STOP for appId application_1427088391284_0089\n"
    },
    {
        "timestamp": "2015-03-23 11:26:06,287",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0089 transitioned from APPLICATION_RESOURCES_CLEANINGUP to FINISHED\n"
    },
    {
        "timestamp": "2015-03-23 11:26:06,287",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler",
        "message": " Scheduling Log Deletion for application: application_1427088391284_0089, with delay of 172800 seconds\n"
    },
    {
        "timestamp": "2015-03-23 11:26:06,287",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Deleting absolute path : /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0089\n"
    },
    {
        "timestamp": "2015-03-23 11:30:23,906",
        "type": "INFO",
        "app": "SecurityLogger.org.apache.hadoop.ipc.Server",
        "message": " Auth successful for appattempt_1427088391284_0091_000001 (auth:SIMPLE)\n"
    },
    {
        "timestamp": "2015-03-23 11:30:24,036",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Start request for container_1427088391284_0091_01_000087 by user ubuntu\n"
    },
    {
        "timestamp": "2015-03-23 11:30:24,036",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Creating a new application reference for app application_1427088391284_0091\n"
    },
    {
        "timestamp": "2015-03-23 11:30:24,037",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0091 transitioned from NEW to INITING\n"
    },
    {
        "timestamp": "2015-03-23 11:30:24,037",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0091 transitioned from INITING to RUNNING\n"
    },
    {
        "timestamp": "2015-03-23 11:30:24,037",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Adding container_1427088391284_0091_01_000087 to application application_1427088391284_0091\n"
    },
    {
        "timestamp": "2015-03-23 11:30:24,037",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0091_01_000087 transitioned from NEW to LOCALIZING\n"
    },
    {
        "timestamp": "2015-03-23 11:30:24,037",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event CONTAINER_INIT for appId application_1427088391284_0091\n"
    },
    {
        "timestamp": "2015-03-23 11:30:24,038",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event APPLICATION_INIT for appId application_1427088391284_0091\n"
    },
    {
        "timestamp": "2015-03-23 11:30:24,038",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got APPLICATION_INIT for service mapreduce_shuffle\n"
    },
    {
        "timestamp": "2015-03-23 11:30:24,038",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Added token for job_1427088391284_0091\n"
    },
    {
        "timestamp": "2015-03-23 11:30:24,038",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/92ff3bd3-150b-4f01-8653-9f155d808f50/hive_2015-03-23_11-28-48_063_8103948983751214248-1/-mr-10003/5f02c0f8-3714-4f06-91af-61ceab0fc0be/map.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 11:30:24,038",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/92ff3bd3-150b-4f01-8653-9f155d808f50/hive_2015-03-23_11-28-48_063_8103948983751214248-1/-mr-10003/5f02c0f8-3714-4f06-91af-61ceab0fc0be/reduce.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 11:30:24,038",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0091/job.jar transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 11:30:24,038",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0091/job.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 11:30:24,039",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tIP=172.31.17.120\tOPERATION=Start Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0091\tCONTAINERID=container_1427088391284_0091_01_000087\n"
    },
    {
        "timestamp": "2015-03-23 11:30:24,039",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService",
        "message": " Created localizer for container_1427088391284_0091_01_000087\n"
    },
    {
        "timestamp": "2015-03-23 11:30:24,043",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService",
        "message": " Writing credentials to the nmPrivate file /tmp/hadoop-ubuntu/nm-local-dir/nmPrivate/container_1427088391284_0091_01_000087.tokens. Credentials list: \n"
    },
    {
        "timestamp": "2015-03-23 11:30:24,064",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Initializing user ubuntu\n"
    },
    {
        "timestamp": "2015-03-23 11:30:24,067",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Copying from /tmp/hadoop-ubuntu/nm-local-dir/nmPrivate/container_1427088391284_0091_01_000087.tokens to /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0091/container_1427088391284_0091_01_000087.tokens\n"
    },
    {
        "timestamp": "2015-03-23 11:30:24,067",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Localizer CWD set to /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0091 = file:/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0091\n"
    },
    {
        "timestamp": "2015-03-23 11:30:24,604",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/92ff3bd3-150b-4f01-8653-9f155d808f50/hive_2015-03-23_11-28-48_063_8103948983751214248-1/-mr-10003/5f02c0f8-3714-4f06-91af-61ceab0fc0be/map.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/filecache/82/map.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 11:30:25,135",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/92ff3bd3-150b-4f01-8653-9f155d808f50/hive_2015-03-23_11-28-48_063_8103948983751214248-1/-mr-10003/5f02c0f8-3714-4f06-91af-61ceab0fc0be/reduce.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/filecache/83/reduce.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 11:30:25,750",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0091/job.jar(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0091/filecache/10/job.jar) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 11:30:27,482",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0091/job.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0091/filecache/11/job.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 11:30:27,483",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0091_01_000087 transitioned from LOCALIZING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 11:30:27,536",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0091_01_000087 transitioned from LOCALIZED to RUNNING\n"
    },
    {
        "timestamp": "2015-03-23 11:30:27,543",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " launchContainer: [bash, /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0091/container_1427088391284_0091_01_000087/default_container_executor.sh]\n"
    },
    {
        "timestamp": "2015-03-23 11:30:30,193",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Starting resource-monitoring for container_1427088391284_0091_01_000087\n"
    },
    {
        "timestamp": "2015-03-23 11:30:30,275",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7455 for container-id container_1427088391284_0091_01_000087: 48.3 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:30:33,305",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7455 for container-id container_1427088391284_0091_01_000087: 59.8 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:30:36,342",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7455 for container-id container_1427088391284_0091_01_000087: 77.5 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:30:39,429",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7455 for container-id container_1427088391284_0091_01_000087: 84.4 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:30:42,442",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7455 for container-id container_1427088391284_0091_01_000087: 99.7 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:30:45,451",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7455 for container-id container_1427088391284_0091_01_000087: 116.1 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:30:48,463",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7455 for container-id container_1427088391284_0091_01_000087: 115.7 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:30:51,472",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7455 for container-id container_1427088391284_0091_01_000087: 115.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:30:54,482",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7455 for container-id container_1427088391284_0091_01_000087: 114.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:30:57,494",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7455 for container-id container_1427088391284_0091_01_000087: 114.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:31:00,503",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7455 for container-id container_1427088391284_0091_01_000087: 114.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:31:03,511",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7455 for container-id container_1427088391284_0091_01_000087: 114.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:31:06,520",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7455 for container-id container_1427088391284_0091_01_000087: 119.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:31:09,529",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7455 for container-id container_1427088391284_0091_01_000087: 119.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:31:12,537",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7455 for container-id container_1427088391284_0091_01_000087: 119.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:31:15,546",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7455 for container-id container_1427088391284_0091_01_000087: 120.2 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:31:18,558",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7455 for container-id container_1427088391284_0091_01_000087: 124.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:31:21,567",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7455 for container-id container_1427088391284_0091_01_000087: 124.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:31:24,576",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7455 for container-id container_1427088391284_0091_01_000087: 124.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:31:27,588",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7455 for container-id container_1427088391284_0091_01_000087: 127.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:31:30,599",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7455 for container-id container_1427088391284_0091_01_000087: 128.1 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:31:33,608",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7455 for container-id container_1427088391284_0091_01_000087: 128.1 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:31:36,620",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7455 for container-id container_1427088391284_0091_01_000087: 128.1 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:31:39,629",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7455 for container-id container_1427088391284_0091_01_000087: 128.1 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:31:42,638",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7455 for container-id container_1427088391284_0091_01_000087: 128.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:31:45,646",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7455 for container-id container_1427088391284_0091_01_000087: 130.7 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:31:48,658",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7455 for container-id container_1427088391284_0091_01_000087: 134.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:31:51,667",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7455 for container-id container_1427088391284_0091_01_000087: 138.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:31:54,704",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7455 for container-id container_1427088391284_0091_01_000087: 138.7 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:31:57,748",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7455 for container-id container_1427088391284_0091_01_000087: 139.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:32:00,829",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7455 for container-id container_1427088391284_0091_01_000087: 154.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:32:03,867",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7455 for container-id container_1427088391284_0091_01_000087: 160.5 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:32:06,910",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7455 for container-id container_1427088391284_0091_01_000087: 173.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:32:09,993",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7455 for container-id container_1427088391284_0091_01_000087: 169.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:32:13,040",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7455 for container-id container_1427088391284_0091_01_000087: 169.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:32:16,086",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7455 for container-id container_1427088391284_0091_01_000087: 163.7 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:32:19,102",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7455 for container-id container_1427088391284_0091_01_000087: 163.7 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:32:22,127",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7455 for container-id container_1427088391284_0091_01_000087: 163.7 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:32:25,175",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7455 for container-id container_1427088391284_0091_01_000087: 163.7 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:32:28,232",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7455 for container-id container_1427088391284_0091_01_000087: 163.7 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:32:31,285",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7455 for container-id container_1427088391284_0091_01_000087: 163.7 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:32:34,296",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7455 for container-id container_1427088391284_0091_01_000087: 163.7 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:32:37,345",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7455 for container-id container_1427088391284_0091_01_000087: 163.7 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:32:40,387",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7455 for container-id container_1427088391284_0091_01_000087: 163.7 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:32:43,408",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7455 for container-id container_1427088391284_0091_01_000087: 163.7 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:32:46,431",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7455 for container-id container_1427088391284_0091_01_000087: 163.7 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:32:49,452",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7455 for container-id container_1427088391284_0091_01_000087: 163.7 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:32:52,493",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7455 for container-id container_1427088391284_0091_01_000087: 163.7 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:32:55,522",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7455 for container-id container_1427088391284_0091_01_000087: 163.7 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:32:58,476",
        "type": "INFO",
        "app": "SecurityLogger.org.apache.hadoop.ipc.Server",
        "message": " Auth successful for appattempt_1427088391284_0091_000001 (auth:SIMPLE)\n"
    },
    {
        "timestamp": "2015-03-23 11:32:58,478",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Stopping container with container Id: container_1427088391284_0091_01_000087\n"
    },
    {
        "timestamp": "2015-03-23 11:32:58,478",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tIP=172.31.17.120\tOPERATION=Stop Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0091\tCONTAINERID=container_1427088391284_0091_01_000087\n"
    },
    {
        "timestamp": "2015-03-23 11:32:58,479",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0091_01_000087 transitioned from RUNNING to KILLING\n"
    },
    {
        "timestamp": "2015-03-23 11:32:58,479",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch",
        "message": " Cleaning up container container_1427088391284_0091_01_000087\n"
    },
    {
        "timestamp": "2015-03-23 11:32:58,543",
        "type": "WARN",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Exit code from container container_1427088391284_0091_01_000087 is : 143\n"
    },
    {
        "timestamp": "2015-03-23 11:32:58,547",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7455 for container-id container_1427088391284_0091_01_000087: 0B of 4 GB physical memory used; 0B of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:32:58,599",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0091_01_000087 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL\n"
    },
    {
        "timestamp": "2015-03-23 11:32:58,600",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Deleting absolute path : /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0091/container_1427088391284_0091_01_000087\n"
    },
    {
        "timestamp": "2015-03-23 11:32:58,602",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tOPERATION=Container Finished - Killed\tTARGET=ContainerImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0091\tCONTAINERID=container_1427088391284_0091_01_000087\n"
    },
    {
        "timestamp": "2015-03-23 11:32:58,602",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0091_01_000087 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE\n"
    },
    {
        "timestamp": "2015-03-23 11:32:58,603",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Removing container_1427088391284_0091_01_000087 from application application_1427088391284_0091\n"
    },
    {
        "timestamp": "2015-03-23 11:32:58,603",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event CONTAINER_STOP for appId application_1427088391284_0091\n"
    },
    {
        "timestamp": "2015-03-23 11:33:01,527",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl",
        "message": " Removed completed containers from NM context: [container_1427088391284_0091_01_000087]\n"
    },
    {
        "timestamp": "2015-03-23 11:33:01,547",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Stopping resource-monitoring for container_1427088391284_0091_01_000087\n"
    },
    {
        "timestamp": "2015-03-23 11:33:29,870",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0091 transitioned from RUNNING to APPLICATION_RESOURCES_CLEANINGUP\n"
    },
    {
        "timestamp": "2015-03-23 11:33:29,871",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event APPLICATION_STOP for appId application_1427088391284_0091\n"
    },
    {
        "timestamp": "2015-03-23 11:33:29,871",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0091 transitioned from APPLICATION_RESOURCES_CLEANINGUP to FINISHED\n"
    },
    {
        "timestamp": "2015-03-23 11:33:29,871",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler",
        "message": " Scheduling Log Deletion for application: application_1427088391284_0091, with delay of 172800 seconds\n"
    },
    {
        "timestamp": "2015-03-23 11:33:29,871",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Deleting absolute path : /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0091\n"
    },
    {
        "timestamp": "2015-03-23 11:39:11,970",
        "type": "INFO",
        "app": "SecurityLogger.org.apache.hadoop.ipc.Server",
        "message": " Auth successful for appattempt_1427088391284_0093_000001 (auth:SIMPLE)\n"
    },
    {
        "timestamp": "2015-03-23 11:39:12,474",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Start request for container_1427088391284_0093_01_000030 by user ubuntu\n"
    },
    {
        "timestamp": "2015-03-23 11:39:12,474",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Creating a new application reference for app application_1427088391284_0093\n"
    },
    {
        "timestamp": "2015-03-23 11:39:12,475",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0093 transitioned from NEW to INITING\n"
    },
    {
        "timestamp": "2015-03-23 11:39:12,475",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0093 transitioned from INITING to RUNNING\n"
    },
    {
        "timestamp": "2015-03-23 11:39:12,475",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Adding container_1427088391284_0093_01_000030 to application application_1427088391284_0093\n"
    },
    {
        "timestamp": "2015-03-23 11:39:12,476",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0093_01_000030 transitioned from NEW to LOCALIZING\n"
    },
    {
        "timestamp": "2015-03-23 11:39:12,476",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event CONTAINER_INIT for appId application_1427088391284_0093\n"
    },
    {
        "timestamp": "2015-03-23 11:39:12,476",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event APPLICATION_INIT for appId application_1427088391284_0093\n"
    },
    {
        "timestamp": "2015-03-23 11:39:12,476",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got APPLICATION_INIT for service mapreduce_shuffle\n"
    },
    {
        "timestamp": "2015-03-23 11:39:12,476",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Added token for job_1427088391284_0093\n"
    },
    {
        "timestamp": "2015-03-23 11:39:12,477",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/03828081-49c0-4f42-b5ee-09aff849c5ab/hive_2015-03-23_11-34-24_966_6916940875845296716-1/-mr-10007/404245b3-1121-45b8-94eb-3a1f0e97e697/map.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 11:39:12,477",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/03828081-49c0-4f42-b5ee-09aff849c5ab/hive_2015-03-23_11-34-24_966_6916940875845296716-1/-mr-10007/404245b3-1121-45b8-94eb-3a1f0e97e697/reduce.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 11:39:12,477",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0093/job.jar transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 11:39:12,477",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0093/job.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 11:39:12,477",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService",
        "message": " Created localizer for container_1427088391284_0093_01_000030\n"
    },
    {
        "timestamp": "2015-03-23 11:39:12,477",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tIP=172.31.17.135\tOPERATION=Start Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0093\tCONTAINERID=container_1427088391284_0093_01_000030\n"
    },
    {
        "timestamp": "2015-03-23 11:39:12,482",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService",
        "message": " Writing credentials to the nmPrivate file /tmp/hadoop-ubuntu/nm-local-dir/nmPrivate/container_1427088391284_0093_01_000030.tokens. Credentials list: \n"
    },
    {
        "timestamp": "2015-03-23 11:39:12,503",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Initializing user ubuntu\n"
    },
    {
        "timestamp": "2015-03-23 11:39:12,530",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Copying from /tmp/hadoop-ubuntu/nm-local-dir/nmPrivate/container_1427088391284_0093_01_000030.tokens to /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0093/container_1427088391284_0093_01_000030.tokens\n"
    },
    {
        "timestamp": "2015-03-23 11:39:12,530",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Localizer CWD set to /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0093 = file:/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0093\n"
    },
    {
        "timestamp": "2015-03-23 11:39:12,741",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/03828081-49c0-4f42-b5ee-09aff849c5ab/hive_2015-03-23_11-34-24_966_6916940875845296716-1/-mr-10007/404245b3-1121-45b8-94eb-3a1f0e97e697/map.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/filecache/84/map.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 11:39:12,787",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/03828081-49c0-4f42-b5ee-09aff849c5ab/hive_2015-03-23_11-34-24_966_6916940875845296716-1/-mr-10007/404245b3-1121-45b8-94eb-3a1f0e97e697/reduce.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/filecache/85/reduce.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 11:39:13,289",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0093/job.jar(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0093/filecache/10/job.jar) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 11:39:13,327",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0093/job.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0093/filecache/11/job.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 11:39:13,330",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0093_01_000030 transitioned from LOCALIZING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 11:39:13,413",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0093_01_000030 transitioned from LOCALIZED to RUNNING\n"
    },
    {
        "timestamp": "2015-03-23 11:39:13,420",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " launchContainer: [bash, /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0093/container_1427088391284_0093_01_000030/default_container_executor.sh]\n"
    },
    {
        "timestamp": "2015-03-23 11:39:13,562",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Starting resource-monitoring for container_1427088391284_0093_01_000030\n"
    },
    {
        "timestamp": "2015-03-23 11:39:13,646",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7592 for container-id container_1427088391284_0093_01_000030: 13.6 MB of 4 GB physical memory used; 3.5 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:39:16,681",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7592 for container-id container_1427088391284_0093_01_000030: 50.1 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:39:19,743",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7592 for container-id container_1427088391284_0093_01_000030: 58.5 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:39:22,871",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7592 for container-id container_1427088391284_0093_01_000030: 77.8 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:39:25,901",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7592 for container-id container_1427088391284_0093_01_000030: 89.7 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:39:28,936",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7592 for container-id container_1427088391284_0093_01_000030: 95.1 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:39:31,951",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7592 for container-id container_1427088391284_0093_01_000030: 104.7 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:39:34,964",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7592 for container-id container_1427088391284_0093_01_000030: 206.5 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:39:37,998",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7592 for container-id container_1427088391284_0093_01_000030: 207.2 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:39:40,785",
        "type": "INFO",
        "app": "SecurityLogger.org.apache.hadoop.ipc.Server",
        "message": " Auth successful for appattempt_1427088391284_0093_000001 (auth:SIMPLE)\n"
    },
    {
        "timestamp": "2015-03-23 11:39:41,006",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7592 for container-id container_1427088391284_0093_01_000030: 207.9 MB of 4 GB physical memory used; 3.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:39:41,057",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Stopping container with container Id: container_1427088391284_0093_01_000030\n"
    },
    {
        "timestamp": "2015-03-23 11:39:41,057",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tIP=172.31.17.135\tOPERATION=Stop Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0093\tCONTAINERID=container_1427088391284_0093_01_000030\n"
    },
    {
        "timestamp": "2015-03-23 11:39:41,058",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0093_01_000030 transitioned from RUNNING to KILLING\n"
    },
    {
        "timestamp": "2015-03-23 11:39:41,058",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch",
        "message": " Cleaning up container container_1427088391284_0093_01_000030\n"
    },
    {
        "timestamp": "2015-03-23 11:39:41,085",
        "type": "WARN",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Exit code from container container_1427088391284_0093_01_000030 is : 143\n"
    },
    {
        "timestamp": "2015-03-23 11:39:41,129",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0093_01_000030 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL\n"
    },
    {
        "timestamp": "2015-03-23 11:39:41,130",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Deleting absolute path : /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0093/container_1427088391284_0093_01_000030\n"
    },
    {
        "timestamp": "2015-03-23 11:39:41,132",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tOPERATION=Container Finished - Killed\tTARGET=ContainerImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0093\tCONTAINERID=container_1427088391284_0093_01_000030\n"
    },
    {
        "timestamp": "2015-03-23 11:39:41,132",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0093_01_000030 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE\n"
    },
    {
        "timestamp": "2015-03-23 11:39:41,132",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Removing container_1427088391284_0093_01_000030 from application application_1427088391284_0093\n"
    },
    {
        "timestamp": "2015-03-23 11:39:41,132",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event CONTAINER_STOP for appId application_1427088391284_0093\n"
    },
    {
        "timestamp": "2015-03-23 11:39:44,007",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Stopping resource-monitoring for container_1427088391284_0093_01_000030\n"
    },
    {
        "timestamp": "2015-03-23 11:39:44,334",
        "type": "INFO",
        "app": "SecurityLogger.org.apache.hadoop.ipc.Server",
        "message": " Auth successful for appattempt_1427088391284_0093_000001 (auth:SIMPLE)\n"
    },
    {
        "timestamp": "2015-03-23 11:39:45,062",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Start request for container_1427088391284_0093_01_000046 by user ubuntu\n"
    },
    {
        "timestamp": "2015-03-23 11:39:45,062",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Adding container_1427088391284_0093_01_000046 to application application_1427088391284_0093\n"
    },
    {
        "timestamp": "2015-03-23 11:39:45,063",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0093_01_000046 transitioned from NEW to LOCALIZING\n"
    },
    {
        "timestamp": "2015-03-23 11:39:45,063",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event CONTAINER_INIT for appId application_1427088391284_0093\n"
    },
    {
        "timestamp": "2015-03-23 11:39:45,063",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event APPLICATION_INIT for appId application_1427088391284_0093\n"
    },
    {
        "timestamp": "2015-03-23 11:39:45,063",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got APPLICATION_INIT for service mapreduce_shuffle\n"
    },
    {
        "timestamp": "2015-03-23 11:39:45,063",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Added token for job_1427088391284_0093\n"
    },
    {
        "timestamp": "2015-03-23 11:39:45,064",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0093_01_000046 transitioned from LOCALIZING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 11:39:45,066",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tIP=172.31.17.135\tOPERATION=Start Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0093\tCONTAINERID=container_1427088391284_0093_01_000046\n"
    },
    {
        "timestamp": "2015-03-23 11:39:45,092",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0093_01_000046 transitioned from LOCALIZED to RUNNING\n"
    },
    {
        "timestamp": "2015-03-23 11:39:45,124",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " launchContainer: [bash, /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0093/container_1427088391284_0093_01_000046/default_container_executor.sh]\n"
    },
    {
        "timestamp": "2015-03-23 11:39:45,134",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl",
        "message": " Removed completed containers from NM context: [container_1427088391284_0093_01_000030]\n"
    },
    {
        "timestamp": "2015-03-23 11:39:47,007",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Starting resource-monitoring for container_1427088391284_0093_01_000046\n"
    },
    {
        "timestamp": "2015-03-23 11:39:47,096",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7640 for container-id container_1427088391284_0093_01_000046: 44.9 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:39:50,128",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7640 for container-id container_1427088391284_0093_01_000046: 61.2 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:39:53,142",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7640 for container-id container_1427088391284_0093_01_000046: 77.9 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:39:56,164",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7640 for container-id container_1427088391284_0093_01_000046: 86.0 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:39:59,180",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7640 for container-id container_1427088391284_0093_01_000046: 92.5 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:40:00,135",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:40:00,179",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:40:00,611",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:40:00,804",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:40:00,867",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:40:01,440",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:40:01,484",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:40:01,644",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:40:01,691",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:40:01,807",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:40:01,836",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:40:01,844",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:40:01,967",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:40:01,969",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:40:02,053",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:40:02,149",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:40:02,268",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:40:02,276",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7640 for container-id container_1427088391284_0093_01_000046: 102.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:40:02,289",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:40:02,364",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:40:02,366",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:40:02,368",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:40:02,374",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:40:02,434",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:40:02,488",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:40:02,543",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:40:02,625",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:40:02,631",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:40:02,824",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:40:02,990",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:40:03,045",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:40:03,078",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:40:03,082",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:40:03,150",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:40:03,255",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:40:03,258",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:40:03,406",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:40:03,452",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:40:03,501",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:40:03,724",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:40:03,782",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:40:03,784",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:40:03,848",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:40:04,107",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:40:04,296",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:40:04,523",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:40:04,661",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:40:04,762",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:40:04,871",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Setting connection close header...\n"
    },
    {
        "timestamp": "2015-03-23 11:40:05,285",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7640 for container-id container_1427088391284_0093_01_000046: 102.1 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:40:08,294",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7640 for container-id container_1427088391284_0093_01_000046: 103.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:40:11,306",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7640 for container-id container_1427088391284_0093_01_000046: 103.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:40:14,326",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7640 for container-id container_1427088391284_0093_01_000046: 111.1 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:40:17,359",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7640 for container-id container_1427088391284_0093_01_000046: 114.1 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:40:20,396",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7640 for container-id container_1427088391284_0093_01_000046: 126 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:40:22,094",
        "type": "INFO",
        "app": "SecurityLogger.org.apache.hadoop.ipc.Server",
        "message": " Auth successful for appattempt_1427088391284_0093_000001 (auth:SIMPLE)\n"
    },
    {
        "timestamp": "2015-03-23 11:40:22,130",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch",
        "message": " Container container_1427088391284_0093_01_000046 succeeded \n"
    },
    {
        "timestamp": "2015-03-23 11:40:22,131",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0093_01_000046 transitioned from RUNNING to EXITED_WITH_SUCCESS\n"
    },
    {
        "timestamp": "2015-03-23 11:40:22,131",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch",
        "message": " Cleaning up container container_1427088391284_0093_01_000046\n"
    },
    {
        "timestamp": "2015-03-23 11:40:22,179",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Stopping container with container Id: container_1427088391284_0093_01_000046\n"
    },
    {
        "timestamp": "2015-03-23 11:40:22,252",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tIP=172.31.17.135\tOPERATION=Stop Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0093\tCONTAINERID=container_1427088391284_0093_01_000046\n"
    },
    {
        "timestamp": "2015-03-23 11:40:22,306",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Deleting absolute path : /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0093/container_1427088391284_0093_01_000046\n"
    },
    {
        "timestamp": "2015-03-23 11:40:22,308",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tOPERATION=Container Finished - Succeeded\tTARGET=ContainerImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0093\tCONTAINERID=container_1427088391284_0093_01_000046\n"
    },
    {
        "timestamp": "2015-03-23 11:40:22,308",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0093_01_000046 transitioned from EXITED_WITH_SUCCESS to DONE\n"
    },
    {
        "timestamp": "2015-03-23 11:40:22,308",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Removing container_1427088391284_0093_01_000046 from application application_1427088391284_0093\n"
    },
    {
        "timestamp": "2015-03-23 11:40:22,309",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event CONTAINER_STOP for appId application_1427088391284_0093\n"
    },
    {
        "timestamp": "2015-03-23 11:40:23,396",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Stopping resource-monitoring for container_1427088391284_0093_01_000046\n"
    },
    {
        "timestamp": "2015-03-23 11:40:31,338",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl",
        "message": " Removed completed containers from NM context: [container_1427088391284_0093_01_000046]\n"
    },
    {
        "timestamp": "2015-03-23 11:40:31,339",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0093 transitioned from RUNNING to APPLICATION_RESOURCES_CLEANINGUP\n"
    },
    {
        "timestamp": "2015-03-23 11:40:31,339",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event APPLICATION_STOP for appId application_1427088391284_0093\n"
    },
    {
        "timestamp": "2015-03-23 11:40:31,340",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0093 transitioned from APPLICATION_RESOURCES_CLEANINGUP to FINISHED\n"
    },
    {
        "timestamp": "2015-03-23 11:40:31,340",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler",
        "message": " Scheduling Log Deletion for application: application_1427088391284_0093, with delay of 172800 seconds\n"
    },
    {
        "timestamp": "2015-03-23 11:40:31,340",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Deleting absolute path : /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0093\n"
    },
    {
        "timestamp": "2015-03-23 11:44:59,821",
        "type": "INFO",
        "app": "SecurityLogger.org.apache.hadoop.ipc.Server",
        "message": " Auth successful for appattempt_1427088391284_0095_000001 (auth:SIMPLE)\n"
    },
    {
        "timestamp": "2015-03-23 11:45:00,129",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Start request for container_1427088391284_0095_01_000117 by user ubuntu\n"
    },
    {
        "timestamp": "2015-03-23 11:45:00,130",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Creating a new application reference for app application_1427088391284_0095\n"
    },
    {
        "timestamp": "2015-03-23 11:45:00,130",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0095 transitioned from NEW to INITING\n"
    },
    {
        "timestamp": "2015-03-23 11:45:00,130",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0095 transitioned from INITING to RUNNING\n"
    },
    {
        "timestamp": "2015-03-23 11:45:00,131",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Adding container_1427088391284_0095_01_000117 to application application_1427088391284_0095\n"
    },
    {
        "timestamp": "2015-03-23 11:45:00,131",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0095_01_000117 transitioned from NEW to LOCALIZING\n"
    },
    {
        "timestamp": "2015-03-23 11:45:00,131",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event CONTAINER_INIT for appId application_1427088391284_0095\n"
    },
    {
        "timestamp": "2015-03-23 11:45:00,131",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event APPLICATION_INIT for appId application_1427088391284_0095\n"
    },
    {
        "timestamp": "2015-03-23 11:45:00,131",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got APPLICATION_INIT for service mapreduce_shuffle\n"
    },
    {
        "timestamp": "2015-03-23 11:45:00,131",
        "type": "INFO",
        "app": "org.apache.hadoop.mapred.ShuffleHandler",
        "message": " Added token for job_1427088391284_0095\n"
    },
    {
        "timestamp": "2015-03-23 11:45:00,132",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/5b38e61e-2325-41e2-b6aa-192bbd2c576b/hive_2015-03-23_11-43-14_963_4424364225699107475-1/-mr-10003/bd47ba55-0304-4cfe-960b-11998d016d76/map.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 11:45:00,132",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/5b38e61e-2325-41e2-b6aa-192bbd2c576b/hive_2015-03-23_11-43-14_963_4424364225699107475-1/-mr-10003/bd47ba55-0304-4cfe-960b-11998d016d76/reduce.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 11:45:00,132",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0095/job.jar transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 11:45:00,132",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0095/job.xml transitioned from INIT to DOWNLOADING\n"
    },
    {
        "timestamp": "2015-03-23 11:45:00,132",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService",
        "message": " Created localizer for container_1427088391284_0095_01_000117\n"
    },
    {
        "timestamp": "2015-03-23 11:45:00,132",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tIP=172.31.16.214\tOPERATION=Start Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0095\tCONTAINERID=container_1427088391284_0095_01_000117\n"
    },
    {
        "timestamp": "2015-03-23 11:45:00,137",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.ResourceLocalizationService",
        "message": " Writing credentials to the nmPrivate file /tmp/hadoop-ubuntu/nm-local-dir/nmPrivate/container_1427088391284_0095_01_000117.tokens. Credentials list: \n"
    },
    {
        "timestamp": "2015-03-23 11:45:00,183",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Initializing user ubuntu\n"
    },
    {
        "timestamp": "2015-03-23 11:45:00,190",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Copying from /tmp/hadoop-ubuntu/nm-local-dir/nmPrivate/container_1427088391284_0095_01_000117.tokens to /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0095/container_1427088391284_0095_01_000117.tokens\n"
    },
    {
        "timestamp": "2015-03-23 11:45:00,190",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Localizer CWD set to /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0095 = file:/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0095\n"
    },
    {
        "timestamp": "2015-03-23 11:45:00,394",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/5b38e61e-2325-41e2-b6aa-192bbd2c576b/hive_2015-03-23_11-43-14_963_4424364225699107475-1/-mr-10003/bd47ba55-0304-4cfe-960b-11998d016d76/map.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/filecache/86/map.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 11:45:00,440",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/ubuntu/5b38e61e-2325-41e2-b6aa-192bbd2c576b/hive_2015-03-23_11-43-14_963_4424364225699107475-1/-mr-10003/bd47ba55-0304-4cfe-960b-11998d016d76/reduce.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/filecache/87/reduce.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 11:45:00,956",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0095/job.jar(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0095/filecache/10/job.jar) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 11:45:01,032",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.localizer.LocalizedResource",
        "message": " Resource hdfs://172.31.17.135:8120/tmp/hadoop-yarn/staging/ubuntu/.staging/job_1427088391284_0095/job.xml(->/tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0095/filecache/11/job.xml) transitioned from DOWNLOADING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 11:45:01,032",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0095_01_000117 transitioned from LOCALIZING to LOCALIZED\n"
    },
    {
        "timestamp": "2015-03-23 11:45:01,090",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0095_01_000117 transitioned from LOCALIZED to RUNNING\n"
    },
    {
        "timestamp": "2015-03-23 11:45:01,121",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " launchContainer: [bash, /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0095/container_1427088391284_0095_01_000117/default_container_executor.sh]\n"
    },
    {
        "timestamp": "2015-03-23 11:45:02,407",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Starting resource-monitoring for container_1427088391284_0095_01_000117\n"
    },
    {
        "timestamp": "2015-03-23 11:45:02,447",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7747 for container-id container_1427088391284_0095_01_000117: 39.9 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:45:05,484",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7747 for container-id container_1427088391284_0095_01_000117: 55.5 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:45:08,501",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7747 for container-id container_1427088391284_0095_01_000117: 71.2 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:45:11,619",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7747 for container-id container_1427088391284_0095_01_000117: 80.9 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:45:14,654",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7747 for container-id container_1427088391284_0095_01_000117: 90.6 MB of 4 GB physical memory used; 6.7 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:45:17,675",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7747 for container-id container_1427088391284_0095_01_000117: 97.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:45:20,684",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7747 for container-id container_1427088391284_0095_01_000117: 111.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:45:23,696",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7747 for container-id container_1427088391284_0095_01_000117: 110.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:45:26,705",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7747 for container-id container_1427088391284_0095_01_000117: 116.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:45:29,714",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7747 for container-id container_1427088391284_0095_01_000117: 116.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:45:32,726",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7747 for container-id container_1427088391284_0095_01_000117: 116.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:45:35,735",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7747 for container-id container_1427088391284_0095_01_000117: 116.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:45:38,743",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7747 for container-id container_1427088391284_0095_01_000117: 120.7 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:45:41,752",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7747 for container-id container_1427088391284_0095_01_000117: 120.7 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:45:44,764",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7747 for container-id container_1427088391284_0095_01_000117: 120.7 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:45:47,772",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7747 for container-id container_1427088391284_0095_01_000117: 125.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:45:50,781",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7747 for container-id container_1427088391284_0095_01_000117: 125.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:45:53,794",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7747 for container-id container_1427088391284_0095_01_000117: 125.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:45:56,803",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7747 for container-id container_1427088391284_0095_01_000117: 126.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:45:59,812",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7747 for container-id container_1427088391284_0095_01_000117: 127.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:46:02,825",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7747 for container-id container_1427088391284_0095_01_000117: 129.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:46:05,834",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7747 for container-id container_1427088391284_0095_01_000117: 131.7 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:46:08,842",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7747 for container-id container_1427088391284_0095_01_000117: 136.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:46:11,854",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7747 for container-id container_1427088391284_0095_01_000117: 136.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:46:14,863",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7747 for container-id container_1427088391284_0095_01_000117: 136.6 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:46:17,873",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7747 for container-id container_1427088391284_0095_01_000117: 136.7 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:46:20,881",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7747 for container-id container_1427088391284_0095_01_000117: 136.7 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:46:23,893",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7747 for container-id container_1427088391284_0095_01_000117: 136.7 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:46:26,901",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7747 for container-id container_1427088391284_0095_01_000117: 136.7 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:46:29,909",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7747 for container-id container_1427088391284_0095_01_000117: 136.7 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:46:32,921",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7747 for container-id container_1427088391284_0095_01_000117: 141.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:46:35,930",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7747 for container-id container_1427088391284_0095_01_000117: 141.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:46:38,938",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7747 for container-id container_1427088391284_0095_01_000117: 141.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:46:41,950",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7747 for container-id container_1427088391284_0095_01_000117: 141.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:46:44,958",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7747 for container-id container_1427088391284_0095_01_000117: 141.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:46:47,966",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7747 for container-id container_1427088391284_0095_01_000117: 141.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:46:50,978",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7747 for container-id container_1427088391284_0095_01_000117: 141.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:46:53,986",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7747 for container-id container_1427088391284_0095_01_000117: 141.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:46:57,004",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7747 for container-id container_1427088391284_0095_01_000117: 141.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:47:00,018",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7747 for container-id container_1427088391284_0095_01_000117: 141.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:47:03,035",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7747 for container-id container_1427088391284_0095_01_000117: 144.1 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:47:06,044",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7747 for container-id container_1427088391284_0095_01_000117: 144.1 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:47:09,052",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7747 for container-id container_1427088391284_0095_01_000117: 144.1 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:47:12,065",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7747 for container-id container_1427088391284_0095_01_000117: 144.1 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:47:15,074",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7747 for container-id container_1427088391284_0095_01_000117: 144.1 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:47:18,205",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7747 for container-id container_1427088391284_0095_01_000117: 144.2 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:47:21,342",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7747 for container-id container_1427088391284_0095_01_000117: 149.9 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:47:24,423",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7747 for container-id container_1427088391284_0095_01_000117: 156.2 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:47:27,457",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7747 for container-id container_1427088391284_0095_01_000117: 174.4 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:47:30,466",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7747 for container-id container_1427088391284_0095_01_000117: 178.1 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:47:33,497",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7747 for container-id container_1427088391284_0095_01_000117: 169.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:47:36,523",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7747 for container-id container_1427088391284_0095_01_000117: 169.0 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:47:39,540",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7747 for container-id container_1427088391284_0095_01_000117: 169.3 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:47:42,564",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7747 for container-id container_1427088391284_0095_01_000117: 165.7 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:47:45,581",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7747 for container-id container_1427088391284_0095_01_000117: 165.7 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:47:48,610",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7747 for container-id container_1427088391284_0095_01_000117: 165.7 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:47:51,646",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7747 for container-id container_1427088391284_0095_01_000117: 165.7 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:47:54,672",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7747 for container-id container_1427088391284_0095_01_000117: 165.7 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:47:57,701",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7747 for container-id container_1427088391284_0095_01_000117: 165.7 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:48:00,738",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7747 for container-id container_1427088391284_0095_01_000117: 165.7 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:48:03,758",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7747 for container-id container_1427088391284_0095_01_000117: 165.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:48:06,775",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7747 for container-id container_1427088391284_0095_01_000117: 165.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:48:09,796",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7747 for container-id container_1427088391284_0095_01_000117: 165.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:48:12,825",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7747 for container-id container_1427088391284_0095_01_000117: 165.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:48:15,838",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Memory usage of ProcessTree 7747 for container-id container_1427088391284_0095_01_000117: 165.8 MB of 4 GB physical memory used; 6.8 GB of 8.4 GB virtual memory used\n"
    },
    {
        "timestamp": "2015-03-23 11:48:18,639",
        "type": "INFO",
        "app": "SecurityLogger.org.apache.hadoop.ipc.Server",
        "message": " Auth successful for appattempt_1427088391284_0095_000001 (auth:SIMPLE)\n"
    },
    {
        "timestamp": "2015-03-23 11:48:18,641",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Stopping container with container Id: container_1427088391284_0095_01_000117\n"
    },
    {
        "timestamp": "2015-03-23 11:48:18,642",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tIP=172.31.16.214\tOPERATION=Stop Container Request\tTARGET=ContainerManageImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0095\tCONTAINERID=container_1427088391284_0095_01_000117\n"
    },
    {
        "timestamp": "2015-03-23 11:48:18,642",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0095_01_000117 transitioned from RUNNING to KILLING\n"
    },
    {
        "timestamp": "2015-03-23 11:48:18,642",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch",
        "message": " Cleaning up container container_1427088391284_0095_01_000117\n"
    },
    {
        "timestamp": "2015-03-23 11:48:18,690",
        "type": "WARN",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Exit code from container container_1427088391284_0095_01_000117 is : 143\n"
    },
    {
        "timestamp": "2015-03-23 11:48:18,748",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0095_01_000117 transitioned from KILLING to CONTAINER_CLEANEDUP_AFTER_KILL\n"
    },
    {
        "timestamp": "2015-03-23 11:48:18,749",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Deleting absolute path : /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0095/container_1427088391284_0095_01_000117\n"
    },
    {
        "timestamp": "2015-03-23 11:48:18,751",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NMAuditLogger",
        "message": " USER=ubuntu\tOPERATION=Container Finished - Killed\tTARGET=ContainerImpl\tRESULT=SUCCESS\tAPPID=application_1427088391284_0095\tCONTAINERID=container_1427088391284_0095_01_000117\n"
    },
    {
        "timestamp": "2015-03-23 11:48:18,751",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.container.Container",
        "message": " Container container_1427088391284_0095_01_000117 transitioned from CONTAINER_CLEANEDUP_AFTER_KILL to DONE\n"
    },
    {
        "timestamp": "2015-03-23 11:48:18,751",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Removing container_1427088391284_0095_01_000117 from application application_1427088391284_0095\n"
    },
    {
        "timestamp": "2015-03-23 11:48:18,752",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event CONTAINER_STOP for appId application_1427088391284_0095\n"
    },
    {
        "timestamp": "2015-03-23 11:48:18,838",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor.ContainersMonitorImpl",
        "message": " Stopping resource-monitoring for container_1427088391284_0095_01_000117\n"
    },
    {
        "timestamp": "2015-03-23 11:48:21,654",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl",
        "message": " Removed completed containers from NM context: [container_1427088391284_0095_01_000117]\n"
    },
    {
        "timestamp": "2015-03-23 11:48:36,707",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0095 transitioned from RUNNING to APPLICATION_RESOURCES_CLEANINGUP\n"
    },
    {
        "timestamp": "2015-03-23 11:48:36,708",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.AuxServices",
        "message": " Got event APPLICATION_STOP for appId application_1427088391284_0095\n"
    },
    {
        "timestamp": "2015-03-23 11:48:36,709",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.application.Application",
        "message": " Application application_1427088391284_0095 transitioned from APPLICATION_RESOURCES_CLEANINGUP to FINISHED\n"
    },
    {
        "timestamp": "2015-03-23 11:48:36,709",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.loghandler.NonAggregatingLogHandler",
        "message": " Scheduling Log Deletion for application: application_1427088391284_0095, with delay of 172800 seconds\n"
    },
    {
        "timestamp": "2015-03-23 11:48:36,709",
        "type": "INFO",
        "app": "org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor",
        "message": " Deleting absolute path : /tmp/hadoop-ubuntu/nm-local-dir/usercache/ubuntu/appcache/application_1427088391284_0095\n"
    },
    {
        "timestamp": "2015-03-23 11:50:25,813",
        "type": "WARN",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Event EventType: KILL_CONTAINER sent to absent container container_1427088391284_0096_01_000276\n"
    },
    {
        "timestamp": "2015-03-23 11:53:26,998",
        "type": "WARN",
        "app": "org.apache.hadoop.yarn.server.nodemanager.containermanager.ContainerManagerImpl",
        "message": " Event EventType: FINISH_APPLICATION sent to absent application application_1427088391284_0096\n"
    }
]